2023-07-07 00:17:59,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-07 00:17:59,337:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-07 00:17:59,337:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-07 00:17:59,337:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-07 00:23:46,013:INFO:PyCaret ClassificationExperiment
2023-07-07 00:23:46,013:INFO:Logging name: clf-default-name
2023-07-07 00:23:46,014:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-07 00:23:46,014:INFO:version 3.0.4
2023-07-07 00:23:46,014:INFO:Initializing setup()
2023-07-07 00:23:46,014:INFO:self.USI: 43ae
2023-07-07 00:23:46,014:INFO:self._variable_keys: {'memory', 'X_test', 'fix_imbalance', 'y', 'X_train', 'log_plots_param', 'gpu_n_jobs_param', 'n_jobs_param', 'logging_param', 'html_param', '_ml_usecase', 'seed', 'y_test', 'is_multiclass', 'X', 'data', 'target_param', '_available_plots', 'USI', 'gpu_param', 'pipeline', 'fold_shuffle_param', 'idx', 'fold_groups_param', 'fold_generator', 'y_train', 'exp_name_log', 'exp_id'}
2023-07-07 00:23:46,014:INFO:Checking environment
2023-07-07 00:23:46,014:INFO:python_version: 3.9.13
2023-07-07 00:23:46,014:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-07-07 00:23:46,014:INFO:machine: AMD64
2023-07-07 00:23:46,014:INFO:platform: Windows-10-10.0.19045-SP0
2023-07-07 00:23:46,015:INFO:Memory: svmem(total=17125732352, available=7018684416, percent=59.0, used=10107047936, free=7018684416)
2023-07-07 00:23:46,015:INFO:Physical Core: 4
2023-07-07 00:23:46,015:INFO:Logical Core: 8
2023-07-07 00:23:46,015:INFO:Checking libraries
2023-07-07 00:23:46,015:INFO:System:
2023-07-07 00:23:46,015:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-07-07 00:23:46,015:INFO:executable: C:\Users\hamim\anaconda3\python.exe
2023-07-07 00:23:46,015:INFO:   machine: Windows-10-10.0.19045-SP0
2023-07-07 00:23:46,015:INFO:PyCaret required dependencies:
2023-07-07 00:23:46,020:INFO:                 pip: 22.2.2
2023-07-07 00:23:46,020:INFO:          setuptools: 63.4.1
2023-07-07 00:23:46,020:INFO:             pycaret: 3.0.4
2023-07-07 00:23:46,020:INFO:             IPython: 7.31.1
2023-07-07 00:23:46,020:INFO:          ipywidgets: 7.6.5
2023-07-07 00:23:46,020:INFO:                tqdm: 4.64.1
2023-07-07 00:23:46,021:INFO:               numpy: 1.21.5
2023-07-07 00:23:46,021:INFO:              pandas: 1.4.4
2023-07-07 00:23:46,021:INFO:              jinja2: 2.11.3
2023-07-07 00:23:46,021:INFO:               scipy: 1.9.1
2023-07-07 00:23:46,021:INFO:              joblib: 1.2.0
2023-07-07 00:23:46,021:INFO:             sklearn: 1.0.2
2023-07-07 00:23:46,021:INFO:                pyod: 1.1.0
2023-07-07 00:23:46,021:INFO:            imblearn: 0.10.1
2023-07-07 00:23:46,021:INFO:   category_encoders: 2.6.1
2023-07-07 00:23:46,021:INFO:            lightgbm: 3.3.5
2023-07-07 00:23:46,021:INFO:               numba: 0.55.1
2023-07-07 00:23:46,021:INFO:            requests: 2.28.1
2023-07-07 00:23:46,021:INFO:          matplotlib: 3.5.2
2023-07-07 00:23:46,021:INFO:          scikitplot: 0.3.7
2023-07-07 00:23:46,021:INFO:         yellowbrick: 1.5
2023-07-07 00:23:46,021:INFO:              plotly: 5.9.0
2023-07-07 00:23:46,021:INFO:    plotly-resampler: Not installed
2023-07-07 00:23:46,021:INFO:             kaleido: 0.2.1
2023-07-07 00:23:46,022:INFO:           schemdraw: 0.15
2023-07-07 00:23:46,022:INFO:         statsmodels: 0.13.2
2023-07-07 00:23:46,022:INFO:              sktime: 0.20.0
2023-07-07 00:23:46,022:INFO:               tbats: 1.1.3
2023-07-07 00:23:46,022:INFO:            pmdarima: 2.0.3
2023-07-07 00:23:46,022:INFO:              psutil: 5.9.0
2023-07-07 00:23:46,022:INFO:          markupsafe: 2.0.1
2023-07-07 00:23:46,022:INFO:             pickle5: Not installed
2023-07-07 00:23:46,022:INFO:         cloudpickle: 2.0.0
2023-07-07 00:23:46,022:INFO:         deprecation: 2.1.0
2023-07-07 00:23:46,022:INFO:              xxhash: 3.2.0
2023-07-07 00:23:46,022:INFO:           wurlitzer: Not installed
2023-07-07 00:23:46,022:INFO:PyCaret optional dependencies:
2023-07-07 00:23:46,049:INFO:                shap: Not installed
2023-07-07 00:23:46,049:INFO:           interpret: Not installed
2023-07-07 00:23:46,049:INFO:                umap: Not installed
2023-07-07 00:23:46,049:INFO:    pandas_profiling: Not installed
2023-07-07 00:23:46,049:INFO:  explainerdashboard: Not installed
2023-07-07 00:23:46,049:INFO:             autoviz: Not installed
2023-07-07 00:23:46,049:INFO:           fairlearn: Not installed
2023-07-07 00:23:46,049:INFO:          deepchecks: Not installed
2023-07-07 00:23:46,049:INFO:             xgboost: Not installed
2023-07-07 00:23:46,049:INFO:            catboost: Not installed
2023-07-07 00:23:46,049:INFO:              kmodes: Not installed
2023-07-07 00:23:46,049:INFO:             mlxtend: Not installed
2023-07-07 00:23:46,049:INFO:       statsforecast: Not installed
2023-07-07 00:23:46,050:INFO:        tune_sklearn: Not installed
2023-07-07 00:23:46,050:INFO:                 ray: Not installed
2023-07-07 00:23:46,050:INFO:            hyperopt: Not installed
2023-07-07 00:23:46,050:INFO:              optuna: Not installed
2023-07-07 00:23:46,050:INFO:               skopt: Not installed
2023-07-07 00:23:46,050:INFO:              mlflow: Not installed
2023-07-07 00:23:46,050:INFO:              gradio: Not installed
2023-07-07 00:23:46,050:INFO:             fastapi: Not installed
2023-07-07 00:23:46,050:INFO:             uvicorn: Not installed
2023-07-07 00:23:46,050:INFO:              m2cgen: Not installed
2023-07-07 00:23:46,050:INFO:           evidently: Not installed
2023-07-07 00:23:46,050:INFO:               fugue: Not installed
2023-07-07 00:23:46,050:INFO:           streamlit: Not installed
2023-07-07 00:23:46,051:INFO:             prophet: Not installed
2023-07-07 00:23:46,051:INFO:None
2023-07-07 00:23:46,051:INFO:Set up data.
2023-07-07 00:23:46,067:INFO:Set up train/test split.
2023-07-07 00:23:46,078:INFO:Set up index.
2023-07-07 00:23:46,078:INFO:Set up folding strategy.
2023-07-07 00:23:46,078:INFO:Assigning column types.
2023-07-07 00:23:46,083:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-07 00:23:46,144:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-07 00:23:46,148:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-07 00:23:46,202:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-07 00:23:46,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-07 00:23:46,491:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-07 00:23:46,492:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-07 00:23:46,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-07 00:23:46,530:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-07 00:23:46,530:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-07 00:23:46,597:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-07 00:23:46,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-07 00:23:46,631:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-07 00:23:46,685:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-07 00:23:46,721:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-07 00:23:46,721:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-07 00:23:46,722:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-07 00:23:46,816:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-07 00:23:46,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-07 00:23:46,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-07 00:23:46,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-07 00:23:46,912:INFO:Preparing preprocessing pipeline...
2023-07-07 00:23:46,925:INFO:Set up simple imputation.
2023-07-07 00:23:46,925:INFO:Set up imbalanced handling.
2023-07-07 00:23:46,927:INFO:Set up column name cleaning.
2023-07-07 00:23:47,008:INFO:Finished creating preprocessing pipeline.
2023-07-07 00:23:47,023:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Daytime/evening attendance',
                                             'Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital...
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-07 00:23:47,023:INFO:Creating final display dataframe.
2023-07-07 00:23:47,215:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Target
2                   Target type            Binary
3           Original data shape        (2802, 35)
4        Transformed data shape        (3825, 35)
5   Transformed train set shape        (2984, 35)
6    Transformed test set shape         (841, 35)
7              Numeric features                34
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              43ae
2023-07-07 00:23:47,322:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-07 00:23:47,323:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-07 00:23:47,408:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-07 00:23:47,409:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-07 00:23:47,410:INFO:setup() successfully completed in 1.4s...............
2023-07-07 00:24:36,468:INFO:Initializing compare_models()
2023-07-07 00:24:36,469:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-07 00:24:36,469:INFO:Checking exceptions
2023-07-07 00:24:36,483:INFO:Preparing display monitor
2023-07-07 00:24:36,546:INFO:Initializing Logistic Regression
2023-07-07 00:24:36,546:INFO:Total runtime is 0.0 minutes
2023-07-07 00:24:36,554:INFO:SubProcess create_model() called ==================================
2023-07-07 00:24:36,555:INFO:Initializing create_model()
2023-07-07 00:24:36,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEA6F4B5E0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:24:36,556:INFO:Checking exceptions
2023-07-07 00:24:36,557:INFO:Importing libraries
2023-07-07 00:24:36,558:INFO:Copying training dataset
2023-07-07 00:24:36,565:INFO:Defining folds
2023-07-07 00:24:36,566:INFO:Declaring metric variables
2023-07-07 00:24:36,571:INFO:Importing untrained model
2023-07-07 00:24:36,579:INFO:Logistic Regression Imported successfully
2023-07-07 00:24:36,593:INFO:Starting cross validation
2023-07-07 00:24:36,595:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:24:45,638:INFO:Calculating mean and std
2023-07-07 00:24:45,640:INFO:Creating metrics dataframe
2023-07-07 00:24:45,656:INFO:Uploading results into container
2023-07-07 00:24:45,657:INFO:Uploading model into container now
2023-07-07 00:24:45,660:INFO:_master_model_container: 1
2023-07-07 00:24:45,660:INFO:_display_container: 2
2023-07-07 00:24:45,661:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-07 00:24:45,661:INFO:create_model() successfully completed......................................
2023-07-07 00:24:45,735:INFO:SubProcess create_model() end ==================================
2023-07-07 00:24:45,735:INFO:Creating metrics dataframe
2023-07-07 00:24:45,744:INFO:Initializing K Neighbors Classifier
2023-07-07 00:24:45,745:INFO:Total runtime is 0.15331243276596068 minutes
2023-07-07 00:24:45,748:INFO:SubProcess create_model() called ==================================
2023-07-07 00:24:45,749:INFO:Initializing create_model()
2023-07-07 00:24:45,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEA6F4B5E0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:24:45,749:INFO:Checking exceptions
2023-07-07 00:24:45,749:INFO:Importing libraries
2023-07-07 00:24:45,749:INFO:Copying training dataset
2023-07-07 00:24:45,756:INFO:Defining folds
2023-07-07 00:24:45,757:INFO:Declaring metric variables
2023-07-07 00:24:45,763:INFO:Importing untrained model
2023-07-07 00:24:45,771:INFO:K Neighbors Classifier Imported successfully
2023-07-07 00:24:45,784:INFO:Starting cross validation
2023-07-07 00:24:45,786:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:24:46,042:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:24:46,053:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:24:46,065:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:24:46,067:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:24:46,101:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:24:46,102:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:24:46,112:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:24:46,117:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:24:46,341:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:24:46,343:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:24:46,409:INFO:Calculating mean and std
2023-07-07 00:24:46,410:INFO:Creating metrics dataframe
2023-07-07 00:24:46,425:INFO:Uploading results into container
2023-07-07 00:24:46,426:INFO:Uploading model into container now
2023-07-07 00:24:46,426:INFO:_master_model_container: 2
2023-07-07 00:24:46,426:INFO:_display_container: 2
2023-07-07 00:24:46,426:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-07 00:24:46,426:INFO:create_model() successfully completed......................................
2023-07-07 00:24:46,492:INFO:SubProcess create_model() end ==================================
2023-07-07 00:24:46,492:INFO:Creating metrics dataframe
2023-07-07 00:24:46,502:INFO:Initializing Naive Bayes
2023-07-07 00:24:46,502:INFO:Total runtime is 0.16593884229660033 minutes
2023-07-07 00:24:46,508:INFO:SubProcess create_model() called ==================================
2023-07-07 00:24:46,509:INFO:Initializing create_model()
2023-07-07 00:24:46,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEA6F4B5E0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:24:46,510:INFO:Checking exceptions
2023-07-07 00:24:46,510:INFO:Importing libraries
2023-07-07 00:24:46,510:INFO:Copying training dataset
2023-07-07 00:24:46,522:INFO:Defining folds
2023-07-07 00:24:46,523:INFO:Declaring metric variables
2023-07-07 00:24:46,529:INFO:Importing untrained model
2023-07-07 00:24:46,536:INFO:Naive Bayes Imported successfully
2023-07-07 00:24:46,547:INFO:Starting cross validation
2023-07-07 00:24:46,550:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:24:47,003:INFO:Calculating mean and std
2023-07-07 00:24:47,005:INFO:Creating metrics dataframe
2023-07-07 00:24:47,019:INFO:Uploading results into container
2023-07-07 00:24:47,020:INFO:Uploading model into container now
2023-07-07 00:24:47,020:INFO:_master_model_container: 3
2023-07-07 00:24:47,020:INFO:_display_container: 2
2023-07-07 00:24:47,020:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-07 00:24:47,020:INFO:create_model() successfully completed......................................
2023-07-07 00:24:47,097:INFO:SubProcess create_model() end ==================================
2023-07-07 00:24:47,097:INFO:Creating metrics dataframe
2023-07-07 00:24:47,110:INFO:Initializing Decision Tree Classifier
2023-07-07 00:24:47,110:INFO:Total runtime is 0.1760656754175822 minutes
2023-07-07 00:24:47,116:INFO:SubProcess create_model() called ==================================
2023-07-07 00:24:47,116:INFO:Initializing create_model()
2023-07-07 00:24:47,116:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEA6F4B5E0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:24:47,116:INFO:Checking exceptions
2023-07-07 00:24:47,117:INFO:Importing libraries
2023-07-07 00:24:47,117:INFO:Copying training dataset
2023-07-07 00:24:47,133:INFO:Defining folds
2023-07-07 00:24:47,133:INFO:Declaring metric variables
2023-07-07 00:24:47,139:INFO:Importing untrained model
2023-07-07 00:24:47,146:INFO:Decision Tree Classifier Imported successfully
2023-07-07 00:24:47,158:INFO:Starting cross validation
2023-07-07 00:24:47,160:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:24:47,624:INFO:Calculating mean and std
2023-07-07 00:24:47,626:INFO:Creating metrics dataframe
2023-07-07 00:24:47,640:INFO:Uploading results into container
2023-07-07 00:24:47,641:INFO:Uploading model into container now
2023-07-07 00:24:47,642:INFO:_master_model_container: 4
2023-07-07 00:24:47,642:INFO:_display_container: 2
2023-07-07 00:24:47,642:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-07 00:24:47,642:INFO:create_model() successfully completed......................................
2023-07-07 00:24:47,710:INFO:SubProcess create_model() end ==================================
2023-07-07 00:24:47,710:INFO:Creating metrics dataframe
2023-07-07 00:24:47,722:INFO:Initializing SVM - Linear Kernel
2023-07-07 00:24:47,722:INFO:Total runtime is 0.18626514275868733 minutes
2023-07-07 00:24:47,727:INFO:SubProcess create_model() called ==================================
2023-07-07 00:24:47,727:INFO:Initializing create_model()
2023-07-07 00:24:47,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEA6F4B5E0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:24:47,728:INFO:Checking exceptions
2023-07-07 00:24:47,728:INFO:Importing libraries
2023-07-07 00:24:47,728:INFO:Copying training dataset
2023-07-07 00:24:47,739:INFO:Defining folds
2023-07-07 00:24:47,740:INFO:Declaring metric variables
2023-07-07 00:24:47,744:INFO:Importing untrained model
2023-07-07 00:24:47,751:INFO:SVM - Linear Kernel Imported successfully
2023-07-07 00:24:47,761:INFO:Starting cross validation
2023-07-07 00:24:47,763:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:24:48,093:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:24:48,115:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:24:48,125:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:24:48,195:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:24:48,195:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:24:48,216:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:24:48,220:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:24:48,300:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:24:48,301:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:24:48,315:INFO:Calculating mean and std
2023-07-07 00:24:48,317:INFO:Creating metrics dataframe
2023-07-07 00:24:48,334:INFO:Uploading results into container
2023-07-07 00:24:48,335:INFO:Uploading model into container now
2023-07-07 00:24:48,335:INFO:_master_model_container: 5
2023-07-07 00:24:48,335:INFO:_display_container: 2
2023-07-07 00:24:48,336:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-07 00:24:48,336:INFO:create_model() successfully completed......................................
2023-07-07 00:24:48,406:INFO:SubProcess create_model() end ==================================
2023-07-07 00:24:48,406:INFO:Creating metrics dataframe
2023-07-07 00:24:48,417:INFO:Initializing Ridge Classifier
2023-07-07 00:24:48,418:INFO:Total runtime is 0.19786814053853352 minutes
2023-07-07 00:24:48,423:INFO:SubProcess create_model() called ==================================
2023-07-07 00:24:48,424:INFO:Initializing create_model()
2023-07-07 00:24:48,424:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEA6F4B5E0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:24:48,424:INFO:Checking exceptions
2023-07-07 00:24:48,424:INFO:Importing libraries
2023-07-07 00:24:48,424:INFO:Copying training dataset
2023-07-07 00:24:48,434:INFO:Defining folds
2023-07-07 00:24:48,434:INFO:Declaring metric variables
2023-07-07 00:24:48,441:INFO:Importing untrained model
2023-07-07 00:24:48,447:INFO:Ridge Classifier Imported successfully
2023-07-07 00:24:48,460:INFO:Starting cross validation
2023-07-07 00:24:48,462:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:24:48,685:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:24:48,688:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:24:48,692:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:24:48,697:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:24:48,717:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:24:48,734:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:24:48,735:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:24:48,767:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:24:48,842:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:24:48,848:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:24:48,859:INFO:Calculating mean and std
2023-07-07 00:24:48,860:INFO:Creating metrics dataframe
2023-07-07 00:24:48,878:INFO:Uploading results into container
2023-07-07 00:24:48,879:INFO:Uploading model into container now
2023-07-07 00:24:48,880:INFO:_master_model_container: 6
2023-07-07 00:24:48,880:INFO:_display_container: 2
2023-07-07 00:24:48,880:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=42, solver='auto', tol=0.001)
2023-07-07 00:24:48,880:INFO:create_model() successfully completed......................................
2023-07-07 00:24:48,952:INFO:SubProcess create_model() end ==================================
2023-07-07 00:24:48,953:INFO:Creating metrics dataframe
2023-07-07 00:24:48,966:INFO:Initializing Random Forest Classifier
2023-07-07 00:24:48,966:INFO:Total runtime is 0.20700081189473468 minutes
2023-07-07 00:24:48,970:INFO:SubProcess create_model() called ==================================
2023-07-07 00:24:48,971:INFO:Initializing create_model()
2023-07-07 00:24:48,971:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEA6F4B5E0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:24:48,971:INFO:Checking exceptions
2023-07-07 00:24:48,972:INFO:Importing libraries
2023-07-07 00:24:48,972:INFO:Copying training dataset
2023-07-07 00:24:48,981:INFO:Defining folds
2023-07-07 00:24:48,981:INFO:Declaring metric variables
2023-07-07 00:24:48,988:INFO:Importing untrained model
2023-07-07 00:24:48,994:INFO:Random Forest Classifier Imported successfully
2023-07-07 00:24:49,005:INFO:Starting cross validation
2023-07-07 00:24:49,007:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:24:51,365:INFO:Calculating mean and std
2023-07-07 00:24:51,366:INFO:Creating metrics dataframe
2023-07-07 00:24:51,389:INFO:Uploading results into container
2023-07-07 00:24:51,390:INFO:Uploading model into container now
2023-07-07 00:24:51,390:INFO:_master_model_container: 7
2023-07-07 00:24:51,391:INFO:_display_container: 2
2023-07-07 00:24:51,391:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-07 00:24:51,391:INFO:create_model() successfully completed......................................
2023-07-07 00:24:51,458:INFO:SubProcess create_model() end ==================================
2023-07-07 00:24:51,458:INFO:Creating metrics dataframe
2023-07-07 00:24:51,471:INFO:Initializing Quadratic Discriminant Analysis
2023-07-07 00:24:51,472:INFO:Total runtime is 0.248773721853892 minutes
2023-07-07 00:24:51,476:INFO:SubProcess create_model() called ==================================
2023-07-07 00:24:51,476:INFO:Initializing create_model()
2023-07-07 00:24:51,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEA6F4B5E0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:24:51,477:INFO:Checking exceptions
2023-07-07 00:24:51,477:INFO:Importing libraries
2023-07-07 00:24:51,477:INFO:Copying training dataset
2023-07-07 00:24:51,487:INFO:Defining folds
2023-07-07 00:24:51,487:INFO:Declaring metric variables
2023-07-07 00:24:51,493:INFO:Importing untrained model
2023-07-07 00:24:51,500:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-07 00:24:51,515:INFO:Starting cross validation
2023-07-07 00:24:51,516:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:24:51,690:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:24:51,691:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:24:51,737:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:24:51,741:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:24:51,745:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:24:51,770:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:24:51,832:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:24:51,882:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:24:51,944:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:24:51,953:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:24:51,964:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:24:52,038:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:24:52,063:INFO:Calculating mean and std
2023-07-07 00:24:52,065:INFO:Creating metrics dataframe
2023-07-07 00:24:52,094:INFO:Uploading results into container
2023-07-07 00:24:52,095:INFO:Uploading model into container now
2023-07-07 00:24:52,096:INFO:_master_model_container: 8
2023-07-07 00:24:52,096:INFO:_display_container: 2
2023-07-07 00:24:52,096:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-07 00:24:52,096:INFO:create_model() successfully completed......................................
2023-07-07 00:24:52,174:INFO:SubProcess create_model() end ==================================
2023-07-07 00:24:52,174:INFO:Creating metrics dataframe
2023-07-07 00:24:52,188:INFO:Initializing Ada Boost Classifier
2023-07-07 00:24:52,188:INFO:Total runtime is 0.26070367097854613 minutes
2023-07-07 00:24:52,195:INFO:SubProcess create_model() called ==================================
2023-07-07 00:24:52,195:INFO:Initializing create_model()
2023-07-07 00:24:52,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEA6F4B5E0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:24:52,195:INFO:Checking exceptions
2023-07-07 00:24:52,196:INFO:Importing libraries
2023-07-07 00:24:52,196:INFO:Copying training dataset
2023-07-07 00:24:52,206:INFO:Defining folds
2023-07-07 00:24:52,206:INFO:Declaring metric variables
2023-07-07 00:24:52,212:INFO:Importing untrained model
2023-07-07 00:24:52,219:INFO:Ada Boost Classifier Imported successfully
2023-07-07 00:24:52,229:INFO:Starting cross validation
2023-07-07 00:24:52,231:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:24:53,707:INFO:Calculating mean and std
2023-07-07 00:24:53,710:INFO:Creating metrics dataframe
2023-07-07 00:24:53,742:INFO:Uploading results into container
2023-07-07 00:24:53,742:INFO:Uploading model into container now
2023-07-07 00:24:53,743:INFO:_master_model_container: 9
2023-07-07 00:24:53,743:INFO:_display_container: 2
2023-07-07 00:24:53,743:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2023-07-07 00:24:53,743:INFO:create_model() successfully completed......................................
2023-07-07 00:24:53,818:INFO:SubProcess create_model() end ==================================
2023-07-07 00:24:53,818:INFO:Creating metrics dataframe
2023-07-07 00:24:53,831:INFO:Initializing Gradient Boosting Classifier
2023-07-07 00:24:53,831:INFO:Total runtime is 0.28808488448460895 minutes
2023-07-07 00:24:53,836:INFO:SubProcess create_model() called ==================================
2023-07-07 00:24:53,836:INFO:Initializing create_model()
2023-07-07 00:24:53,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEA6F4B5E0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:24:53,836:INFO:Checking exceptions
2023-07-07 00:24:53,836:INFO:Importing libraries
2023-07-07 00:24:53,836:INFO:Copying training dataset
2023-07-07 00:24:53,848:INFO:Defining folds
2023-07-07 00:24:53,848:INFO:Declaring metric variables
2023-07-07 00:24:53,855:INFO:Importing untrained model
2023-07-07 00:24:53,861:INFO:Gradient Boosting Classifier Imported successfully
2023-07-07 00:24:53,869:INFO:Starting cross validation
2023-07-07 00:24:53,871:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:24:56,040:INFO:Calculating mean and std
2023-07-07 00:24:56,043:INFO:Creating metrics dataframe
2023-07-07 00:24:56,085:INFO:Uploading results into container
2023-07-07 00:24:56,086:INFO:Uploading model into container now
2023-07-07 00:24:56,086:INFO:_master_model_container: 10
2023-07-07 00:24:56,086:INFO:_display_container: 2
2023-07-07 00:24:56,087:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-07 00:24:56,087:INFO:create_model() successfully completed......................................
2023-07-07 00:24:56,168:INFO:SubProcess create_model() end ==================================
2023-07-07 00:24:56,169:INFO:Creating metrics dataframe
2023-07-07 00:24:56,184:INFO:Initializing Linear Discriminant Analysis
2023-07-07 00:24:56,184:INFO:Total runtime is 0.3272980491320292 minutes
2023-07-07 00:24:56,188:INFO:SubProcess create_model() called ==================================
2023-07-07 00:24:56,189:INFO:Initializing create_model()
2023-07-07 00:24:56,189:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEA6F4B5E0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:24:56,189:INFO:Checking exceptions
2023-07-07 00:24:56,189:INFO:Importing libraries
2023-07-07 00:24:56,190:INFO:Copying training dataset
2023-07-07 00:24:56,197:INFO:Defining folds
2023-07-07 00:24:56,197:INFO:Declaring metric variables
2023-07-07 00:24:56,203:INFO:Importing untrained model
2023-07-07 00:24:56,209:INFO:Linear Discriminant Analysis Imported successfully
2023-07-07 00:24:56,222:INFO:Starting cross validation
2023-07-07 00:24:56,225:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:24:56,821:INFO:Calculating mean and std
2023-07-07 00:24:56,823:INFO:Creating metrics dataframe
2023-07-07 00:24:56,866:INFO:Uploading results into container
2023-07-07 00:24:56,866:INFO:Uploading model into container now
2023-07-07 00:24:56,867:INFO:_master_model_container: 11
2023-07-07 00:24:56,867:INFO:_display_container: 2
2023-07-07 00:24:56,867:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-07 00:24:56,867:INFO:create_model() successfully completed......................................
2023-07-07 00:24:56,935:INFO:SubProcess create_model() end ==================================
2023-07-07 00:24:56,935:INFO:Creating metrics dataframe
2023-07-07 00:24:56,948:INFO:Initializing Extra Trees Classifier
2023-07-07 00:24:56,948:INFO:Total runtime is 0.34003224372863766 minutes
2023-07-07 00:24:56,952:INFO:SubProcess create_model() called ==================================
2023-07-07 00:24:56,953:INFO:Initializing create_model()
2023-07-07 00:24:56,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEA6F4B5E0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:24:56,953:INFO:Checking exceptions
2023-07-07 00:24:56,953:INFO:Importing libraries
2023-07-07 00:24:56,953:INFO:Copying training dataset
2023-07-07 00:24:56,960:INFO:Defining folds
2023-07-07 00:24:56,960:INFO:Declaring metric variables
2023-07-07 00:24:56,966:INFO:Importing untrained model
2023-07-07 00:24:56,972:INFO:Extra Trees Classifier Imported successfully
2023-07-07 00:24:56,983:INFO:Starting cross validation
2023-07-07 00:24:56,984:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:24:59,241:INFO:Calculating mean and std
2023-07-07 00:24:59,247:INFO:Creating metrics dataframe
2023-07-07 00:24:59,302:INFO:Uploading results into container
2023-07-07 00:24:59,303:INFO:Uploading model into container now
2023-07-07 00:24:59,303:INFO:_master_model_container: 12
2023-07-07 00:24:59,303:INFO:_display_container: 2
2023-07-07 00:24:59,304:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-07 00:24:59,304:INFO:create_model() successfully completed......................................
2023-07-07 00:24:59,370:INFO:SubProcess create_model() end ==================================
2023-07-07 00:24:59,370:INFO:Creating metrics dataframe
2023-07-07 00:24:59,384:INFO:Initializing Light Gradient Boosting Machine
2023-07-07 00:24:59,384:INFO:Total runtime is 0.38062935272852577 minutes
2023-07-07 00:24:59,389:INFO:SubProcess create_model() called ==================================
2023-07-07 00:24:59,389:INFO:Initializing create_model()
2023-07-07 00:24:59,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEA6F4B5E0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:24:59,390:INFO:Checking exceptions
2023-07-07 00:24:59,390:INFO:Importing libraries
2023-07-07 00:24:59,390:INFO:Copying training dataset
2023-07-07 00:24:59,400:INFO:Defining folds
2023-07-07 00:24:59,400:INFO:Declaring metric variables
2023-07-07 00:24:59,405:INFO:Importing untrained model
2023-07-07 00:24:59,412:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-07 00:24:59,429:INFO:Starting cross validation
2023-07-07 00:24:59,431:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:25:02,032:INFO:Calculating mean and std
2023-07-07 00:25:02,034:INFO:Creating metrics dataframe
2023-07-07 00:25:02,080:INFO:Uploading results into container
2023-07-07 00:25:02,081:INFO:Uploading model into container now
2023-07-07 00:25:02,081:INFO:_master_model_container: 13
2023-07-07 00:25:02,081:INFO:_display_container: 2
2023-07-07 00:25:02,082:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-07 00:25:02,082:INFO:create_model() successfully completed......................................
2023-07-07 00:25:02,147:INFO:SubProcess create_model() end ==================================
2023-07-07 00:25:02,147:INFO:Creating metrics dataframe
2023-07-07 00:25:02,161:INFO:Initializing Dummy Classifier
2023-07-07 00:25:02,161:INFO:Total runtime is 0.42691381374994913 minutes
2023-07-07 00:25:02,164:INFO:SubProcess create_model() called ==================================
2023-07-07 00:25:02,165:INFO:Initializing create_model()
2023-07-07 00:25:02,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEA6F4B5E0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:25:02,165:INFO:Checking exceptions
2023-07-07 00:25:02,165:INFO:Importing libraries
2023-07-07 00:25:02,165:INFO:Copying training dataset
2023-07-07 00:25:02,172:INFO:Defining folds
2023-07-07 00:25:02,173:INFO:Declaring metric variables
2023-07-07 00:25:02,179:INFO:Importing untrained model
2023-07-07 00:25:02,185:INFO:Dummy Classifier Imported successfully
2023-07-07 00:25:02,197:INFO:Starting cross validation
2023-07-07 00:25:02,198:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:25:02,427:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:25:02,449:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:25:02,478:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:25:02,480:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:25:02,497:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:25:02,506:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:25:02,508:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:25:02,523:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:25:02,699:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:25:02,701:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:25:02,851:INFO:Calculating mean and std
2023-07-07 00:25:02,854:INFO:Creating metrics dataframe
2023-07-07 00:25:02,911:INFO:Uploading results into container
2023-07-07 00:25:02,911:INFO:Uploading model into container now
2023-07-07 00:25:02,912:INFO:_master_model_container: 14
2023-07-07 00:25:02,912:INFO:_display_container: 2
2023-07-07 00:25:02,912:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-07 00:25:02,912:INFO:create_model() successfully completed......................................
2023-07-07 00:25:02,981:INFO:SubProcess create_model() end ==================================
2023-07-07 00:25:02,981:INFO:Creating metrics dataframe
2023-07-07 00:25:03,013:INFO:Initializing create_model()
2023-07-07 00:25:03,013:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:25:03,013:INFO:Checking exceptions
2023-07-07 00:25:03,015:INFO:Importing libraries
2023-07-07 00:25:03,016:INFO:Copying training dataset
2023-07-07 00:25:03,023:INFO:Defining folds
2023-07-07 00:25:03,023:INFO:Declaring metric variables
2023-07-07 00:25:03,023:INFO:Importing untrained model
2023-07-07 00:25:03,024:INFO:Declaring custom model
2023-07-07 00:25:03,025:INFO:Gradient Boosting Classifier Imported successfully
2023-07-07 00:25:03,028:INFO:Cross validation set to False
2023-07-07 00:25:03,028:INFO:Fitting Model
2023-07-07 00:25:03,605:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-07 00:25:03,605:INFO:create_model() successfully completed......................................
2023-07-07 00:25:03,726:INFO:_master_model_container: 14
2023-07-07 00:25:03,726:INFO:_display_container: 2
2023-07-07 00:25:03,727:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-07 00:25:03,727:INFO:compare_models() successfully completed......................................
2023-07-07 00:28:57,037:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-07 00:29:58,758:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-07 00:30:32,949:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-07 00:32:46,551:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-07 00:33:05,947:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-07-07 00:39:30,348:INFO:Initializing plot_model()
2023-07-07 00:39:30,348:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:39:30,348:INFO:Checking exceptions
2023-07-07 00:39:30,356:INFO:Preloading libraries
2023-07-07 00:39:30,369:INFO:Copying training dataset
2023-07-07 00:39:30,369:INFO:Plot type: confusion_matrix
2023-07-07 00:39:30,576:INFO:Fitting Model
2023-07-07 00:39:30,589:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-07-07 00:39:30,590:INFO:Scoring test/hold-out set
2023-07-07 00:39:30,753:INFO:Visual Rendered Successfully
2023-07-07 00:39:30,832:INFO:plot_model() successfully completed......................................
2023-07-07 00:39:45,905:INFO:Initializing plot_model()
2023-07-07 00:39:45,905:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:39:45,905:INFO:Checking exceptions
2023-07-07 00:39:45,913:INFO:Preloading libraries
2023-07-07 00:39:45,925:INFO:Copying training dataset
2023-07-07 00:39:45,926:INFO:Plot type: confusion_matrix
2023-07-07 00:39:46,174:INFO:Fitting Model
2023-07-07 00:39:46,174:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-07-07 00:39:46,175:INFO:Scoring test/hold-out set
2023-07-07 00:39:46,356:INFO:Visual Rendered Successfully
2023-07-07 00:39:46,431:INFO:plot_model() successfully completed......................................
2023-07-07 00:41:39,104:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,105:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,139:INFO:Initializing plot_model()
2023-07-07 00:41:39,139:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,139:INFO:Checking exceptions
2023-07-07 00:41:39,148:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,149:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,176:INFO:Initializing plot_model()
2023-07-07 00:41:39,177:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,177:INFO:Checking exceptions
2023-07-07 00:41:39,185:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,185:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,221:INFO:Initializing plot_model()
2023-07-07 00:41:39,221:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,221:INFO:Checking exceptions
2023-07-07 00:41:39,228:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,229:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,258:INFO:Initializing plot_model()
2023-07-07 00:41:39,258:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,258:INFO:Checking exceptions
2023-07-07 00:41:39,265:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,266:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,293:INFO:Initializing plot_model()
2023-07-07 00:41:39,293:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,293:INFO:Checking exceptions
2023-07-07 00:41:39,300:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,300:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,332:INFO:Initializing plot_model()
2023-07-07 00:41:39,332:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,333:INFO:Checking exceptions
2023-07-07 00:41:39,341:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,342:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,369:INFO:Initializing plot_model()
2023-07-07 00:41:39,369:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,369:INFO:Checking exceptions
2023-07-07 00:41:39,375:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,376:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,405:INFO:Initializing plot_model()
2023-07-07 00:41:39,405:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,405:INFO:Checking exceptions
2023-07-07 00:41:39,412:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,412:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,449:INFO:Initializing plot_model()
2023-07-07 00:41:39,449:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,449:INFO:Checking exceptions
2023-07-07 00:41:39,456:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,457:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,484:INFO:Initializing plot_model()
2023-07-07 00:41:39,485:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,485:INFO:Checking exceptions
2023-07-07 00:41:39,492:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,493:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,520:INFO:Initializing plot_model()
2023-07-07 00:41:39,520:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,521:INFO:Checking exceptions
2023-07-07 00:41:39,526:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,526:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,549:INFO:Initializing plot_model()
2023-07-07 00:41:39,549:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,549:INFO:Checking exceptions
2023-07-07 00:41:39,556:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,556:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,580:INFO:Initializing plot_model()
2023-07-07 00:41:39,580:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,581:INFO:Checking exceptions
2023-07-07 00:41:39,586:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,586:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,609:INFO:Initializing plot_model()
2023-07-07 00:41:39,609:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,609:INFO:Checking exceptions
2023-07-07 00:41:39,616:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,616:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,637:INFO:Initializing plot_model()
2023-07-07 00:41:39,637:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,638:INFO:Checking exceptions
2023-07-07 00:41:39,643:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,643:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,667:INFO:Initializing plot_model()
2023-07-07 00:41:39,668:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,668:INFO:Checking exceptions
2023-07-07 00:41:39,673:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,674:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,697:INFO:Initializing plot_model()
2023-07-07 00:41:39,697:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,697:INFO:Checking exceptions
2023-07-07 00:41:39,703:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,703:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,725:INFO:Initializing plot_model()
2023-07-07 00:41:39,726:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,726:INFO:Checking exceptions
2023-07-07 00:41:39,732:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,733:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,757:INFO:Initializing plot_model()
2023-07-07 00:41:39,757:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,757:INFO:Checking exceptions
2023-07-07 00:41:39,763:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,763:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,788:INFO:Initializing plot_model()
2023-07-07 00:41:39,789:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,789:INFO:Checking exceptions
2023-07-07 00:41:39,794:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,795:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,819:INFO:Initializing plot_model()
2023-07-07 00:41:39,820:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,820:INFO:Checking exceptions
2023-07-07 00:41:39,826:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,826:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,850:INFO:Initializing plot_model()
2023-07-07 00:41:39,850:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,850:INFO:Checking exceptions
2023-07-07 00:41:39,856:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,856:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,890:INFO:Initializing plot_model()
2023-07-07 00:41:39,890:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,890:INFO:Checking exceptions
2023-07-07 00:41:39,896:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,896:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,926:INFO:Initializing plot_model()
2023-07-07 00:41:39,926:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,926:INFO:Checking exceptions
2023-07-07 00:41:39,933:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,934:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,963:INFO:Initializing plot_model()
2023-07-07 00:41:39,963:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:39,963:INFO:Checking exceptions
2023-07-07 00:41:39,971:INFO:Initializing evaluate_model()
2023-07-07 00:41:39,971:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:39,999:INFO:Initializing plot_model()
2023-07-07 00:41:39,999:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,000:INFO:Checking exceptions
2023-07-07 00:41:40,007:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,007:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,032:INFO:Initializing plot_model()
2023-07-07 00:41:40,032:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,032:INFO:Checking exceptions
2023-07-07 00:41:40,040:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,040:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,065:INFO:Initializing plot_model()
2023-07-07 00:41:40,065:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,065:INFO:Checking exceptions
2023-07-07 00:41:40,074:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,075:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,098:INFO:Initializing plot_model()
2023-07-07 00:41:40,099:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,099:INFO:Checking exceptions
2023-07-07 00:41:40,105:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,105:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,129:INFO:Initializing plot_model()
2023-07-07 00:41:40,129:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,129:INFO:Checking exceptions
2023-07-07 00:41:40,136:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,137:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,165:INFO:Initializing plot_model()
2023-07-07 00:41:40,165:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,165:INFO:Checking exceptions
2023-07-07 00:41:40,171:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,172:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,196:INFO:Initializing plot_model()
2023-07-07 00:41:40,196:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,197:INFO:Checking exceptions
2023-07-07 00:41:40,202:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,202:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,229:INFO:Initializing plot_model()
2023-07-07 00:41:40,229:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,229:INFO:Checking exceptions
2023-07-07 00:41:40,235:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,235:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,261:INFO:Initializing plot_model()
2023-07-07 00:41:40,261:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,261:INFO:Checking exceptions
2023-07-07 00:41:40,267:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,267:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,294:INFO:Initializing plot_model()
2023-07-07 00:41:40,295:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,295:INFO:Checking exceptions
2023-07-07 00:41:40,301:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,302:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,330:INFO:Initializing plot_model()
2023-07-07 00:41:40,330:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,331:INFO:Checking exceptions
2023-07-07 00:41:40,338:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,338:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,366:INFO:Initializing plot_model()
2023-07-07 00:41:40,366:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,366:INFO:Checking exceptions
2023-07-07 00:41:40,372:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,373:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,397:INFO:Initializing plot_model()
2023-07-07 00:41:40,397:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,397:INFO:Checking exceptions
2023-07-07 00:41:40,404:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,404:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,431:INFO:Initializing plot_model()
2023-07-07 00:41:40,431:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,432:INFO:Checking exceptions
2023-07-07 00:41:40,438:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,438:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,478:INFO:Initializing plot_model()
2023-07-07 00:41:40,478:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,479:INFO:Checking exceptions
2023-07-07 00:41:40,485:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,485:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,512:INFO:Initializing plot_model()
2023-07-07 00:41:40,512:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,512:INFO:Checking exceptions
2023-07-07 00:41:40,520:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,520:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,547:INFO:Initializing plot_model()
2023-07-07 00:41:40,547:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,547:INFO:Checking exceptions
2023-07-07 00:41:40,553:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,553:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,582:INFO:Initializing plot_model()
2023-07-07 00:41:40,582:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,582:INFO:Checking exceptions
2023-07-07 00:41:40,590:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,591:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,615:INFO:Initializing plot_model()
2023-07-07 00:41:40,615:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,615:INFO:Checking exceptions
2023-07-07 00:41:40,623:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,623:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,650:INFO:Initializing plot_model()
2023-07-07 00:41:40,651:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,651:INFO:Checking exceptions
2023-07-07 00:41:40,657:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,657:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,683:INFO:Initializing plot_model()
2023-07-07 00:41:40,683:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,683:INFO:Checking exceptions
2023-07-07 00:41:40,691:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,691:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,717:INFO:Initializing plot_model()
2023-07-07 00:41:40,717:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,717:INFO:Checking exceptions
2023-07-07 00:41:40,725:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,725:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,752:INFO:Initializing plot_model()
2023-07-07 00:41:40,752:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,752:INFO:Checking exceptions
2023-07-07 00:41:40,759:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,760:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,785:INFO:Initializing plot_model()
2023-07-07 00:41:40,786:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,786:INFO:Checking exceptions
2023-07-07 00:41:40,793:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,793:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,822:INFO:Initializing plot_model()
2023-07-07 00:41:40,823:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,823:INFO:Checking exceptions
2023-07-07 00:41:40,830:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,830:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,856:INFO:Initializing plot_model()
2023-07-07 00:41:40,856:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,856:INFO:Checking exceptions
2023-07-07 00:41:40,862:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,863:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,891:INFO:Initializing plot_model()
2023-07-07 00:41:40,891:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,892:INFO:Checking exceptions
2023-07-07 00:41:40,898:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,898:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,921:INFO:Initializing plot_model()
2023-07-07 00:41:40,921:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,921:INFO:Checking exceptions
2023-07-07 00:41:40,927:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,927:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,951:INFO:Initializing plot_model()
2023-07-07 00:41:40,952:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,952:INFO:Checking exceptions
2023-07-07 00:41:40,957:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,957:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:40,981:INFO:Initializing plot_model()
2023-07-07 00:41:40,981:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:40,981:INFO:Checking exceptions
2023-07-07 00:41:40,987:INFO:Initializing evaluate_model()
2023-07-07 00:41:40,987:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,010:INFO:Initializing plot_model()
2023-07-07 00:41:41,010:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,010:INFO:Checking exceptions
2023-07-07 00:41:41,031:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,032:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,062:INFO:Initializing plot_model()
2023-07-07 00:41:41,062:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,062:INFO:Checking exceptions
2023-07-07 00:41:41,071:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,071:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,099:INFO:Initializing plot_model()
2023-07-07 00:41:41,099:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,100:INFO:Checking exceptions
2023-07-07 00:41:41,107:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,107:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,133:INFO:Initializing plot_model()
2023-07-07 00:41:41,133:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,133:INFO:Checking exceptions
2023-07-07 00:41:41,140:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,140:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,166:INFO:Initializing plot_model()
2023-07-07 00:41:41,166:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,167:INFO:Checking exceptions
2023-07-07 00:41:41,175:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,175:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,205:INFO:Initializing plot_model()
2023-07-07 00:41:41,205:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,206:INFO:Checking exceptions
2023-07-07 00:41:41,213:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,214:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,243:INFO:Initializing plot_model()
2023-07-07 00:41:41,243:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,243:INFO:Checking exceptions
2023-07-07 00:41:41,251:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,251:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,278:INFO:Initializing plot_model()
2023-07-07 00:41:41,278:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,278:INFO:Checking exceptions
2023-07-07 00:41:41,283:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,283:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,308:INFO:Initializing plot_model()
2023-07-07 00:41:41,308:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,308:INFO:Checking exceptions
2023-07-07 00:41:41,315:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,316:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,340:INFO:Initializing plot_model()
2023-07-07 00:41:41,341:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,341:INFO:Checking exceptions
2023-07-07 00:41:41,347:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,348:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,373:INFO:Initializing plot_model()
2023-07-07 00:41:41,373:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,374:INFO:Checking exceptions
2023-07-07 00:41:41,381:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,381:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,405:INFO:Initializing plot_model()
2023-07-07 00:41:41,405:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,406:INFO:Checking exceptions
2023-07-07 00:41:41,413:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,413:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,439:INFO:Initializing plot_model()
2023-07-07 00:41:41,439:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,439:INFO:Checking exceptions
2023-07-07 00:41:41,445:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,445:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,469:INFO:Initializing plot_model()
2023-07-07 00:41:41,469:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,469:INFO:Checking exceptions
2023-07-07 00:41:41,476:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,476:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,501:INFO:Initializing plot_model()
2023-07-07 00:41:41,502:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,502:INFO:Checking exceptions
2023-07-07 00:41:41,508:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,508:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,533:INFO:Initializing plot_model()
2023-07-07 00:41:41,533:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,533:INFO:Checking exceptions
2023-07-07 00:41:41,539:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,540:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,564:INFO:Initializing plot_model()
2023-07-07 00:41:41,564:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,564:INFO:Checking exceptions
2023-07-07 00:41:41,570:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,570:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,597:INFO:Initializing plot_model()
2023-07-07 00:41:41,597:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,597:INFO:Checking exceptions
2023-07-07 00:41:41,603:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,604:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,629:INFO:Initializing plot_model()
2023-07-07 00:41:41,629:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,630:INFO:Checking exceptions
2023-07-07 00:41:41,636:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,636:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,660:INFO:Initializing plot_model()
2023-07-07 00:41:41,661:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,661:INFO:Checking exceptions
2023-07-07 00:41:41,667:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,667:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,691:INFO:Initializing plot_model()
2023-07-07 00:41:41,692:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,692:INFO:Checking exceptions
2023-07-07 00:41:41,699:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,699:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,725:INFO:Initializing plot_model()
2023-07-07 00:41:41,725:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,725:INFO:Checking exceptions
2023-07-07 00:41:41,732:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,732:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,757:INFO:Initializing plot_model()
2023-07-07 00:41:41,758:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,758:INFO:Checking exceptions
2023-07-07 00:41:41,765:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,766:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,798:INFO:Initializing plot_model()
2023-07-07 00:41:41,799:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,799:INFO:Checking exceptions
2023-07-07 00:41:41,807:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,807:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,832:INFO:Initializing plot_model()
2023-07-07 00:41:41,832:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,832:INFO:Checking exceptions
2023-07-07 00:41:41,841:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,841:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,868:INFO:Initializing plot_model()
2023-07-07 00:41:41,868:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,868:INFO:Checking exceptions
2023-07-07 00:41:41,874:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,875:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,899:INFO:Initializing plot_model()
2023-07-07 00:41:41,899:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,899:INFO:Checking exceptions
2023-07-07 00:41:41,905:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,905:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,928:INFO:Initializing plot_model()
2023-07-07 00:41:41,929:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,929:INFO:Checking exceptions
2023-07-07 00:41:41,935:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,935:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,957:INFO:Initializing plot_model()
2023-07-07 00:41:41,957:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,958:INFO:Checking exceptions
2023-07-07 00:41:41,963:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,964:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:41,991:INFO:Initializing plot_model()
2023-07-07 00:41:41,991:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:41,991:INFO:Checking exceptions
2023-07-07 00:41:41,999:INFO:Initializing evaluate_model()
2023-07-07 00:41:41,999:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:42,028:INFO:Initializing plot_model()
2023-07-07 00:41:42,029:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:42,029:INFO:Checking exceptions
2023-07-07 00:41:42,037:INFO:Initializing evaluate_model()
2023-07-07 00:41:42,037:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:42,065:INFO:Initializing plot_model()
2023-07-07 00:41:42,065:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:42,065:INFO:Checking exceptions
2023-07-07 00:41:42,074:INFO:Initializing evaluate_model()
2023-07-07 00:41:42,074:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:42,105:INFO:Initializing plot_model()
2023-07-07 00:41:42,105:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:42,105:INFO:Checking exceptions
2023-07-07 00:41:42,114:INFO:Initializing evaluate_model()
2023-07-07 00:41:42,114:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:42,146:INFO:Initializing plot_model()
2023-07-07 00:41:42,146:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:42,147:INFO:Checking exceptions
2023-07-07 00:41:42,157:INFO:Initializing evaluate_model()
2023-07-07 00:41:42,157:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:42,189:INFO:Initializing plot_model()
2023-07-07 00:41:42,189:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:42,189:INFO:Checking exceptions
2023-07-07 00:41:42,197:INFO:Initializing evaluate_model()
2023-07-07 00:41:42,197:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:42,237:INFO:Initializing plot_model()
2023-07-07 00:41:42,237:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:42,238:INFO:Checking exceptions
2023-07-07 00:41:42,244:INFO:Initializing evaluate_model()
2023-07-07 00:41:42,245:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:42,270:INFO:Initializing plot_model()
2023-07-07 00:41:42,270:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:42,270:INFO:Checking exceptions
2023-07-07 00:41:42,275:INFO:Initializing evaluate_model()
2023-07-07 00:41:42,276:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:42,306:INFO:Initializing plot_model()
2023-07-07 00:41:42,306:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:42,306:INFO:Checking exceptions
2023-07-07 00:41:42,314:INFO:Initializing evaluate_model()
2023-07-07 00:41:42,315:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:42,342:INFO:Initializing plot_model()
2023-07-07 00:41:42,343:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:42,343:INFO:Checking exceptions
2023-07-07 00:41:42,349:INFO:Initializing evaluate_model()
2023-07-07 00:41:42,349:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:42,375:INFO:Initializing plot_model()
2023-07-07 00:41:42,376:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:42,376:INFO:Checking exceptions
2023-07-07 00:41:42,382:INFO:Initializing evaluate_model()
2023-07-07 00:41:42,382:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:42,409:INFO:Initializing plot_model()
2023-07-07 00:41:42,409:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:42,409:INFO:Checking exceptions
2023-07-07 00:41:42,415:INFO:Initializing evaluate_model()
2023-07-07 00:41:42,416:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:42,443:INFO:Initializing plot_model()
2023-07-07 00:41:42,443:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:42,443:INFO:Checking exceptions
2023-07-07 00:41:42,451:INFO:Initializing evaluate_model()
2023-07-07 00:41:42,452:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:42,480:INFO:Initializing plot_model()
2023-07-07 00:41:42,480:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:42,480:INFO:Checking exceptions
2023-07-07 00:41:42,488:INFO:Initializing evaluate_model()
2023-07-07 00:41:42,488:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:42,518:INFO:Initializing plot_model()
2023-07-07 00:41:42,518:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:42,519:INFO:Checking exceptions
2023-07-07 00:41:42,526:INFO:Initializing evaluate_model()
2023-07-07 00:41:42,526:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:41:42,553:INFO:Initializing plot_model()
2023-07-07 00:41:42,554:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:42,554:INFO:Checking exceptions
2023-07-07 00:41:42,879:INFO:Initializing plot_model()
2023-07-07 00:41:42,880:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:41:42,880:INFO:Checking exceptions
2023-07-07 00:42:05,319:INFO:Initializing plot_model()
2023-07-07 00:42:05,319:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:42:05,319:INFO:Checking exceptions
2023-07-07 00:42:05,734:INFO:Initializing plot_model()
2023-07-07 00:42:05,734:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:42:05,735:INFO:Checking exceptions
2023-07-07 00:44:22,603:INFO:Initializing plot_model()
2023-07-07 00:44:22,603:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:44:22,603:INFO:Checking exceptions
2023-07-07 00:48:32,589:INFO:Initializing plot_model()
2023-07-07 00:48:32,589:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:48:32,589:INFO:Checking exceptions
2023-07-07 00:48:55,066:INFO:Initializing plot_model()
2023-07-07 00:48:55,066:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:48:55,066:INFO:Checking exceptions
2023-07-07 00:48:55,073:INFO:Preloading libraries
2023-07-07 00:48:55,086:INFO:Copying training dataset
2023-07-07 00:48:55,086:INFO:Plot type: confusion_matrix
2023-07-07 00:48:55,281:INFO:Fitting Model
2023-07-07 00:48:55,281:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-07-07 00:48:55,281:INFO:Scoring test/hold-out set
2023-07-07 00:48:55,435:INFO:Visual Rendered Successfully
2023-07-07 00:48:55,526:INFO:plot_model() successfully completed......................................
2023-07-07 00:51:13,889:INFO:Initializing plot_model()
2023-07-07 00:51:13,889:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:51:13,889:INFO:Checking exceptions
2023-07-07 00:52:03,378:INFO:Initializing plot_model()
2023-07-07 00:52:03,378:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:52:03,378:INFO:Checking exceptions
2023-07-07 00:52:07,150:INFO:Initializing plot_model()
2023-07-07 00:52:07,151:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:52:07,152:INFO:Checking exceptions
2023-07-07 00:52:10,933:INFO:Initializing plot_model()
2023-07-07 00:52:10,934:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:52:10,934:INFO:Checking exceptions
2023-07-07 00:52:52,825:INFO:Initializing evaluate_model()
2023-07-07 00:52:52,825:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 00:52:52,855:INFO:Initializing plot_model()
2023-07-07 00:52:52,855:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:52:52,856:INFO:Checking exceptions
2023-07-07 00:53:21,323:INFO:Initializing plot_model()
2023-07-07 00:53:21,323:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:53:21,323:INFO:Checking exceptions
2023-07-07 00:53:40,599:INFO:Initializing compare_models()
2023-07-07 00:53:40,599:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, include=1, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, 'include': 1, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-07 00:53:40,599:INFO:Checking exceptions
2023-07-07 00:53:51,957:INFO:Initializing compare_models()
2023-07-07 00:53:51,957:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, include=[0], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, 'include': [0], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-07 00:53:51,957:INFO:Checking exceptions
2023-07-07 00:53:58,392:INFO:Initializing compare_models()
2023-07-07 00:53:58,392:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-07 00:53:58,392:INFO:Checking exceptions
2023-07-07 00:53:58,396:INFO:Preparing display monitor
2023-07-07 00:53:58,444:INFO:Initializing Logistic Regression
2023-07-07 00:53:58,445:INFO:Total runtime is 1.6399224599202474e-05 minutes
2023-07-07 00:53:58,449:INFO:SubProcess create_model() called ==================================
2023-07-07 00:53:58,450:INFO:Initializing create_model()
2023-07-07 00:53:58,450:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAC9C1E80>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:53:58,450:INFO:Checking exceptions
2023-07-07 00:53:58,450:INFO:Importing libraries
2023-07-07 00:53:58,451:INFO:Copying training dataset
2023-07-07 00:53:58,458:INFO:Defining folds
2023-07-07 00:53:58,458:INFO:Declaring metric variables
2023-07-07 00:53:58,463:INFO:Importing untrained model
2023-07-07 00:53:58,470:INFO:Logistic Regression Imported successfully
2023-07-07 00:53:58,482:INFO:Starting cross validation
2023-07-07 00:53:58,485:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:54:07,206:INFO:Calculating mean and std
2023-07-07 00:54:07,208:INFO:Creating metrics dataframe
2023-07-07 00:54:07,266:INFO:Uploading results into container
2023-07-07 00:54:07,266:INFO:Uploading model into container now
2023-07-07 00:54:07,267:INFO:_master_model_container: 15
2023-07-07 00:54:07,267:INFO:_display_container: 3
2023-07-07 00:54:07,267:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-07 00:54:07,267:INFO:create_model() successfully completed......................................
2023-07-07 00:54:07,350:INFO:SubProcess create_model() end ==================================
2023-07-07 00:54:07,350:INFO:Creating metrics dataframe
2023-07-07 00:54:07,360:INFO:Initializing K Neighbors Classifier
2023-07-07 00:54:07,360:INFO:Total runtime is 0.14860086838404338 minutes
2023-07-07 00:54:07,364:INFO:SubProcess create_model() called ==================================
2023-07-07 00:54:07,365:INFO:Initializing create_model()
2023-07-07 00:54:07,365:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAC9C1E80>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:54:07,365:INFO:Checking exceptions
2023-07-07 00:54:07,365:INFO:Importing libraries
2023-07-07 00:54:07,365:INFO:Copying training dataset
2023-07-07 00:54:07,375:INFO:Defining folds
2023-07-07 00:54:07,375:INFO:Declaring metric variables
2023-07-07 00:54:07,383:INFO:Importing untrained model
2023-07-07 00:54:07,393:INFO:K Neighbors Classifier Imported successfully
2023-07-07 00:54:07,405:INFO:Starting cross validation
2023-07-07 00:54:07,407:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:54:07,692:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:54:07,708:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:54:07,717:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:54:07,719:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:54:07,729:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:54:07,754:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:54:07,757:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:54:07,759:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:54:08,090:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:54:08,120:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:54:08,350:INFO:Calculating mean and std
2023-07-07 00:54:08,352:INFO:Creating metrics dataframe
2023-07-07 00:54:08,427:INFO:Uploading results into container
2023-07-07 00:54:08,428:INFO:Uploading model into container now
2023-07-07 00:54:08,428:INFO:_master_model_container: 16
2023-07-07 00:54:08,429:INFO:_display_container: 3
2023-07-07 00:54:08,429:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-07 00:54:08,429:INFO:create_model() successfully completed......................................
2023-07-07 00:54:08,514:INFO:SubProcess create_model() end ==================================
2023-07-07 00:54:08,515:INFO:Creating metrics dataframe
2023-07-07 00:54:08,530:INFO:Initializing Naive Bayes
2023-07-07 00:54:08,530:INFO:Total runtime is 0.16809735695521036 minutes
2023-07-07 00:54:08,536:INFO:SubProcess create_model() called ==================================
2023-07-07 00:54:08,536:INFO:Initializing create_model()
2023-07-07 00:54:08,536:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAC9C1E80>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:54:08,536:INFO:Checking exceptions
2023-07-07 00:54:08,536:INFO:Importing libraries
2023-07-07 00:54:08,537:INFO:Copying training dataset
2023-07-07 00:54:08,547:INFO:Defining folds
2023-07-07 00:54:08,547:INFO:Declaring metric variables
2023-07-07 00:54:08,555:INFO:Importing untrained model
2023-07-07 00:54:08,561:INFO:Naive Bayes Imported successfully
2023-07-07 00:54:08,572:INFO:Starting cross validation
2023-07-07 00:54:08,575:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:54:09,308:INFO:Calculating mean and std
2023-07-07 00:54:09,310:INFO:Creating metrics dataframe
2023-07-07 00:54:09,375:INFO:Uploading results into container
2023-07-07 00:54:09,376:INFO:Uploading model into container now
2023-07-07 00:54:09,376:INFO:_master_model_container: 17
2023-07-07 00:54:09,376:INFO:_display_container: 3
2023-07-07 00:54:09,377:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-07 00:54:09,377:INFO:create_model() successfully completed......................................
2023-07-07 00:54:09,463:INFO:SubProcess create_model() end ==================================
2023-07-07 00:54:09,463:INFO:Creating metrics dataframe
2023-07-07 00:54:09,476:INFO:Initializing Decision Tree Classifier
2023-07-07 00:54:09,476:INFO:Total runtime is 0.18386086225509643 minutes
2023-07-07 00:54:09,481:INFO:SubProcess create_model() called ==================================
2023-07-07 00:54:09,481:INFO:Initializing create_model()
2023-07-07 00:54:09,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAC9C1E80>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:54:09,482:INFO:Checking exceptions
2023-07-07 00:54:09,482:INFO:Importing libraries
2023-07-07 00:54:09,482:INFO:Copying training dataset
2023-07-07 00:54:09,490:INFO:Defining folds
2023-07-07 00:54:09,490:INFO:Declaring metric variables
2023-07-07 00:54:09,496:INFO:Importing untrained model
2023-07-07 00:54:09,503:INFO:Decision Tree Classifier Imported successfully
2023-07-07 00:54:09,516:INFO:Starting cross validation
2023-07-07 00:54:09,519:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:54:10,201:INFO:Calculating mean and std
2023-07-07 00:54:10,203:INFO:Creating metrics dataframe
2023-07-07 00:54:10,265:INFO:Uploading results into container
2023-07-07 00:54:10,266:INFO:Uploading model into container now
2023-07-07 00:54:10,266:INFO:_master_model_container: 18
2023-07-07 00:54:10,266:INFO:_display_container: 3
2023-07-07 00:54:10,266:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-07 00:54:10,266:INFO:create_model() successfully completed......................................
2023-07-07 00:54:10,339:INFO:SubProcess create_model() end ==================================
2023-07-07 00:54:10,339:INFO:Creating metrics dataframe
2023-07-07 00:54:10,351:INFO:Initializing SVM - Linear Kernel
2023-07-07 00:54:10,351:INFO:Total runtime is 0.1984453241030375 minutes
2023-07-07 00:54:10,356:INFO:SubProcess create_model() called ==================================
2023-07-07 00:54:10,357:INFO:Initializing create_model()
2023-07-07 00:54:10,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAC9C1E80>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:54:10,357:INFO:Checking exceptions
2023-07-07 00:54:10,357:INFO:Importing libraries
2023-07-07 00:54:10,358:INFO:Copying training dataset
2023-07-07 00:54:10,367:INFO:Defining folds
2023-07-07 00:54:10,367:INFO:Declaring metric variables
2023-07-07 00:54:10,372:INFO:Importing untrained model
2023-07-07 00:54:10,381:INFO:SVM - Linear Kernel Imported successfully
2023-07-07 00:54:10,393:INFO:Starting cross validation
2023-07-07 00:54:10,395:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:54:10,667:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:54:10,695:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:54:10,730:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:54:10,738:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:54:10,768:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:54:10,777:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:54:10,807:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:54:10,823:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:54:10,922:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:54:10,947:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:54:11,121:INFO:Calculating mean and std
2023-07-07 00:54:11,123:INFO:Creating metrics dataframe
2023-07-07 00:54:11,196:INFO:Uploading results into container
2023-07-07 00:54:11,197:INFO:Uploading model into container now
2023-07-07 00:54:11,197:INFO:_master_model_container: 19
2023-07-07 00:54:11,197:INFO:_display_container: 3
2023-07-07 00:54:11,198:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-07 00:54:11,198:INFO:create_model() successfully completed......................................
2023-07-07 00:54:11,282:INFO:SubProcess create_model() end ==================================
2023-07-07 00:54:11,282:INFO:Creating metrics dataframe
2023-07-07 00:54:11,294:INFO:Initializing Ridge Classifier
2023-07-07 00:54:11,294:INFO:Total runtime is 0.21416707038879393 minutes
2023-07-07 00:54:11,299:INFO:SubProcess create_model() called ==================================
2023-07-07 00:54:11,299:INFO:Initializing create_model()
2023-07-07 00:54:11,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAC9C1E80>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:54:11,299:INFO:Checking exceptions
2023-07-07 00:54:11,299:INFO:Importing libraries
2023-07-07 00:54:11,299:INFO:Copying training dataset
2023-07-07 00:54:11,309:INFO:Defining folds
2023-07-07 00:54:11,309:INFO:Declaring metric variables
2023-07-07 00:54:11,315:INFO:Importing untrained model
2023-07-07 00:54:11,323:INFO:Ridge Classifier Imported successfully
2023-07-07 00:54:11,335:INFO:Starting cross validation
2023-07-07 00:54:11,339:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:54:11,531:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:54:11,563:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:54:11,567:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:54:11,597:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:54:11,602:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:54:11,618:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:54:11,620:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:54:11,621:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:54:11,766:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:54:11,795:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:54:11,997:INFO:Calculating mean and std
2023-07-07 00:54:11,999:INFO:Creating metrics dataframe
2023-07-07 00:54:12,070:INFO:Uploading results into container
2023-07-07 00:54:12,071:INFO:Uploading model into container now
2023-07-07 00:54:12,071:INFO:_master_model_container: 20
2023-07-07 00:54:12,071:INFO:_display_container: 3
2023-07-07 00:54:12,072:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=42, solver='auto', tol=0.001)
2023-07-07 00:54:12,072:INFO:create_model() successfully completed......................................
2023-07-07 00:54:12,153:INFO:SubProcess create_model() end ==================================
2023-07-07 00:54:12,153:INFO:Creating metrics dataframe
2023-07-07 00:54:12,166:INFO:Initializing Random Forest Classifier
2023-07-07 00:54:12,166:INFO:Total runtime is 0.2287003397941589 minutes
2023-07-07 00:54:12,172:INFO:SubProcess create_model() called ==================================
2023-07-07 00:54:12,173:INFO:Initializing create_model()
2023-07-07 00:54:12,173:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAC9C1E80>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:54:12,173:INFO:Checking exceptions
2023-07-07 00:54:12,174:INFO:Importing libraries
2023-07-07 00:54:12,174:INFO:Copying training dataset
2023-07-07 00:54:12,185:INFO:Defining folds
2023-07-07 00:54:12,185:INFO:Declaring metric variables
2023-07-07 00:54:12,192:INFO:Importing untrained model
2023-07-07 00:54:12,199:INFO:Random Forest Classifier Imported successfully
2023-07-07 00:54:12,210:INFO:Starting cross validation
2023-07-07 00:54:12,213:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:54:14,604:INFO:Calculating mean and std
2023-07-07 00:54:14,606:INFO:Creating metrics dataframe
2023-07-07 00:54:14,682:INFO:Uploading results into container
2023-07-07 00:54:14,683:INFO:Uploading model into container now
2023-07-07 00:54:14,684:INFO:_master_model_container: 21
2023-07-07 00:54:14,684:INFO:_display_container: 3
2023-07-07 00:54:14,684:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-07 00:54:14,684:INFO:create_model() successfully completed......................................
2023-07-07 00:54:14,756:INFO:SubProcess create_model() end ==================================
2023-07-07 00:54:14,757:INFO:Creating metrics dataframe
2023-07-07 00:54:14,769:INFO:Initializing Quadratic Discriminant Analysis
2023-07-07 00:54:14,769:INFO:Total runtime is 0.2720859209696452 minutes
2023-07-07 00:54:14,773:INFO:SubProcess create_model() called ==================================
2023-07-07 00:54:14,774:INFO:Initializing create_model()
2023-07-07 00:54:14,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAC9C1E80>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:54:14,774:INFO:Checking exceptions
2023-07-07 00:54:14,774:INFO:Importing libraries
2023-07-07 00:54:14,774:INFO:Copying training dataset
2023-07-07 00:54:14,782:INFO:Defining folds
2023-07-07 00:54:14,783:INFO:Declaring metric variables
2023-07-07 00:54:14,790:INFO:Importing untrained model
2023-07-07 00:54:14,797:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-07 00:54:14,808:INFO:Starting cross validation
2023-07-07 00:54:14,810:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:54:14,962:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:54:14,980:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:54:14,984:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:54:14,986:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:54:15,019:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:54:15,029:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:54:15,034:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:54:15,038:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:54:15,085:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:54:15,145:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:54:15,259:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:54:15,263:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:54:15,314:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:54:15,530:INFO:Calculating mean and std
2023-07-07 00:54:15,532:INFO:Creating metrics dataframe
2023-07-07 00:54:15,605:INFO:Uploading results into container
2023-07-07 00:54:15,605:INFO:Uploading model into container now
2023-07-07 00:54:15,606:INFO:_master_model_container: 22
2023-07-07 00:54:15,606:INFO:_display_container: 3
2023-07-07 00:54:15,606:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-07 00:54:15,606:INFO:create_model() successfully completed......................................
2023-07-07 00:54:15,679:INFO:SubProcess create_model() end ==================================
2023-07-07 00:54:15,679:INFO:Creating metrics dataframe
2023-07-07 00:54:15,693:INFO:Initializing Ada Boost Classifier
2023-07-07 00:54:15,694:INFO:Total runtime is 0.2874937335650126 minutes
2023-07-07 00:54:15,698:INFO:SubProcess create_model() called ==================================
2023-07-07 00:54:15,699:INFO:Initializing create_model()
2023-07-07 00:54:15,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAC9C1E80>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:54:15,699:INFO:Checking exceptions
2023-07-07 00:54:15,699:INFO:Importing libraries
2023-07-07 00:54:15,699:INFO:Copying training dataset
2023-07-07 00:54:15,706:INFO:Defining folds
2023-07-07 00:54:15,706:INFO:Declaring metric variables
2023-07-07 00:54:15,712:INFO:Importing untrained model
2023-07-07 00:54:15,718:INFO:Ada Boost Classifier Imported successfully
2023-07-07 00:54:15,729:INFO:Starting cross validation
2023-07-07 00:54:15,731:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:54:17,144:INFO:Calculating mean and std
2023-07-07 00:54:17,146:INFO:Creating metrics dataframe
2023-07-07 00:54:17,224:INFO:Uploading results into container
2023-07-07 00:54:17,225:INFO:Uploading model into container now
2023-07-07 00:54:17,225:INFO:_master_model_container: 23
2023-07-07 00:54:17,225:INFO:_display_container: 3
2023-07-07 00:54:17,226:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2023-07-07 00:54:17,226:INFO:create_model() successfully completed......................................
2023-07-07 00:54:17,298:INFO:SubProcess create_model() end ==================================
2023-07-07 00:54:17,298:INFO:Creating metrics dataframe
2023-07-07 00:54:17,310:INFO:Initializing Gradient Boosting Classifier
2023-07-07 00:54:17,310:INFO:Total runtime is 0.31443578004837036 minutes
2023-07-07 00:54:17,314:INFO:SubProcess create_model() called ==================================
2023-07-07 00:54:17,314:INFO:Initializing create_model()
2023-07-07 00:54:17,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAC9C1E80>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:54:17,315:INFO:Checking exceptions
2023-07-07 00:54:17,315:INFO:Importing libraries
2023-07-07 00:54:17,315:INFO:Copying training dataset
2023-07-07 00:54:17,325:INFO:Defining folds
2023-07-07 00:54:17,325:INFO:Declaring metric variables
2023-07-07 00:54:17,330:INFO:Importing untrained model
2023-07-07 00:54:17,336:INFO:Gradient Boosting Classifier Imported successfully
2023-07-07 00:54:17,349:INFO:Starting cross validation
2023-07-07 00:54:17,351:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:54:19,693:INFO:Calculating mean and std
2023-07-07 00:54:19,694:INFO:Creating metrics dataframe
2023-07-07 00:54:19,777:INFO:Uploading results into container
2023-07-07 00:54:19,778:INFO:Uploading model into container now
2023-07-07 00:54:19,778:INFO:_master_model_container: 24
2023-07-07 00:54:19,778:INFO:_display_container: 3
2023-07-07 00:54:19,779:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-07 00:54:19,779:INFO:create_model() successfully completed......................................
2023-07-07 00:54:19,851:INFO:SubProcess create_model() end ==================================
2023-07-07 00:54:19,851:INFO:Creating metrics dataframe
2023-07-07 00:54:19,866:INFO:Initializing Linear Discriminant Analysis
2023-07-07 00:54:19,866:INFO:Total runtime is 0.35703697204589846 minutes
2023-07-07 00:54:19,871:INFO:SubProcess create_model() called ==================================
2023-07-07 00:54:19,872:INFO:Initializing create_model()
2023-07-07 00:54:19,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAC9C1E80>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:54:19,872:INFO:Checking exceptions
2023-07-07 00:54:19,872:INFO:Importing libraries
2023-07-07 00:54:19,873:INFO:Copying training dataset
2023-07-07 00:54:19,881:INFO:Defining folds
2023-07-07 00:54:19,881:INFO:Declaring metric variables
2023-07-07 00:54:19,887:INFO:Importing untrained model
2023-07-07 00:54:19,895:INFO:Linear Discriminant Analysis Imported successfully
2023-07-07 00:54:19,907:INFO:Starting cross validation
2023-07-07 00:54:19,909:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:54:20,774:INFO:Calculating mean and std
2023-07-07 00:54:20,776:INFO:Creating metrics dataframe
2023-07-07 00:54:20,868:INFO:Uploading results into container
2023-07-07 00:54:20,869:INFO:Uploading model into container now
2023-07-07 00:54:20,870:INFO:_master_model_container: 25
2023-07-07 00:54:20,870:INFO:_display_container: 3
2023-07-07 00:54:20,870:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-07 00:54:20,870:INFO:create_model() successfully completed......................................
2023-07-07 00:54:20,943:INFO:SubProcess create_model() end ==================================
2023-07-07 00:54:20,943:INFO:Creating metrics dataframe
2023-07-07 00:54:20,958:INFO:Initializing Extra Trees Classifier
2023-07-07 00:54:20,958:INFO:Total runtime is 0.37524118820826213 minutes
2023-07-07 00:54:20,963:INFO:SubProcess create_model() called ==================================
2023-07-07 00:54:20,964:INFO:Initializing create_model()
2023-07-07 00:54:20,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAC9C1E80>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:54:20,964:INFO:Checking exceptions
2023-07-07 00:54:20,964:INFO:Importing libraries
2023-07-07 00:54:20,965:INFO:Copying training dataset
2023-07-07 00:54:20,975:INFO:Defining folds
2023-07-07 00:54:20,975:INFO:Declaring metric variables
2023-07-07 00:54:20,980:INFO:Importing untrained model
2023-07-07 00:54:20,985:INFO:Extra Trees Classifier Imported successfully
2023-07-07 00:54:20,995:INFO:Starting cross validation
2023-07-07 00:54:20,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:54:23,619:INFO:Calculating mean and std
2023-07-07 00:54:23,621:INFO:Creating metrics dataframe
2023-07-07 00:54:23,707:INFO:Uploading results into container
2023-07-07 00:54:23,708:INFO:Uploading model into container now
2023-07-07 00:54:23,708:INFO:_master_model_container: 26
2023-07-07 00:54:23,708:INFO:_display_container: 3
2023-07-07 00:54:23,709:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-07 00:54:23,709:INFO:create_model() successfully completed......................................
2023-07-07 00:54:23,780:INFO:SubProcess create_model() end ==================================
2023-07-07 00:54:23,780:INFO:Creating metrics dataframe
2023-07-07 00:54:23,794:INFO:Initializing Light Gradient Boosting Machine
2023-07-07 00:54:23,794:INFO:Total runtime is 0.4225013732910156 minutes
2023-07-07 00:54:23,798:INFO:SubProcess create_model() called ==================================
2023-07-07 00:54:23,799:INFO:Initializing create_model()
2023-07-07 00:54:23,799:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAC9C1E80>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:54:23,799:INFO:Checking exceptions
2023-07-07 00:54:23,800:INFO:Importing libraries
2023-07-07 00:54:23,800:INFO:Copying training dataset
2023-07-07 00:54:23,807:INFO:Defining folds
2023-07-07 00:54:23,807:INFO:Declaring metric variables
2023-07-07 00:54:23,814:INFO:Importing untrained model
2023-07-07 00:54:23,820:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-07 00:54:23,833:INFO:Starting cross validation
2023-07-07 00:54:23,835:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:54:27,029:INFO:Calculating mean and std
2023-07-07 00:54:27,031:INFO:Creating metrics dataframe
2023-07-07 00:54:27,134:INFO:Uploading results into container
2023-07-07 00:54:27,134:INFO:Uploading model into container now
2023-07-07 00:54:27,135:INFO:_master_model_container: 27
2023-07-07 00:54:27,135:INFO:_display_container: 3
2023-07-07 00:54:27,136:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-07 00:54:27,136:INFO:create_model() successfully completed......................................
2023-07-07 00:54:27,213:INFO:SubProcess create_model() end ==================================
2023-07-07 00:54:27,213:INFO:Creating metrics dataframe
2023-07-07 00:54:27,228:INFO:Initializing Dummy Classifier
2023-07-07 00:54:27,228:INFO:Total runtime is 0.47973304986953735 minutes
2023-07-07 00:54:27,234:INFO:SubProcess create_model() called ==================================
2023-07-07 00:54:27,235:INFO:Initializing create_model()
2023-07-07 00:54:27,235:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAC9C1E80>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:54:27,235:INFO:Checking exceptions
2023-07-07 00:54:27,235:INFO:Importing libraries
2023-07-07 00:54:27,235:INFO:Copying training dataset
2023-07-07 00:54:27,242:INFO:Defining folds
2023-07-07 00:54:27,242:INFO:Declaring metric variables
2023-07-07 00:54:27,247:INFO:Importing untrained model
2023-07-07 00:54:27,253:INFO:Dummy Classifier Imported successfully
2023-07-07 00:54:27,264:INFO:Starting cross validation
2023-07-07 00:54:27,267:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:54:27,523:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:54:27,540:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:54:27,550:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:54:27,553:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:54:27,572:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:54:27,581:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:54:27,595:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:54:27,605:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:54:27,816:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:54:27,857:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:54:28,265:INFO:Calculating mean and std
2023-07-07 00:54:28,267:INFO:Creating metrics dataframe
2023-07-07 00:54:28,381:INFO:Uploading results into container
2023-07-07 00:54:28,382:INFO:Uploading model into container now
2023-07-07 00:54:28,383:INFO:_master_model_container: 28
2023-07-07 00:54:28,383:INFO:_display_container: 3
2023-07-07 00:54:28,383:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-07 00:54:28,383:INFO:create_model() successfully completed......................................
2023-07-07 00:54:28,475:INFO:SubProcess create_model() end ==================================
2023-07-07 00:54:28,475:INFO:Creating metrics dataframe
2023-07-07 00:54:28,510:INFO:Initializing create_model()
2023-07-07 00:54:28,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:54:28,511:INFO:Checking exceptions
2023-07-07 00:54:28,514:INFO:Importing libraries
2023-07-07 00:54:28,515:INFO:Copying training dataset
2023-07-07 00:54:28,524:INFO:Defining folds
2023-07-07 00:54:28,524:INFO:Declaring metric variables
2023-07-07 00:54:28,525:INFO:Importing untrained model
2023-07-07 00:54:28,525:INFO:Declaring custom model
2023-07-07 00:54:28,526:INFO:Gradient Boosting Classifier Imported successfully
2023-07-07 00:54:28,528:INFO:Cross validation set to False
2023-07-07 00:54:28,529:INFO:Fitting Model
2023-07-07 00:54:28,685:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-07 00:54:28,685:INFO:create_model() successfully completed......................................
2023-07-07 00:54:28,809:INFO:_master_model_container: 28
2023-07-07 00:54:28,809:INFO:_display_container: 3
2023-07-07 00:54:28,810:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-07 00:54:28,810:INFO:compare_models() successfully completed......................................
2023-07-07 00:54:52,909:INFO:Initializing plot_model()
2023-07-07 00:54:52,909:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEACBE3640,
                       splitter='best')                                     ], feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 00:54:52,910:INFO:Checking exceptions
2023-07-07 00:58:23,906:INFO:Initializing compare_models()
2023-07-07 00:58:23,907:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-07 00:58:23,907:INFO:Checking exceptions
2023-07-07 00:58:23,911:INFO:Preparing display monitor
2023-07-07 00:58:23,972:INFO:Initializing Logistic Regression
2023-07-07 00:58:23,973:INFO:Total runtime is 1.641114552815755e-05 minutes
2023-07-07 00:58:23,980:INFO:SubProcess create_model() called ==================================
2023-07-07 00:58:23,981:INFO:Initializing create_model()
2023-07-07 00:58:23,981:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB123BB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:58:23,981:INFO:Checking exceptions
2023-07-07 00:58:23,981:INFO:Importing libraries
2023-07-07 00:58:23,982:INFO:Copying training dataset
2023-07-07 00:58:23,990:INFO:Defining folds
2023-07-07 00:58:23,991:INFO:Declaring metric variables
2023-07-07 00:58:23,995:INFO:Importing untrained model
2023-07-07 00:58:24,002:INFO:Logistic Regression Imported successfully
2023-07-07 00:58:24,015:INFO:Starting cross validation
2023-07-07 00:58:24,018:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:58:25,534:INFO:Calculating mean and std
2023-07-07 00:58:25,536:INFO:Creating metrics dataframe
2023-07-07 00:58:25,665:INFO:Uploading results into container
2023-07-07 00:58:25,666:INFO:Uploading model into container now
2023-07-07 00:58:25,666:INFO:_master_model_container: 29
2023-07-07 00:58:25,667:INFO:_display_container: 4
2023-07-07 00:58:25,668:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-07 00:58:25,668:INFO:create_model() successfully completed......................................
2023-07-07 00:58:25,750:INFO:SubProcess create_model() end ==================================
2023-07-07 00:58:25,750:INFO:Creating metrics dataframe
2023-07-07 00:58:25,761:INFO:Initializing K Neighbors Classifier
2023-07-07 00:58:25,761:INFO:Total runtime is 0.029803387324015298 minutes
2023-07-07 00:58:25,767:INFO:SubProcess create_model() called ==================================
2023-07-07 00:58:25,767:INFO:Initializing create_model()
2023-07-07 00:58:25,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB123BB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:58:25,768:INFO:Checking exceptions
2023-07-07 00:58:25,768:INFO:Importing libraries
2023-07-07 00:58:25,768:INFO:Copying training dataset
2023-07-07 00:58:25,776:INFO:Defining folds
2023-07-07 00:58:25,777:INFO:Declaring metric variables
2023-07-07 00:58:25,782:INFO:Importing untrained model
2023-07-07 00:58:25,788:INFO:K Neighbors Classifier Imported successfully
2023-07-07 00:58:25,803:INFO:Starting cross validation
2023-07-07 00:58:25,805:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:58:26,028:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:58:26,029:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:58:26,074:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:58:26,081:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:58:26,087:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:58:26,090:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:58:26,158:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:58:26,160:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:58:26,473:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:58:26,503:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 00:58:26,956:INFO:Calculating mean and std
2023-07-07 00:58:26,958:INFO:Creating metrics dataframe
2023-07-07 00:58:27,063:INFO:Uploading results into container
2023-07-07 00:58:27,064:INFO:Uploading model into container now
2023-07-07 00:58:27,065:INFO:_master_model_container: 30
2023-07-07 00:58:27,065:INFO:_display_container: 4
2023-07-07 00:58:27,065:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-07 00:58:27,065:INFO:create_model() successfully completed......................................
2023-07-07 00:58:27,141:INFO:SubProcess create_model() end ==================================
2023-07-07 00:58:27,142:INFO:Creating metrics dataframe
2023-07-07 00:58:27,153:INFO:Initializing Naive Bayes
2023-07-07 00:58:27,154:INFO:Total runtime is 0.05301714340845744 minutes
2023-07-07 00:58:27,158:INFO:SubProcess create_model() called ==================================
2023-07-07 00:58:27,158:INFO:Initializing create_model()
2023-07-07 00:58:27,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB123BB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:58:27,159:INFO:Checking exceptions
2023-07-07 00:58:27,159:INFO:Importing libraries
2023-07-07 00:58:27,159:INFO:Copying training dataset
2023-07-07 00:58:27,170:INFO:Defining folds
2023-07-07 00:58:27,170:INFO:Declaring metric variables
2023-07-07 00:58:27,177:INFO:Importing untrained model
2023-07-07 00:58:27,183:INFO:Naive Bayes Imported successfully
2023-07-07 00:58:27,192:INFO:Starting cross validation
2023-07-07 00:58:27,193:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:58:28,161:INFO:Calculating mean and std
2023-07-07 00:58:28,164:INFO:Creating metrics dataframe
2023-07-07 00:58:28,275:INFO:Uploading results into container
2023-07-07 00:58:28,276:INFO:Uploading model into container now
2023-07-07 00:58:28,276:INFO:_master_model_container: 31
2023-07-07 00:58:28,276:INFO:_display_container: 4
2023-07-07 00:58:28,277:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-07 00:58:28,277:INFO:create_model() successfully completed......................................
2023-07-07 00:58:28,352:INFO:SubProcess create_model() end ==================================
2023-07-07 00:58:28,352:INFO:Creating metrics dataframe
2023-07-07 00:58:28,362:INFO:Initializing Decision Tree Classifier
2023-07-07 00:58:28,363:INFO:Total runtime is 0.07317732175191244 minutes
2023-07-07 00:58:28,368:INFO:SubProcess create_model() called ==================================
2023-07-07 00:58:28,369:INFO:Initializing create_model()
2023-07-07 00:58:28,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB123BB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:58:28,369:INFO:Checking exceptions
2023-07-07 00:58:28,369:INFO:Importing libraries
2023-07-07 00:58:28,369:INFO:Copying training dataset
2023-07-07 00:58:28,377:INFO:Defining folds
2023-07-07 00:58:28,378:INFO:Declaring metric variables
2023-07-07 00:58:28,384:INFO:Importing untrained model
2023-07-07 00:58:28,388:INFO:Decision Tree Classifier Imported successfully
2023-07-07 00:58:28,398:INFO:Starting cross validation
2023-07-07 00:58:28,400:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:58:29,300:INFO:Calculating mean and std
2023-07-07 00:58:29,301:INFO:Creating metrics dataframe
2023-07-07 00:58:29,408:INFO:Uploading results into container
2023-07-07 00:58:29,409:INFO:Uploading model into container now
2023-07-07 00:58:29,409:INFO:_master_model_container: 32
2023-07-07 00:58:29,409:INFO:_display_container: 4
2023-07-07 00:58:29,409:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-07 00:58:29,410:INFO:create_model() successfully completed......................................
2023-07-07 00:58:29,483:INFO:SubProcess create_model() end ==================================
2023-07-07 00:58:29,483:INFO:Creating metrics dataframe
2023-07-07 00:58:29,495:INFO:Initializing SVM - Linear Kernel
2023-07-07 00:58:29,496:INFO:Total runtime is 0.09206596215566 minutes
2023-07-07 00:58:29,501:INFO:SubProcess create_model() called ==================================
2023-07-07 00:58:29,501:INFO:Initializing create_model()
2023-07-07 00:58:29,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB123BB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:58:29,502:INFO:Checking exceptions
2023-07-07 00:58:29,502:INFO:Importing libraries
2023-07-07 00:58:29,502:INFO:Copying training dataset
2023-07-07 00:58:29,511:INFO:Defining folds
2023-07-07 00:58:29,512:INFO:Declaring metric variables
2023-07-07 00:58:29,517:INFO:Importing untrained model
2023-07-07 00:58:29,524:INFO:SVM - Linear Kernel Imported successfully
2023-07-07 00:58:29,535:INFO:Starting cross validation
2023-07-07 00:58:29,537:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:58:29,767:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:58:29,826:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:58:29,833:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:58:29,855:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:58:29,883:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:58:29,950:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:58:29,980:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:58:29,987:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:58:30,378:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:58:30,493:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 00:58:30,840:INFO:Calculating mean and std
2023-07-07 00:58:30,841:INFO:Creating metrics dataframe
2023-07-07 00:58:30,964:INFO:Uploading results into container
2023-07-07 00:58:30,964:INFO:Uploading model into container now
2023-07-07 00:58:30,965:INFO:_master_model_container: 33
2023-07-07 00:58:30,965:INFO:_display_container: 4
2023-07-07 00:58:30,966:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-07 00:58:30,967:INFO:create_model() successfully completed......................................
2023-07-07 00:58:31,049:INFO:SubProcess create_model() end ==================================
2023-07-07 00:58:31,049:INFO:Creating metrics dataframe
2023-07-07 00:58:31,060:INFO:Initializing Ridge Classifier
2023-07-07 00:58:31,061:INFO:Total runtime is 0.11815020640691122 minutes
2023-07-07 00:58:31,065:INFO:SubProcess create_model() called ==================================
2023-07-07 00:58:31,066:INFO:Initializing create_model()
2023-07-07 00:58:31,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB123BB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:58:31,066:INFO:Checking exceptions
2023-07-07 00:58:31,066:INFO:Importing libraries
2023-07-07 00:58:31,066:INFO:Copying training dataset
2023-07-07 00:58:31,075:INFO:Defining folds
2023-07-07 00:58:31,075:INFO:Declaring metric variables
2023-07-07 00:58:31,081:INFO:Importing untrained model
2023-07-07 00:58:31,089:INFO:Ridge Classifier Imported successfully
2023-07-07 00:58:31,098:INFO:Starting cross validation
2023-07-07 00:58:31,100:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:58:31,245:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:58:31,273:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:58:31,294:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:58:31,351:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:58:31,353:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:58:31,357:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:58:31,367:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:58:31,382:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:58:31,543:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:58:31,597:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 00:58:32,030:INFO:Calculating mean and std
2023-07-07 00:58:32,032:INFO:Creating metrics dataframe
2023-07-07 00:58:32,139:INFO:Uploading results into container
2023-07-07 00:58:32,139:INFO:Uploading model into container now
2023-07-07 00:58:32,140:INFO:_master_model_container: 34
2023-07-07 00:58:32,140:INFO:_display_container: 4
2023-07-07 00:58:32,141:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=42, solver='auto', tol=0.001)
2023-07-07 00:58:32,141:INFO:create_model() successfully completed......................................
2023-07-07 00:58:32,213:INFO:SubProcess create_model() end ==================================
2023-07-07 00:58:32,213:INFO:Creating metrics dataframe
2023-07-07 00:58:32,227:INFO:Initializing Random Forest Classifier
2023-07-07 00:58:32,227:INFO:Total runtime is 0.13757426738739015 minutes
2023-07-07 00:58:32,232:INFO:SubProcess create_model() called ==================================
2023-07-07 00:58:32,233:INFO:Initializing create_model()
2023-07-07 00:58:32,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB123BB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:58:32,233:INFO:Checking exceptions
2023-07-07 00:58:32,234:INFO:Importing libraries
2023-07-07 00:58:32,234:INFO:Copying training dataset
2023-07-07 00:58:32,241:INFO:Defining folds
2023-07-07 00:58:32,241:INFO:Declaring metric variables
2023-07-07 00:58:32,245:INFO:Importing untrained model
2023-07-07 00:58:32,250:INFO:Random Forest Classifier Imported successfully
2023-07-07 00:58:32,260:INFO:Starting cross validation
2023-07-07 00:58:32,262:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:58:34,695:INFO:Calculating mean and std
2023-07-07 00:58:34,696:INFO:Creating metrics dataframe
2023-07-07 00:58:34,816:INFO:Uploading results into container
2023-07-07 00:58:34,817:INFO:Uploading model into container now
2023-07-07 00:58:34,818:INFO:_master_model_container: 35
2023-07-07 00:58:34,818:INFO:_display_container: 4
2023-07-07 00:58:34,818:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-07 00:58:34,818:INFO:create_model() successfully completed......................................
2023-07-07 00:58:34,893:INFO:SubProcess create_model() end ==================================
2023-07-07 00:58:34,894:INFO:Creating metrics dataframe
2023-07-07 00:58:34,913:INFO:Initializing Quadratic Discriminant Analysis
2023-07-07 00:58:34,913:INFO:Total runtime is 0.18233451445897422 minutes
2023-07-07 00:58:34,917:INFO:SubProcess create_model() called ==================================
2023-07-07 00:58:34,918:INFO:Initializing create_model()
2023-07-07 00:58:34,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB123BB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:58:34,918:INFO:Checking exceptions
2023-07-07 00:58:34,918:INFO:Importing libraries
2023-07-07 00:58:34,919:INFO:Copying training dataset
2023-07-07 00:58:34,925:INFO:Defining folds
2023-07-07 00:58:34,926:INFO:Declaring metric variables
2023-07-07 00:58:34,932:INFO:Importing untrained model
2023-07-07 00:58:34,936:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-07 00:58:34,946:INFO:Starting cross validation
2023-07-07 00:58:34,948:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:58:35,060:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:58:35,091:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:58:35,103:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:58:35,140:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:58:35,142:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:58:35,146:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:58:35,167:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:58:35,189:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:58:35,250:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:58:35,302:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:58:35,455:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:58:35,476:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 00:58:35,516:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:58:35,973:INFO:Calculating mean and std
2023-07-07 00:58:35,974:INFO:Creating metrics dataframe
2023-07-07 00:58:36,091:INFO:Uploading results into container
2023-07-07 00:58:36,092:INFO:Uploading model into container now
2023-07-07 00:58:36,092:INFO:_master_model_container: 36
2023-07-07 00:58:36,092:INFO:_display_container: 4
2023-07-07 00:58:36,092:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-07 00:58:36,093:INFO:create_model() successfully completed......................................
2023-07-07 00:58:36,167:INFO:SubProcess create_model() end ==================================
2023-07-07 00:58:36,167:INFO:Creating metrics dataframe
2023-07-07 00:58:36,182:INFO:Initializing Ada Boost Classifier
2023-07-07 00:58:36,182:INFO:Total runtime is 0.20349895954132083 minutes
2023-07-07 00:58:36,186:INFO:SubProcess create_model() called ==================================
2023-07-07 00:58:36,186:INFO:Initializing create_model()
2023-07-07 00:58:36,187:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB123BB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:58:36,187:INFO:Checking exceptions
2023-07-07 00:58:36,187:INFO:Importing libraries
2023-07-07 00:58:36,187:INFO:Copying training dataset
2023-07-07 00:58:36,196:INFO:Defining folds
2023-07-07 00:58:36,196:INFO:Declaring metric variables
2023-07-07 00:58:36,207:INFO:Importing untrained model
2023-07-07 00:58:36,220:INFO:Ada Boost Classifier Imported successfully
2023-07-07 00:58:36,239:INFO:Starting cross validation
2023-07-07 00:58:36,240:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:58:37,850:INFO:Calculating mean and std
2023-07-07 00:58:37,852:INFO:Creating metrics dataframe
2023-07-07 00:58:37,983:INFO:Uploading results into container
2023-07-07 00:58:37,983:INFO:Uploading model into container now
2023-07-07 00:58:37,984:INFO:_master_model_container: 37
2023-07-07 00:58:37,984:INFO:_display_container: 4
2023-07-07 00:58:37,984:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2023-07-07 00:58:37,984:INFO:create_model() successfully completed......................................
2023-07-07 00:58:38,057:INFO:SubProcess create_model() end ==================================
2023-07-07 00:58:38,057:INFO:Creating metrics dataframe
2023-07-07 00:58:38,071:INFO:Initializing Gradient Boosting Classifier
2023-07-07 00:58:38,071:INFO:Total runtime is 0.2349690357844035 minutes
2023-07-07 00:58:38,076:INFO:SubProcess create_model() called ==================================
2023-07-07 00:58:38,077:INFO:Initializing create_model()
2023-07-07 00:58:38,077:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB123BB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:58:38,077:INFO:Checking exceptions
2023-07-07 00:58:38,078:INFO:Importing libraries
2023-07-07 00:58:38,078:INFO:Copying training dataset
2023-07-07 00:58:38,084:INFO:Defining folds
2023-07-07 00:58:38,084:INFO:Declaring metric variables
2023-07-07 00:58:38,091:INFO:Importing untrained model
2023-07-07 00:58:38,096:INFO:Gradient Boosting Classifier Imported successfully
2023-07-07 00:58:38,107:INFO:Starting cross validation
2023-07-07 00:58:38,110:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:58:40,319:INFO:Calculating mean and std
2023-07-07 00:58:40,321:INFO:Creating metrics dataframe
2023-07-07 00:58:40,455:INFO:Uploading results into container
2023-07-07 00:58:40,456:INFO:Uploading model into container now
2023-07-07 00:58:40,457:INFO:_master_model_container: 38
2023-07-07 00:58:40,457:INFO:_display_container: 4
2023-07-07 00:58:40,458:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-07 00:58:40,458:INFO:create_model() successfully completed......................................
2023-07-07 00:58:40,541:INFO:SubProcess create_model() end ==================================
2023-07-07 00:58:40,541:INFO:Creating metrics dataframe
2023-07-07 00:58:40,555:INFO:Initializing Linear Discriminant Analysis
2023-07-07 00:58:40,555:INFO:Total runtime is 0.27637005249659224 minutes
2023-07-07 00:58:40,561:INFO:SubProcess create_model() called ==================================
2023-07-07 00:58:40,561:INFO:Initializing create_model()
2023-07-07 00:58:40,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB123BB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:58:40,562:INFO:Checking exceptions
2023-07-07 00:58:40,562:INFO:Importing libraries
2023-07-07 00:58:40,562:INFO:Copying training dataset
2023-07-07 00:58:40,571:INFO:Defining folds
2023-07-07 00:58:40,571:INFO:Declaring metric variables
2023-07-07 00:58:40,579:INFO:Importing untrained model
2023-07-07 00:58:40,585:INFO:Linear Discriminant Analysis Imported successfully
2023-07-07 00:58:40,598:INFO:Starting cross validation
2023-07-07 00:58:40,601:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:58:41,778:INFO:Calculating mean and std
2023-07-07 00:58:41,780:INFO:Creating metrics dataframe
2023-07-07 00:58:41,917:INFO:Uploading results into container
2023-07-07 00:58:41,918:INFO:Uploading model into container now
2023-07-07 00:58:41,918:INFO:_master_model_container: 39
2023-07-07 00:58:41,918:INFO:_display_container: 4
2023-07-07 00:58:41,918:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-07 00:58:41,919:INFO:create_model() successfully completed......................................
2023-07-07 00:58:41,995:INFO:SubProcess create_model() end ==================================
2023-07-07 00:58:41,995:INFO:Creating metrics dataframe
2023-07-07 00:58:42,008:INFO:Initializing Extra Trees Classifier
2023-07-07 00:58:42,008:INFO:Total runtime is 0.30058574279149375 minutes
2023-07-07 00:58:42,012:INFO:SubProcess create_model() called ==================================
2023-07-07 00:58:42,013:INFO:Initializing create_model()
2023-07-07 00:58:42,013:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB123BB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:58:42,013:INFO:Checking exceptions
2023-07-07 00:58:42,013:INFO:Importing libraries
2023-07-07 00:58:42,014:INFO:Copying training dataset
2023-07-07 00:58:42,021:INFO:Defining folds
2023-07-07 00:58:42,021:INFO:Declaring metric variables
2023-07-07 00:58:42,026:INFO:Importing untrained model
2023-07-07 00:58:42,032:INFO:Extra Trees Classifier Imported successfully
2023-07-07 00:58:42,044:INFO:Starting cross validation
2023-07-07 00:58:42,046:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:58:44,729:INFO:Calculating mean and std
2023-07-07 00:58:44,730:INFO:Creating metrics dataframe
2023-07-07 00:58:44,859:INFO:Uploading results into container
2023-07-07 00:58:44,860:INFO:Uploading model into container now
2023-07-07 00:58:44,860:INFO:_master_model_container: 40
2023-07-07 00:58:44,861:INFO:_display_container: 4
2023-07-07 00:58:44,861:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-07 00:58:44,861:INFO:create_model() successfully completed......................................
2023-07-07 00:58:44,941:INFO:SubProcess create_model() end ==================================
2023-07-07 00:58:44,941:INFO:Creating metrics dataframe
2023-07-07 00:58:44,954:INFO:Initializing Light Gradient Boosting Machine
2023-07-07 00:58:44,955:INFO:Total runtime is 0.34970343907674156 minutes
2023-07-07 00:58:44,960:INFO:SubProcess create_model() called ==================================
2023-07-07 00:58:44,960:INFO:Initializing create_model()
2023-07-07 00:58:44,960:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB123BB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:58:44,961:INFO:Checking exceptions
2023-07-07 00:58:44,961:INFO:Importing libraries
2023-07-07 00:58:44,961:INFO:Copying training dataset
2023-07-07 00:58:44,968:INFO:Defining folds
2023-07-07 00:58:44,968:INFO:Declaring metric variables
2023-07-07 00:58:44,973:INFO:Importing untrained model
2023-07-07 00:58:44,982:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-07 00:58:44,994:INFO:Starting cross validation
2023-07-07 00:58:44,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:58:46,470:INFO:Calculating mean and std
2023-07-07 00:58:46,472:INFO:Creating metrics dataframe
2023-07-07 00:58:46,639:INFO:Uploading results into container
2023-07-07 00:58:46,640:INFO:Uploading model into container now
2023-07-07 00:58:46,641:INFO:_master_model_container: 41
2023-07-07 00:58:46,641:INFO:_display_container: 4
2023-07-07 00:58:46,642:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-07 00:58:46,642:INFO:create_model() successfully completed......................................
2023-07-07 00:58:46,722:INFO:SubProcess create_model() end ==================================
2023-07-07 00:58:46,722:INFO:Creating metrics dataframe
2023-07-07 00:58:46,736:INFO:Initializing Dummy Classifier
2023-07-07 00:58:46,736:INFO:Total runtime is 0.37938913106918337 minutes
2023-07-07 00:58:46,741:INFO:SubProcess create_model() called ==================================
2023-07-07 00:58:46,741:INFO:Initializing create_model()
2023-07-07 00:58:46,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB123BB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:58:46,741:INFO:Checking exceptions
2023-07-07 00:58:46,742:INFO:Importing libraries
2023-07-07 00:58:46,742:INFO:Copying training dataset
2023-07-07 00:58:46,750:INFO:Defining folds
2023-07-07 00:58:46,751:INFO:Declaring metric variables
2023-07-07 00:58:46,756:INFO:Importing untrained model
2023-07-07 00:58:46,761:INFO:Dummy Classifier Imported successfully
2023-07-07 00:58:46,772:INFO:Starting cross validation
2023-07-07 00:58:46,773:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 00:58:46,959:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:58:46,997:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:58:47,010:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:58:47,012:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:58:47,049:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:58:47,060:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:58:47,069:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:58:47,080:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:58:47,323:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:58:47,328:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 00:58:48,003:INFO:Calculating mean and std
2023-07-07 00:58:48,005:INFO:Creating metrics dataframe
2023-07-07 00:58:48,150:INFO:Uploading results into container
2023-07-07 00:58:48,151:INFO:Uploading model into container now
2023-07-07 00:58:48,152:INFO:_master_model_container: 42
2023-07-07 00:58:48,152:INFO:_display_container: 4
2023-07-07 00:58:48,152:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-07 00:58:48,152:INFO:create_model() successfully completed......................................
2023-07-07 00:58:48,226:INFO:SubProcess create_model() end ==================================
2023-07-07 00:58:48,226:INFO:Creating metrics dataframe
2023-07-07 00:58:48,250:INFO:Initializing create_model()
2023-07-07 00:58:48,251:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-07 00:58:48,251:INFO:Checking exceptions
2023-07-07 00:58:48,253:INFO:Importing libraries
2023-07-07 00:58:48,253:INFO:Copying training dataset
2023-07-07 00:58:48,259:INFO:Defining folds
2023-07-07 00:58:48,259:INFO:Declaring metric variables
2023-07-07 00:58:48,259:INFO:Importing untrained model
2023-07-07 00:58:48,259:INFO:Declaring custom model
2023-07-07 00:58:48,260:INFO:Gradient Boosting Classifier Imported successfully
2023-07-07 00:58:48,262:INFO:Cross validation set to False
2023-07-07 00:58:48,262:INFO:Fitting Model
2023-07-07 00:58:48,473:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-07 00:58:48,474:INFO:create_model() successfully completed......................................
2023-07-07 00:58:48,591:INFO:_master_model_container: 42
2023-07-07 00:58:48,591:INFO:_display_container: 4
2023-07-07 00:58:48,592:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-07 00:58:48,592:INFO:compare_models() successfully completed......................................
2023-07-07 01:00:29,299:INFO:Initializing compare_models()
2023-07-07 01:00:29,299:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-07 01:00:29,299:INFO:Checking exceptions
2023-07-07 01:00:29,304:INFO:Preparing display monitor
2023-07-07 01:00:29,352:INFO:Initializing Logistic Regression
2023-07-07 01:00:29,353:INFO:Total runtime is 1.6427040100097658e-05 minutes
2023-07-07 01:00:29,357:INFO:SubProcess create_model() called ==================================
2023-07-07 01:00:29,358:INFO:Initializing create_model()
2023-07-07 01:00:29,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB41C850>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 01:00:29,358:INFO:Checking exceptions
2023-07-07 01:00:29,358:INFO:Importing libraries
2023-07-07 01:00:29,358:INFO:Copying training dataset
2023-07-07 01:00:29,367:INFO:Defining folds
2023-07-07 01:00:29,367:INFO:Declaring metric variables
2023-07-07 01:00:29,372:INFO:Importing untrained model
2023-07-07 01:00:29,377:INFO:Logistic Regression Imported successfully
2023-07-07 01:00:29,387:INFO:Starting cross validation
2023-07-07 01:00:29,388:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 01:00:31,221:INFO:Calculating mean and std
2023-07-07 01:00:31,223:INFO:Creating metrics dataframe
2023-07-07 01:00:31,368:INFO:Uploading results into container
2023-07-07 01:00:31,369:INFO:Uploading model into container now
2023-07-07 01:00:31,370:INFO:_master_model_container: 43
2023-07-07 01:00:31,370:INFO:_display_container: 5
2023-07-07 01:00:31,370:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-07 01:00:31,370:INFO:create_model() successfully completed......................................
2023-07-07 01:00:31,450:INFO:SubProcess create_model() end ==================================
2023-07-07 01:00:31,450:INFO:Creating metrics dataframe
2023-07-07 01:00:31,460:INFO:Initializing K Neighbors Classifier
2023-07-07 01:00:31,460:INFO:Total runtime is 0.03512062231699625 minutes
2023-07-07 01:00:31,464:INFO:SubProcess create_model() called ==================================
2023-07-07 01:00:31,465:INFO:Initializing create_model()
2023-07-07 01:00:31,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB41C850>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 01:00:31,465:INFO:Checking exceptions
2023-07-07 01:00:31,465:INFO:Importing libraries
2023-07-07 01:00:31,465:INFO:Copying training dataset
2023-07-07 01:00:31,472:INFO:Defining folds
2023-07-07 01:00:31,473:INFO:Declaring metric variables
2023-07-07 01:00:31,479:INFO:Importing untrained model
2023-07-07 01:00:31,485:INFO:K Neighbors Classifier Imported successfully
2023-07-07 01:00:31,497:INFO:Starting cross validation
2023-07-07 01:00:31,499:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 01:00:31,739:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 01:00:31,752:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 01:00:31,764:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 01:00:31,764:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 01:00:31,777:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 01:00:31,787:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 01:00:31,804:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 01:00:31,838:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 01:00:32,226:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 01:00:32,238:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-07 01:00:32,978:INFO:Calculating mean and std
2023-07-07 01:00:32,981:INFO:Creating metrics dataframe
2023-07-07 01:00:33,136:INFO:Uploading results into container
2023-07-07 01:00:33,137:INFO:Uploading model into container now
2023-07-07 01:00:33,137:INFO:_master_model_container: 44
2023-07-07 01:00:33,137:INFO:_display_container: 5
2023-07-07 01:00:33,138:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-07 01:00:33,138:INFO:create_model() successfully completed......................................
2023-07-07 01:00:33,221:INFO:SubProcess create_model() end ==================================
2023-07-07 01:00:33,222:INFO:Creating metrics dataframe
2023-07-07 01:00:33,234:INFO:Initializing Naive Bayes
2023-07-07 01:00:33,235:INFO:Total runtime is 0.06468443870544432 minutes
2023-07-07 01:00:33,239:INFO:SubProcess create_model() called ==================================
2023-07-07 01:00:33,240:INFO:Initializing create_model()
2023-07-07 01:00:33,240:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB41C850>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 01:00:33,240:INFO:Checking exceptions
2023-07-07 01:00:33,240:INFO:Importing libraries
2023-07-07 01:00:33,241:INFO:Copying training dataset
2023-07-07 01:00:33,250:INFO:Defining folds
2023-07-07 01:00:33,251:INFO:Declaring metric variables
2023-07-07 01:00:33,257:INFO:Importing untrained model
2023-07-07 01:00:33,263:INFO:Naive Bayes Imported successfully
2023-07-07 01:00:33,274:INFO:Starting cross validation
2023-07-07 01:00:33,276:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 01:00:34,587:INFO:Calculating mean and std
2023-07-07 01:00:34,589:INFO:Creating metrics dataframe
2023-07-07 01:00:34,756:INFO:Uploading results into container
2023-07-07 01:00:34,756:INFO:Uploading model into container now
2023-07-07 01:00:34,757:INFO:_master_model_container: 45
2023-07-07 01:00:34,757:INFO:_display_container: 5
2023-07-07 01:00:34,757:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-07 01:00:34,758:INFO:create_model() successfully completed......................................
2023-07-07 01:00:34,841:INFO:SubProcess create_model() end ==================================
2023-07-07 01:00:34,842:INFO:Creating metrics dataframe
2023-07-07 01:00:34,854:INFO:Initializing Decision Tree Classifier
2023-07-07 01:00:34,854:INFO:Total runtime is 0.09168986479441324 minutes
2023-07-07 01:00:34,860:INFO:SubProcess create_model() called ==================================
2023-07-07 01:00:34,861:INFO:Initializing create_model()
2023-07-07 01:00:34,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB41C850>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 01:00:34,861:INFO:Checking exceptions
2023-07-07 01:00:34,861:INFO:Importing libraries
2023-07-07 01:00:34,862:INFO:Copying training dataset
2023-07-07 01:00:34,871:INFO:Defining folds
2023-07-07 01:00:34,871:INFO:Declaring metric variables
2023-07-07 01:00:34,878:INFO:Importing untrained model
2023-07-07 01:00:34,885:INFO:Decision Tree Classifier Imported successfully
2023-07-07 01:00:34,895:INFO:Starting cross validation
2023-07-07 01:00:34,898:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 01:00:36,423:INFO:Calculating mean and std
2023-07-07 01:00:36,425:INFO:Creating metrics dataframe
2023-07-07 01:00:36,581:INFO:Uploading results into container
2023-07-07 01:00:36,581:INFO:Uploading model into container now
2023-07-07 01:00:36,582:INFO:_master_model_container: 46
2023-07-07 01:00:36,582:INFO:_display_container: 5
2023-07-07 01:00:36,583:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-07 01:00:36,583:INFO:create_model() successfully completed......................................
2023-07-07 01:00:36,665:INFO:SubProcess create_model() end ==================================
2023-07-07 01:00:36,665:INFO:Creating metrics dataframe
2023-07-07 01:00:36,678:INFO:Initializing SVM - Linear Kernel
2023-07-07 01:00:36,678:INFO:Total runtime is 0.12208515803019204 minutes
2023-07-07 01:00:36,684:INFO:SubProcess create_model() called ==================================
2023-07-07 01:00:36,685:INFO:Initializing create_model()
2023-07-07 01:00:36,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB41C850>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 01:00:36,685:INFO:Checking exceptions
2023-07-07 01:00:36,685:INFO:Importing libraries
2023-07-07 01:00:36,685:INFO:Copying training dataset
2023-07-07 01:00:36,696:INFO:Defining folds
2023-07-07 01:00:36,696:INFO:Declaring metric variables
2023-07-07 01:00:36,702:INFO:Importing untrained model
2023-07-07 01:00:36,708:INFO:SVM - Linear Kernel Imported successfully
2023-07-07 01:00:36,719:INFO:Starting cross validation
2023-07-07 01:00:36,722:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 01:00:36,953:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 01:00:36,972:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 01:00:37,014:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 01:00:37,020:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 01:00:37,027:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 01:00:37,049:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 01:00:37,083:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 01:00:37,092:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 01:00:37,315:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 01:00:37,368:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-07 01:00:37,951:INFO:Calculating mean and std
2023-07-07 01:00:37,953:INFO:Creating metrics dataframe
2023-07-07 01:00:38,107:INFO:Uploading results into container
2023-07-07 01:00:38,108:INFO:Uploading model into container now
2023-07-07 01:00:38,108:INFO:_master_model_container: 47
2023-07-07 01:00:38,108:INFO:_display_container: 5
2023-07-07 01:00:38,109:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-07 01:00:38,109:INFO:create_model() successfully completed......................................
2023-07-07 01:00:38,185:INFO:SubProcess create_model() end ==================================
2023-07-07 01:00:38,185:INFO:Creating metrics dataframe
2023-07-07 01:00:38,196:INFO:Initializing Ridge Classifier
2023-07-07 01:00:38,196:INFO:Total runtime is 0.14739549160003662 minutes
2023-07-07 01:00:38,200:INFO:SubProcess create_model() called ==================================
2023-07-07 01:00:38,200:INFO:Initializing create_model()
2023-07-07 01:00:38,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB41C850>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 01:00:38,201:INFO:Checking exceptions
2023-07-07 01:00:38,201:INFO:Importing libraries
2023-07-07 01:00:38,201:INFO:Copying training dataset
2023-07-07 01:00:38,208:INFO:Defining folds
2023-07-07 01:00:38,208:INFO:Declaring metric variables
2023-07-07 01:00:38,214:INFO:Importing untrained model
2023-07-07 01:00:38,220:INFO:Ridge Classifier Imported successfully
2023-07-07 01:00:38,230:INFO:Starting cross validation
2023-07-07 01:00:38,232:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 01:00:38,371:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 01:00:38,395:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 01:00:38,429:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 01:00:38,436:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 01:00:38,455:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 01:00:38,457:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 01:00:38,486:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 01:00:38,497:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 01:00:38,709:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 01:00:38,729:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-07 01:00:39,374:INFO:Calculating mean and std
2023-07-07 01:00:39,376:INFO:Creating metrics dataframe
2023-07-07 01:00:39,532:INFO:Uploading results into container
2023-07-07 01:00:39,533:INFO:Uploading model into container now
2023-07-07 01:00:39,534:INFO:_master_model_container: 48
2023-07-07 01:00:39,534:INFO:_display_container: 5
2023-07-07 01:00:39,534:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=42, solver='auto', tol=0.001)
2023-07-07 01:00:39,535:INFO:create_model() successfully completed......................................
2023-07-07 01:00:39,609:INFO:SubProcess create_model() end ==================================
2023-07-07 01:00:39,609:INFO:Creating metrics dataframe
2023-07-07 01:00:39,624:INFO:Initializing Random Forest Classifier
2023-07-07 01:00:39,624:INFO:Total runtime is 0.17119173208872476 minutes
2023-07-07 01:00:39,629:INFO:SubProcess create_model() called ==================================
2023-07-07 01:00:39,629:INFO:Initializing create_model()
2023-07-07 01:00:39,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB41C850>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 01:00:39,630:INFO:Checking exceptions
2023-07-07 01:00:39,630:INFO:Importing libraries
2023-07-07 01:00:39,630:INFO:Copying training dataset
2023-07-07 01:00:39,639:INFO:Defining folds
2023-07-07 01:00:39,639:INFO:Declaring metric variables
2023-07-07 01:00:39,645:INFO:Importing untrained model
2023-07-07 01:00:39,651:INFO:Random Forest Classifier Imported successfully
2023-07-07 01:00:39,662:INFO:Starting cross validation
2023-07-07 01:00:39,663:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 01:00:42,135:INFO:Calculating mean and std
2023-07-07 01:00:42,137:INFO:Creating metrics dataframe
2023-07-07 01:00:42,290:INFO:Uploading results into container
2023-07-07 01:00:42,291:INFO:Uploading model into container now
2023-07-07 01:00:42,292:INFO:_master_model_container: 49
2023-07-07 01:00:42,292:INFO:_display_container: 5
2023-07-07 01:00:42,292:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-07 01:00:42,292:INFO:create_model() successfully completed......................................
2023-07-07 01:00:42,366:INFO:SubProcess create_model() end ==================================
2023-07-07 01:00:42,366:INFO:Creating metrics dataframe
2023-07-07 01:00:42,379:INFO:Initializing Quadratic Discriminant Analysis
2023-07-07 01:00:42,379:INFO:Total runtime is 0.21711004972457884 minutes
2023-07-07 01:00:42,383:INFO:SubProcess create_model() called ==================================
2023-07-07 01:00:42,383:INFO:Initializing create_model()
2023-07-07 01:00:42,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB41C850>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 01:00:42,384:INFO:Checking exceptions
2023-07-07 01:00:42,384:INFO:Importing libraries
2023-07-07 01:00:42,384:INFO:Copying training dataset
2023-07-07 01:00:42,389:INFO:Defining folds
2023-07-07 01:00:42,390:INFO:Declaring metric variables
2023-07-07 01:00:42,393:INFO:Importing untrained model
2023-07-07 01:00:42,398:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-07 01:00:42,411:INFO:Starting cross validation
2023-07-07 01:00:42,414:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 01:00:42,528:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 01:00:42,561:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 01:00:42,568:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 01:00:42,595:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 01:00:42,599:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 01:00:42,600:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 01:00:42,600:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 01:00:42,615:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 01:00:42,704:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 01:00:42,727:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 01:00:42,924:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 01:00:42,939:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-07 01:00:42,984:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 01:00:43,656:INFO:Calculating mean and std
2023-07-07 01:00:43,658:INFO:Creating metrics dataframe
2023-07-07 01:00:43,820:INFO:Uploading results into container
2023-07-07 01:00:43,821:INFO:Uploading model into container now
2023-07-07 01:00:43,821:INFO:_master_model_container: 50
2023-07-07 01:00:43,821:INFO:_display_container: 5
2023-07-07 01:00:43,821:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-07 01:00:43,821:INFO:create_model() successfully completed......................................
2023-07-07 01:00:43,894:INFO:SubProcess create_model() end ==================================
2023-07-07 01:00:43,894:INFO:Creating metrics dataframe
2023-07-07 01:00:43,909:INFO:Initializing Ada Boost Classifier
2023-07-07 01:00:43,909:INFO:Total runtime is 0.24260117610295612 minutes
2023-07-07 01:00:43,913:INFO:SubProcess create_model() called ==================================
2023-07-07 01:00:43,913:INFO:Initializing create_model()
2023-07-07 01:00:43,913:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB41C850>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 01:00:43,913:INFO:Checking exceptions
2023-07-07 01:00:43,913:INFO:Importing libraries
2023-07-07 01:00:43,913:INFO:Copying training dataset
2023-07-07 01:00:43,921:INFO:Defining folds
2023-07-07 01:00:43,921:INFO:Declaring metric variables
2023-07-07 01:00:43,927:INFO:Importing untrained model
2023-07-07 01:00:43,932:INFO:Ada Boost Classifier Imported successfully
2023-07-07 01:00:43,942:INFO:Starting cross validation
2023-07-07 01:00:43,943:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 01:00:45,727:INFO:Calculating mean and std
2023-07-07 01:00:45,729:INFO:Creating metrics dataframe
2023-07-07 01:00:45,892:INFO:Uploading results into container
2023-07-07 01:00:45,893:INFO:Uploading model into container now
2023-07-07 01:00:45,893:INFO:_master_model_container: 51
2023-07-07 01:00:45,893:INFO:_display_container: 5
2023-07-07 01:00:45,894:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2023-07-07 01:00:45,894:INFO:create_model() successfully completed......................................
2023-07-07 01:00:45,967:INFO:SubProcess create_model() end ==================================
2023-07-07 01:00:45,968:INFO:Creating metrics dataframe
2023-07-07 01:00:45,981:INFO:Initializing Gradient Boosting Classifier
2023-07-07 01:00:45,982:INFO:Total runtime is 0.2771574298540751 minutes
2023-07-07 01:00:45,986:INFO:SubProcess create_model() called ==================================
2023-07-07 01:00:45,987:INFO:Initializing create_model()
2023-07-07 01:00:45,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB41C850>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 01:00:45,987:INFO:Checking exceptions
2023-07-07 01:00:45,987:INFO:Importing libraries
2023-07-07 01:00:45,987:INFO:Copying training dataset
2023-07-07 01:00:45,994:INFO:Defining folds
2023-07-07 01:00:45,994:INFO:Declaring metric variables
2023-07-07 01:00:46,002:INFO:Importing untrained model
2023-07-07 01:00:46,009:INFO:Gradient Boosting Classifier Imported successfully
2023-07-07 01:00:46,017:INFO:Starting cross validation
2023-07-07 01:00:46,019:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 01:00:48,264:INFO:Calculating mean and std
2023-07-07 01:00:48,266:INFO:Creating metrics dataframe
2023-07-07 01:00:48,444:INFO:Uploading results into container
2023-07-07 01:00:48,445:INFO:Uploading model into container now
2023-07-07 01:00:48,446:INFO:_master_model_container: 52
2023-07-07 01:00:48,446:INFO:_display_container: 5
2023-07-07 01:00:48,446:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-07 01:00:48,447:INFO:create_model() successfully completed......................................
2023-07-07 01:00:48,537:INFO:SubProcess create_model() end ==================================
2023-07-07 01:00:48,537:INFO:Creating metrics dataframe
2023-07-07 01:00:48,555:INFO:Initializing Linear Discriminant Analysis
2023-07-07 01:00:48,556:INFO:Total runtime is 0.32005960543950396 minutes
2023-07-07 01:00:48,562:INFO:SubProcess create_model() called ==================================
2023-07-07 01:00:48,562:INFO:Initializing create_model()
2023-07-07 01:00:48,562:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB41C850>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 01:00:48,563:INFO:Checking exceptions
2023-07-07 01:00:48,563:INFO:Importing libraries
2023-07-07 01:00:48,563:INFO:Copying training dataset
2023-07-07 01:00:48,572:INFO:Defining folds
2023-07-07 01:00:48,573:INFO:Declaring metric variables
2023-07-07 01:00:48,580:INFO:Importing untrained model
2023-07-07 01:00:48,587:INFO:Linear Discriminant Analysis Imported successfully
2023-07-07 01:00:48,598:INFO:Starting cross validation
2023-07-07 01:00:48,600:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 01:00:50,030:INFO:Calculating mean and std
2023-07-07 01:00:50,031:INFO:Creating metrics dataframe
2023-07-07 01:00:50,213:INFO:Uploading results into container
2023-07-07 01:00:50,214:INFO:Uploading model into container now
2023-07-07 01:00:50,215:INFO:_master_model_container: 53
2023-07-07 01:00:50,215:INFO:_display_container: 5
2023-07-07 01:00:50,216:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-07 01:00:50,216:INFO:create_model() successfully completed......................................
2023-07-07 01:00:50,294:INFO:SubProcess create_model() end ==================================
2023-07-07 01:00:50,294:INFO:Creating metrics dataframe
2023-07-07 01:00:50,307:INFO:Initializing Extra Trees Classifier
2023-07-07 01:00:50,307:INFO:Total runtime is 0.3492435574531555 minutes
2023-07-07 01:00:50,312:INFO:SubProcess create_model() called ==================================
2023-07-07 01:00:50,312:INFO:Initializing create_model()
2023-07-07 01:00:50,313:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB41C850>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 01:00:50,313:INFO:Checking exceptions
2023-07-07 01:00:50,313:INFO:Importing libraries
2023-07-07 01:00:50,313:INFO:Copying training dataset
2023-07-07 01:00:50,320:INFO:Defining folds
2023-07-07 01:00:50,320:INFO:Declaring metric variables
2023-07-07 01:00:50,325:INFO:Importing untrained model
2023-07-07 01:00:50,333:INFO:Extra Trees Classifier Imported successfully
2023-07-07 01:00:50,345:INFO:Starting cross validation
2023-07-07 01:00:50,346:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 01:00:53,153:INFO:Calculating mean and std
2023-07-07 01:00:53,155:INFO:Creating metrics dataframe
2023-07-07 01:00:53,321:INFO:Uploading results into container
2023-07-07 01:00:53,322:INFO:Uploading model into container now
2023-07-07 01:00:53,322:INFO:_master_model_container: 54
2023-07-07 01:00:53,322:INFO:_display_container: 5
2023-07-07 01:00:53,323:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-07 01:00:53,323:INFO:create_model() successfully completed......................................
2023-07-07 01:00:53,398:INFO:SubProcess create_model() end ==================================
2023-07-07 01:00:53,398:INFO:Creating metrics dataframe
2023-07-07 01:00:53,411:INFO:Initializing Light Gradient Boosting Machine
2023-07-07 01:00:53,411:INFO:Total runtime is 0.4009700814882914 minutes
2023-07-07 01:00:53,416:INFO:SubProcess create_model() called ==================================
2023-07-07 01:00:53,416:INFO:Initializing create_model()
2023-07-07 01:00:53,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB41C850>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 01:00:53,417:INFO:Checking exceptions
2023-07-07 01:00:53,417:INFO:Importing libraries
2023-07-07 01:00:53,417:INFO:Copying training dataset
2023-07-07 01:00:53,425:INFO:Defining folds
2023-07-07 01:00:53,425:INFO:Declaring metric variables
2023-07-07 01:00:53,430:INFO:Importing untrained model
2023-07-07 01:00:53,436:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-07 01:00:53,457:INFO:Starting cross validation
2023-07-07 01:00:53,459:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 01:00:55,178:INFO:Calculating mean and std
2023-07-07 01:00:55,180:INFO:Creating metrics dataframe
2023-07-07 01:00:55,360:INFO:Uploading results into container
2023-07-07 01:00:55,362:INFO:Uploading model into container now
2023-07-07 01:00:55,362:INFO:_master_model_container: 55
2023-07-07 01:00:55,362:INFO:_display_container: 5
2023-07-07 01:00:55,363:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-07 01:00:55,363:INFO:create_model() successfully completed......................................
2023-07-07 01:00:55,438:INFO:SubProcess create_model() end ==================================
2023-07-07 01:00:55,438:INFO:Creating metrics dataframe
2023-07-07 01:00:55,450:INFO:Initializing Dummy Classifier
2023-07-07 01:00:55,450:INFO:Total runtime is 0.43496062755584713 minutes
2023-07-07 01:00:55,454:INFO:SubProcess create_model() called ==================================
2023-07-07 01:00:55,455:INFO:Initializing create_model()
2023-07-07 01:00:55,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEAB41C850>, model_only=True, return_train_score=False, kwargs={})
2023-07-07 01:00:55,455:INFO:Checking exceptions
2023-07-07 01:00:55,455:INFO:Importing libraries
2023-07-07 01:00:55,455:INFO:Copying training dataset
2023-07-07 01:00:55,462:INFO:Defining folds
2023-07-07 01:00:55,463:INFO:Declaring metric variables
2023-07-07 01:00:55,468:INFO:Importing untrained model
2023-07-07 01:00:55,475:INFO:Dummy Classifier Imported successfully
2023-07-07 01:00:55,484:INFO:Starting cross validation
2023-07-07 01:00:55,485:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-07 01:00:55,662:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 01:00:55,675:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 01:00:55,692:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 01:00:55,719:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 01:00:55,725:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 01:00:55,747:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 01:00:55,757:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 01:00:55,773:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 01:00:56,095:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 01:00:56,112:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-07 01:00:56,920:INFO:Calculating mean and std
2023-07-07 01:00:56,922:INFO:Creating metrics dataframe
2023-07-07 01:00:57,102:INFO:Uploading results into container
2023-07-07 01:00:57,103:INFO:Uploading model into container now
2023-07-07 01:00:57,104:INFO:_master_model_container: 56
2023-07-07 01:00:57,104:INFO:_display_container: 5
2023-07-07 01:00:57,104:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-07 01:00:57,105:INFO:create_model() successfully completed......................................
2023-07-07 01:00:57,178:INFO:SubProcess create_model() end ==================================
2023-07-07 01:00:57,178:INFO:Creating metrics dataframe
2023-07-07 01:00:57,204:INFO:Initializing create_model()
2023-07-07 01:00:57,205:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-07 01:00:57,205:INFO:Checking exceptions
2023-07-07 01:00:57,207:INFO:Importing libraries
2023-07-07 01:00:57,207:INFO:Copying training dataset
2023-07-07 01:00:57,213:INFO:Defining folds
2023-07-07 01:00:57,213:INFO:Declaring metric variables
2023-07-07 01:00:57,214:INFO:Importing untrained model
2023-07-07 01:00:57,214:INFO:Declaring custom model
2023-07-07 01:00:57,215:INFO:Gradient Boosting Classifier Imported successfully
2023-07-07 01:00:57,216:INFO:Cross validation set to False
2023-07-07 01:00:57,216:INFO:Fitting Model
2023-07-07 01:00:57,390:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-07 01:00:57,390:INFO:create_model() successfully completed......................................
2023-07-07 01:00:57,497:INFO:_master_model_container: 56
2023-07-07 01:00:57,497:INFO:_display_container: 5
2023-07-07 01:00:57,498:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-07 01:00:57,498:INFO:compare_models() successfully completed......................................
2023-07-07 01:00:57,499:INFO:Initializing predict_model()
2023-07-07 01:00:57,499:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EEACC1E0D0>)
2023-07-07 01:00:57,499:INFO:Checking exceptions
2023-07-07 01:00:57,499:INFO:Preloading libraries
2023-07-07 01:00:57,501:INFO:Set up data.
2023-07-07 01:00:57,511:INFO:Set up index.
2023-07-07 01:02:50,503:INFO:Initializing plot_model()
2023-07-07 01:02:50,504:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=lr, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:02:50,504:INFO:Checking exceptions
2023-07-07 01:03:14,855:INFO:Initializing plot_model()
2023-07-07 01:03:14,856:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=Logistic Regression, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:03:14,856:INFO:Checking exceptions
2023-07-07 01:05:03,575:INFO:Initializing plot_model()
2023-07-07 01:05:03,575:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEAB1FB740,
                       splitter='best')                                     ], feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:05:03,576:INFO:Checking exceptions
2023-07-07 01:05:19,183:INFO:Initializing plot_model()
2023-07-07 01:05:19,183:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=rf, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:05:19,184:INFO:Checking exceptions
2023-07-07 01:07:38,033:INFO:Initializing plot_model()
2023-07-07 01:07:38,033:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEACBE3140,
                       splitter='best')                                     ], feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:07:38,034:INFO:Checking exceptions
2023-07-07 01:08:27,167:INFO:Initializing plot_model()
2023-07-07 01:08:27,167:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=3,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=RandomState(MT19937) at 0x1EEACBE3140,
                       splitter='best')                                     ], feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:08:27,168:INFO:Checking exceptions
2023-07-07 01:08:55,944:INFO:Initializing plot_model()
2023-07-07 01:08:55,944:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:08:55,945:INFO:Checking exceptions
2023-07-07 01:08:55,952:INFO:Preloading libraries
2023-07-07 01:08:55,968:INFO:Copying training dataset
2023-07-07 01:08:55,969:INFO:Plot type: confusion_matrix
2023-07-07 01:08:56,134:INFO:Fitting Model
2023-07-07 01:08:56,134:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-07-07 01:08:56,135:INFO:Scoring test/hold-out set
2023-07-07 01:08:56,292:INFO:Visual Rendered Successfully
2023-07-07 01:08:56,377:INFO:plot_model() successfully completed......................................
2023-07-07 01:13:04,059:INFO:Initializing evaluate_model()
2023-07-07 01:13:04,059:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-07 01:13:04,087:INFO:Initializing plot_model()
2023-07-07 01:13:04,087:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:13:04,087:INFO:Checking exceptions
2023-07-07 01:13:04,092:INFO:Preloading libraries
2023-07-07 01:13:04,105:INFO:Copying training dataset
2023-07-07 01:13:04,105:INFO:Plot type: pipeline
2023-07-07 01:13:04,264:INFO:Visual Rendered Successfully
2023-07-07 01:13:04,378:INFO:plot_model() successfully completed......................................
2023-07-07 01:13:09,536:INFO:Initializing plot_model()
2023-07-07 01:13:09,536:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:13:09,536:INFO:Checking exceptions
2023-07-07 01:13:09,540:INFO:Preloading libraries
2023-07-07 01:13:09,553:INFO:Copying training dataset
2023-07-07 01:13:09,553:INFO:Plot type: pr
2023-07-07 01:13:09,751:INFO:Fitting Model
2023-07-07 01:13:09,752:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-07-07 01:13:09,752:INFO:Scoring test/hold-out set
2023-07-07 01:13:09,931:INFO:Visual Rendered Successfully
2023-07-07 01:13:10,007:INFO:plot_model() successfully completed......................................
2023-07-07 01:13:11,736:INFO:Initializing plot_model()
2023-07-07 01:13:11,737:INFO:plot_model(plot=manifold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:13:11,737:INFO:Checking exceptions
2023-07-07 01:13:11,740:INFO:Preloading libraries
2023-07-07 01:13:11,749:INFO:Copying training dataset
2023-07-07 01:13:11,749:INFO:Plot type: manifold
2023-07-07 01:13:12,013:INFO:Fitting & Transforming Model
2023-07-07 01:13:12,027:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\manifold\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.
  warnings.warn(

2023-07-07 01:13:12,403:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\manifold\_t_sne.py:982: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.
  warnings.warn(

2023-07-07 01:13:29,922:INFO:Visual Rendered Successfully
2023-07-07 01:13:30,009:INFO:plot_model() successfully completed......................................
2023-07-07 01:13:30,022:INFO:Initializing plot_model()
2023-07-07 01:13:30,023:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:13:30,023:INFO:Checking exceptions
2023-07-07 01:13:30,026:INFO:Preloading libraries
2023-07-07 01:13:30,036:INFO:Copying training dataset
2023-07-07 01:13:30,036:INFO:Plot type: feature_all
2023-07-07 01:13:30,085:WARNING:No coef_ found. Trying feature_importances_
2023-07-07 01:13:30,478:INFO:Visual Rendered Successfully
2023-07-07 01:13:30,554:INFO:plot_model() successfully completed......................................
2023-07-07 01:13:30,614:INFO:Initializing plot_model()
2023-07-07 01:13:30,614:INFO:plot_model(plot=tree, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:13:30,615:INFO:Checking exceptions
2023-07-07 01:13:33,276:INFO:Initializing plot_model()
2023-07-07 01:13:33,277:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:13:33,277:INFO:Checking exceptions
2023-07-07 01:13:33,280:INFO:Preloading libraries
2023-07-07 01:13:33,290:INFO:Copying training dataset
2023-07-07 01:13:33,290:INFO:Plot type: feature
2023-07-07 01:13:33,290:WARNING:No coef_ found. Trying feature_importances_
2023-07-07 01:13:33,504:INFO:Visual Rendered Successfully
2023-07-07 01:13:33,579:INFO:plot_model() successfully completed......................................
2023-07-07 01:13:42,079:INFO:Initializing plot_model()
2023-07-07 01:13:42,080:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:13:42,080:INFO:Checking exceptions
2023-07-07 01:13:42,083:INFO:Preloading libraries
2023-07-07 01:13:42,097:INFO:Copying training dataset
2023-07-07 01:13:42,097:INFO:Plot type: learning
2023-07-07 01:13:42,253:INFO:Fitting Model
2023-07-07 01:13:52,186:INFO:Visual Rendered Successfully
2023-07-07 01:13:52,280:INFO:plot_model() successfully completed......................................
2023-07-07 01:14:02,018:INFO:Initializing plot_model()
2023-07-07 01:14:02,018:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:14:02,018:INFO:Checking exceptions
2023-07-07 01:14:02,021:INFO:Preloading libraries
2023-07-07 01:14:02,032:INFO:Copying training dataset
2023-07-07 01:14:02,032:INFO:Plot type: threshold
2023-07-07 01:14:02,195:INFO:Fitting Model
2023-07-07 01:14:21,152:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-07-07 01:14:21,172:INFO:Scoring test/hold-out set
2023-07-07 01:14:21,691:INFO:Visual Rendered Successfully
2023-07-07 01:14:21,784:INFO:plot_model() successfully completed......................................
2023-07-07 01:15:01,233:INFO:Initializing plot_model()
2023-07-07 01:15:01,234:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:15:01,234:INFO:Checking exceptions
2023-07-07 01:15:01,237:INFO:Preloading libraries
2023-07-07 01:15:01,248:INFO:Copying training dataset
2023-07-07 01:15:01,248:INFO:Plot type: pipeline
2023-07-07 01:15:01,335:INFO:Visual Rendered Successfully
2023-07-07 01:15:01,413:INFO:plot_model() successfully completed......................................
2023-07-07 01:15:06,712:INFO:Initializing plot_model()
2023-07-07 01:15:06,712:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:15:06,713:INFO:Checking exceptions
2023-07-07 01:15:06,716:INFO:Preloading libraries
2023-07-07 01:15:06,727:INFO:Copying training dataset
2023-07-07 01:15:06,727:INFO:Plot type: pr
2023-07-07 01:15:06,879:INFO:Fitting Model
2023-07-07 01:15:06,879:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-07-07 01:15:06,879:INFO:Scoring test/hold-out set
2023-07-07 01:15:07,058:INFO:Visual Rendered Successfully
2023-07-07 01:15:07,138:INFO:plot_model() successfully completed......................................
2023-07-07 01:15:12,182:INFO:Initializing plot_model()
2023-07-07 01:15:12,183:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:15:12,183:INFO:Checking exceptions
2023-07-07 01:15:12,187:INFO:Preloading libraries
2023-07-07 01:15:12,201:INFO:Copying training dataset
2023-07-07 01:15:12,201:INFO:Plot type: class_report
2023-07-07 01:15:12,421:INFO:Fitting Model
2023-07-07 01:15:12,421:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-07-07 01:15:12,421:INFO:Scoring test/hold-out set
2023-07-07 01:15:12,801:INFO:Visual Rendered Successfully
2023-07-07 01:15:12,885:INFO:plot_model() successfully completed......................................
2023-07-07 01:15:17,271:INFO:Initializing plot_model()
2023-07-07 01:15:17,271:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:15:17,271:INFO:Checking exceptions
2023-07-07 01:15:17,275:INFO:Preloading libraries
2023-07-07 01:15:17,285:INFO:Copying training dataset
2023-07-07 01:15:17,285:INFO:Plot type: confusion_matrix
2023-07-07 01:15:17,459:INFO:Fitting Model
2023-07-07 01:15:17,459:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-07-07 01:15:17,460:INFO:Scoring test/hold-out set
2023-07-07 01:15:17,602:INFO:Visual Rendered Successfully
2023-07-07 01:15:17,692:INFO:plot_model() successfully completed......................................
2023-07-07 01:15:45,092:INFO:Initializing plot_model()
2023-07-07 01:15:45,093:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEA83714C0>, system=True)
2023-07-07 01:15:45,093:INFO:Checking exceptions
2023-07-07 01:15:45,096:INFO:Preloading libraries
2023-07-07 01:15:45,107:INFO:Copying training dataset
2023-07-07 01:15:45,107:INFO:Plot type: pipeline
2023-07-07 01:15:45,213:INFO:Visual Rendered Successfully
2023-07-07 01:15:45,299:INFO:plot_model() successfully completed......................................
2023-07-08 09:43:57,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-08 09:43:57,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-08 09:43:57,919:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-08 09:43:57,919:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-08 09:44:29,314:INFO:PyCaret ClassificationExperiment
2023-07-08 09:44:29,314:INFO:Logging name: clf-default-name
2023-07-08 09:44:29,314:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-08 09:44:29,314:INFO:version 3.0.4
2023-07-08 09:44:29,314:INFO:Initializing setup()
2023-07-08 09:44:29,314:INFO:self.USI: 4b9f
2023-07-08 09:44:29,314:INFO:self._variable_keys: {'USI', 'fold_shuffle_param', 'is_multiclass', 'logging_param', 'X_train', 'pipeline', 'memory', 'gpu_param', 'fold_groups_param', 'X_test', 'data', 'idx', 'exp_name_log', 'target_param', 'fix_imbalance', 'html_param', 'n_jobs_param', 'gpu_n_jobs_param', 'exp_id', 'y_test', 'fold_generator', 'X', 'y_train', 'log_plots_param', 'seed', '_ml_usecase', 'y', '_available_plots'}
2023-07-08 09:44:29,314:INFO:Checking environment
2023-07-08 09:44:29,314:INFO:python_version: 3.9.13
2023-07-08 09:44:29,314:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-07-08 09:44:29,314:INFO:machine: AMD64
2023-07-08 09:44:29,314:INFO:platform: Windows-10-10.0.19045-SP0
2023-07-08 09:44:29,314:INFO:Memory: svmem(total=17125732352, available=10211602432, percent=40.4, used=6914129920, free=10211602432)
2023-07-08 09:44:29,314:INFO:Physical Core: 4
2023-07-08 09:44:29,314:INFO:Logical Core: 8
2023-07-08 09:44:29,314:INFO:Checking libraries
2023-07-08 09:44:29,314:INFO:System:
2023-07-08 09:44:29,314:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-07-08 09:44:29,314:INFO:executable: C:\Users\hamim\anaconda3\python.exe
2023-07-08 09:44:29,315:INFO:   machine: Windows-10-10.0.19045-SP0
2023-07-08 09:44:29,315:INFO:PyCaret required dependencies:
2023-07-08 09:44:29,317:INFO:                 pip: 22.2.2
2023-07-08 09:44:29,317:INFO:          setuptools: 63.4.1
2023-07-08 09:44:29,317:INFO:             pycaret: 3.0.4
2023-07-08 09:44:29,317:INFO:             IPython: 7.31.1
2023-07-08 09:44:29,317:INFO:          ipywidgets: 7.6.5
2023-07-08 09:44:29,317:INFO:                tqdm: 4.64.1
2023-07-08 09:44:29,318:INFO:               numpy: 1.21.5
2023-07-08 09:44:29,318:INFO:              pandas: 1.4.4
2023-07-08 09:44:29,318:INFO:              jinja2: 2.11.3
2023-07-08 09:44:29,318:INFO:               scipy: 1.9.1
2023-07-08 09:44:29,318:INFO:              joblib: 1.2.0
2023-07-08 09:44:29,318:INFO:             sklearn: 1.0.2
2023-07-08 09:44:29,318:INFO:                pyod: 1.1.0
2023-07-08 09:44:29,318:INFO:            imblearn: 0.10.1
2023-07-08 09:44:29,318:INFO:   category_encoders: 2.6.1
2023-07-08 09:44:29,318:INFO:            lightgbm: 3.3.5
2023-07-08 09:44:29,318:INFO:               numba: 0.55.1
2023-07-08 09:44:29,318:INFO:            requests: 2.28.1
2023-07-08 09:44:29,318:INFO:          matplotlib: 3.5.2
2023-07-08 09:44:29,318:INFO:          scikitplot: 0.3.7
2023-07-08 09:44:29,318:INFO:         yellowbrick: 1.5
2023-07-08 09:44:29,318:INFO:              plotly: 5.9.0
2023-07-08 09:44:29,318:INFO:    plotly-resampler: Not installed
2023-07-08 09:44:29,318:INFO:             kaleido: 0.2.1
2023-07-08 09:44:29,318:INFO:           schemdraw: 0.15
2023-07-08 09:44:29,318:INFO:         statsmodels: 0.13.2
2023-07-08 09:44:29,318:INFO:              sktime: 0.20.0
2023-07-08 09:44:29,318:INFO:               tbats: 1.1.3
2023-07-08 09:44:29,318:INFO:            pmdarima: 2.0.3
2023-07-08 09:44:29,319:INFO:              psutil: 5.9.0
2023-07-08 09:44:29,319:INFO:          markupsafe: 2.0.1
2023-07-08 09:44:29,319:INFO:             pickle5: Not installed
2023-07-08 09:44:29,319:INFO:         cloudpickle: 2.0.0
2023-07-08 09:44:29,319:INFO:         deprecation: 2.1.0
2023-07-08 09:44:29,319:INFO:              xxhash: 3.2.0
2023-07-08 09:44:29,319:INFO:           wurlitzer: Not installed
2023-07-08 09:44:29,319:INFO:PyCaret optional dependencies:
2023-07-08 09:44:29,338:INFO:                shap: Not installed
2023-07-08 09:44:29,338:INFO:           interpret: Not installed
2023-07-08 09:44:29,338:INFO:                umap: Not installed
2023-07-08 09:44:29,338:INFO:    pandas_profiling: Not installed
2023-07-08 09:44:29,338:INFO:  explainerdashboard: Not installed
2023-07-08 09:44:29,339:INFO:             autoviz: Not installed
2023-07-08 09:44:29,339:INFO:           fairlearn: Not installed
2023-07-08 09:44:29,339:INFO:          deepchecks: Not installed
2023-07-08 09:44:29,339:INFO:             xgboost: Not installed
2023-07-08 09:44:29,339:INFO:            catboost: Not installed
2023-07-08 09:44:29,339:INFO:              kmodes: Not installed
2023-07-08 09:44:29,339:INFO:             mlxtend: Not installed
2023-07-08 09:44:29,339:INFO:       statsforecast: Not installed
2023-07-08 09:44:29,339:INFO:        tune_sklearn: Not installed
2023-07-08 09:44:29,339:INFO:                 ray: Not installed
2023-07-08 09:44:29,339:INFO:            hyperopt: Not installed
2023-07-08 09:44:29,339:INFO:              optuna: Not installed
2023-07-08 09:44:29,339:INFO:               skopt: Not installed
2023-07-08 09:44:29,339:INFO:              mlflow: Not installed
2023-07-08 09:44:29,339:INFO:              gradio: Not installed
2023-07-08 09:44:29,339:INFO:             fastapi: Not installed
2023-07-08 09:44:29,339:INFO:             uvicorn: Not installed
2023-07-08 09:44:29,339:INFO:              m2cgen: Not installed
2023-07-08 09:44:29,339:INFO:           evidently: Not installed
2023-07-08 09:44:29,339:INFO:               fugue: Not installed
2023-07-08 09:44:29,339:INFO:           streamlit: Not installed
2023-07-08 09:44:29,340:INFO:             prophet: Not installed
2023-07-08 09:44:29,340:INFO:None
2023-07-08 09:44:29,340:INFO:Set up data.
2023-07-08 09:44:29,352:INFO:Set up train/test split.
2023-07-08 09:44:29,358:INFO:Set up index.
2023-07-08 09:44:29,358:INFO:Set up folding strategy.
2023-07-08 09:44:29,358:INFO:Assigning column types.
2023-07-08 09:44:29,362:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-08 09:44:29,413:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-08 09:44:29,418:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 09:44:29,461:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 09:44:29,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 09:44:29,718:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-08 09:44:29,719:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 09:44:29,754:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 09:44:29,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 09:44:29,754:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-08 09:44:29,806:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 09:44:29,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 09:44:29,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 09:44:29,898:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 09:44:29,936:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 09:44:29,937:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 09:44:29,937:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-08 09:44:30,018:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 09:44:30,018:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 09:44:30,101:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 09:44:30,102:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 09:44:30,105:INFO:Preparing preprocessing pipeline...
2023-07-08 09:44:30,107:INFO:Set up simple imputation.
2023-07-08 09:44:30,107:INFO:Set up imbalanced handling.
2023-07-08 09:44:30,108:INFO:Set up column name cleaning.
2023-07-08 09:44:30,192:INFO:Finished creating preprocessing pipeline.
2023-07-08 09:44:30,202:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-08 09:44:30,202:INFO:Creating final display dataframe.
2023-07-08 09:44:30,501:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Target
2                   Target type            Binary
3           Original data shape        (2802, 34)
4        Transformed data shape        (3825, 34)
5   Transformed train set shape        (2984, 34)
6    Transformed test set shape         (841, 34)
7              Numeric features                33
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              4b9f
2023-07-08 09:44:30,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 09:44:30,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 09:44:30,682:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 09:44:30,683:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 09:44:30,683:INFO:setup() successfully completed in 1.53s...............
2023-07-08 09:44:44,650:INFO:Initializing compare_models()
2023-07-08 09:44:44,650:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-08 09:44:44,651:INFO:Checking exceptions
2023-07-08 09:44:44,657:INFO:Preparing display monitor
2023-07-08 09:44:44,704:INFO:Initializing Logistic Regression
2023-07-08 09:44:44,704:INFO:Total runtime is 0.0 minutes
2023-07-08 09:44:44,709:INFO:SubProcess create_model() called ==================================
2023-07-08 09:44:44,710:INFO:Initializing create_model()
2023-07-08 09:44:44,710:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E30CF406A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 09:44:44,710:INFO:Checking exceptions
2023-07-08 09:44:44,710:INFO:Importing libraries
2023-07-08 09:44:44,710:INFO:Copying training dataset
2023-07-08 09:44:44,716:INFO:Defining folds
2023-07-08 09:44:44,717:INFO:Declaring metric variables
2023-07-08 09:44:44,723:INFO:Importing untrained model
2023-07-08 09:44:44,729:INFO:Logistic Regression Imported successfully
2023-07-08 09:44:44,741:INFO:Starting cross validation
2023-07-08 09:44:44,742:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 09:44:55,355:INFO:Calculating mean and std
2023-07-08 09:44:55,356:INFO:Creating metrics dataframe
2023-07-08 09:44:55,538:INFO:Uploading results into container
2023-07-08 09:44:55,539:INFO:Uploading model into container now
2023-07-08 09:44:55,540:INFO:_master_model_container: 1
2023-07-08 09:44:55,540:INFO:_display_container: 2
2023-07-08 09:44:55,540:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-08 09:44:55,540:INFO:create_model() successfully completed......................................
2023-07-08 09:44:55,608:INFO:SubProcess create_model() end ==================================
2023-07-08 09:44:55,608:INFO:Creating metrics dataframe
2023-07-08 09:44:55,619:INFO:Initializing K Neighbors Classifier
2023-07-08 09:44:55,619:INFO:Total runtime is 0.18191076517105104 minutes
2023-07-08 09:44:55,625:INFO:SubProcess create_model() called ==================================
2023-07-08 09:44:55,626:INFO:Initializing create_model()
2023-07-08 09:44:55,626:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E30CF406A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 09:44:55,626:INFO:Checking exceptions
2023-07-08 09:44:55,626:INFO:Importing libraries
2023-07-08 09:44:55,627:INFO:Copying training dataset
2023-07-08 09:44:55,632:INFO:Defining folds
2023-07-08 09:44:55,632:INFO:Declaring metric variables
2023-07-08 09:44:55,637:INFO:Importing untrained model
2023-07-08 09:44:55,644:INFO:K Neighbors Classifier Imported successfully
2023-07-08 09:44:55,659:INFO:Starting cross validation
2023-07-08 09:44:55,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 09:44:55,908:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 09:44:55,920:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 09:44:55,925:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 09:44:55,926:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 09:44:55,948:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 09:44:55,951:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 09:44:55,954:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 09:44:56,009:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 09:44:56,433:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 09:44:56,437:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 09:44:57,320:INFO:Calculating mean and std
2023-07-08 09:44:57,321:INFO:Creating metrics dataframe
2023-07-08 09:44:57,509:INFO:Uploading results into container
2023-07-08 09:44:57,509:INFO:Uploading model into container now
2023-07-08 09:44:57,510:INFO:_master_model_container: 2
2023-07-08 09:44:57,510:INFO:_display_container: 2
2023-07-08 09:44:57,511:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-08 09:44:57,511:INFO:create_model() successfully completed......................................
2023-07-08 09:44:57,582:INFO:SubProcess create_model() end ==================================
2023-07-08 09:44:57,582:INFO:Creating metrics dataframe
2023-07-08 09:44:57,594:INFO:Initializing Naive Bayes
2023-07-08 09:44:57,594:INFO:Total runtime is 0.21481765906016032 minutes
2023-07-08 09:44:57,598:INFO:SubProcess create_model() called ==================================
2023-07-08 09:44:57,598:INFO:Initializing create_model()
2023-07-08 09:44:57,598:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E30CF406A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 09:44:57,598:INFO:Checking exceptions
2023-07-08 09:44:57,598:INFO:Importing libraries
2023-07-08 09:44:57,598:INFO:Copying training dataset
2023-07-08 09:44:57,610:INFO:Defining folds
2023-07-08 09:44:57,611:INFO:Declaring metric variables
2023-07-08 09:44:57,615:INFO:Importing untrained model
2023-07-08 09:44:57,622:INFO:Naive Bayes Imported successfully
2023-07-08 09:44:57,632:INFO:Starting cross validation
2023-07-08 09:44:57,635:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 09:44:59,168:INFO:Calculating mean and std
2023-07-08 09:44:59,170:INFO:Creating metrics dataframe
2023-07-08 09:44:59,348:INFO:Uploading results into container
2023-07-08 09:44:59,350:INFO:Uploading model into container now
2023-07-08 09:44:59,351:INFO:_master_model_container: 3
2023-07-08 09:44:59,351:INFO:_display_container: 2
2023-07-08 09:44:59,352:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-08 09:44:59,352:INFO:create_model() successfully completed......................................
2023-07-08 09:44:59,422:INFO:SubProcess create_model() end ==================================
2023-07-08 09:44:59,423:INFO:Creating metrics dataframe
2023-07-08 09:44:59,436:INFO:Initializing Decision Tree Classifier
2023-07-08 09:44:59,436:INFO:Total runtime is 0.24553091923395792 minutes
2023-07-08 09:44:59,442:INFO:SubProcess create_model() called ==================================
2023-07-08 09:44:59,442:INFO:Initializing create_model()
2023-07-08 09:44:59,442:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E30CF406A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 09:44:59,442:INFO:Checking exceptions
2023-07-08 09:44:59,442:INFO:Importing libraries
2023-07-08 09:44:59,442:INFO:Copying training dataset
2023-07-08 09:44:59,451:INFO:Defining folds
2023-07-08 09:44:59,451:INFO:Declaring metric variables
2023-07-08 09:44:59,455:INFO:Importing untrained model
2023-07-08 09:44:59,462:INFO:Decision Tree Classifier Imported successfully
2023-07-08 09:44:59,473:INFO:Starting cross validation
2023-07-08 09:44:59,476:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 09:45:00,986:INFO:Calculating mean and std
2023-07-08 09:45:00,987:INFO:Creating metrics dataframe
2023-07-08 09:45:01,174:INFO:Uploading results into container
2023-07-08 09:45:01,175:INFO:Uploading model into container now
2023-07-08 09:45:01,175:INFO:_master_model_container: 4
2023-07-08 09:45:01,176:INFO:_display_container: 2
2023-07-08 09:45:01,176:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-08 09:45:01,176:INFO:create_model() successfully completed......................................
2023-07-08 09:45:01,242:INFO:SubProcess create_model() end ==================================
2023-07-08 09:45:01,243:INFO:Creating metrics dataframe
2023-07-08 09:45:01,256:INFO:Initializing SVM - Linear Kernel
2023-07-08 09:45:01,256:INFO:Total runtime is 0.27585243384043373 minutes
2023-07-08 09:45:01,261:INFO:SubProcess create_model() called ==================================
2023-07-08 09:45:01,261:INFO:Initializing create_model()
2023-07-08 09:45:01,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E30CF406A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 09:45:01,261:INFO:Checking exceptions
2023-07-08 09:45:01,261:INFO:Importing libraries
2023-07-08 09:45:01,261:INFO:Copying training dataset
2023-07-08 09:45:01,269:INFO:Defining folds
2023-07-08 09:45:01,269:INFO:Declaring metric variables
2023-07-08 09:45:01,275:INFO:Importing untrained model
2023-07-08 09:45:01,282:INFO:SVM - Linear Kernel Imported successfully
2023-07-08 09:45:01,297:INFO:Starting cross validation
2023-07-08 09:45:01,299:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 09:45:01,569:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 09:45:01,612:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 09:45:01,612:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 09:45:01,614:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 09:45:01,616:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 09:45:01,625:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 09:45:01,640:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 09:45:01,984:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 09:45:02,013:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 09:45:02,854:INFO:Calculating mean and std
2023-07-08 09:45:02,856:INFO:Creating metrics dataframe
2023-07-08 09:45:03,032:INFO:Uploading results into container
2023-07-08 09:45:03,033:INFO:Uploading model into container now
2023-07-08 09:45:03,033:INFO:_master_model_container: 5
2023-07-08 09:45:03,034:INFO:_display_container: 2
2023-07-08 09:45:03,034:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-08 09:45:03,034:INFO:create_model() successfully completed......................................
2023-07-08 09:45:03,101:INFO:SubProcess create_model() end ==================================
2023-07-08 09:45:03,101:INFO:Creating metrics dataframe
2023-07-08 09:45:03,117:INFO:Initializing Ridge Classifier
2023-07-08 09:45:03,117:INFO:Total runtime is 0.3068789958953857 minutes
2023-07-08 09:45:03,125:INFO:SubProcess create_model() called ==================================
2023-07-08 09:45:03,126:INFO:Initializing create_model()
2023-07-08 09:45:03,126:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E30CF406A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 09:45:03,126:INFO:Checking exceptions
2023-07-08 09:45:03,126:INFO:Importing libraries
2023-07-08 09:45:03,127:INFO:Copying training dataset
2023-07-08 09:45:03,138:INFO:Defining folds
2023-07-08 09:45:03,138:INFO:Declaring metric variables
2023-07-08 09:45:03,144:INFO:Importing untrained model
2023-07-08 09:45:03,152:INFO:Ridge Classifier Imported successfully
2023-07-08 09:45:03,166:INFO:Starting cross validation
2023-07-08 09:45:03,167:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 09:45:03,404:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 09:45:03,406:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 09:45:03,413:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 09:45:03,414:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 09:45:03,418:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 09:45:03,426:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 09:45:03,433:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 09:45:03,457:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 09:45:03,788:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 09:45:03,816:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 09:45:04,722:INFO:Calculating mean and std
2023-07-08 09:45:04,724:INFO:Creating metrics dataframe
2023-07-08 09:45:04,915:INFO:Uploading results into container
2023-07-08 09:45:04,916:INFO:Uploading model into container now
2023-07-08 09:45:04,916:INFO:_master_model_container: 6
2023-07-08 09:45:04,916:INFO:_display_container: 2
2023-07-08 09:45:04,916:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=42, solver='auto', tol=0.001)
2023-07-08 09:45:04,916:INFO:create_model() successfully completed......................................
2023-07-08 09:45:04,985:INFO:SubProcess create_model() end ==================================
2023-07-08 09:45:04,986:INFO:Creating metrics dataframe
2023-07-08 09:45:04,999:INFO:Initializing Random Forest Classifier
2023-07-08 09:45:04,999:INFO:Total runtime is 0.338248070081075 minutes
2023-07-08 09:45:05,006:INFO:SubProcess create_model() called ==================================
2023-07-08 09:45:05,006:INFO:Initializing create_model()
2023-07-08 09:45:05,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E30CF406A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 09:45:05,008:INFO:Checking exceptions
2023-07-08 09:45:05,008:INFO:Importing libraries
2023-07-08 09:45:05,008:INFO:Copying training dataset
2023-07-08 09:45:05,016:INFO:Defining folds
2023-07-08 09:45:05,016:INFO:Declaring metric variables
2023-07-08 09:45:05,023:INFO:Importing untrained model
2023-07-08 09:45:05,031:INFO:Random Forest Classifier Imported successfully
2023-07-08 09:45:05,044:INFO:Starting cross validation
2023-07-08 09:45:05,046:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 09:45:08,136:INFO:Calculating mean and std
2023-07-08 09:45:08,138:INFO:Creating metrics dataframe
2023-07-08 09:45:08,346:INFO:Uploading results into container
2023-07-08 09:45:08,347:INFO:Uploading model into container now
2023-07-08 09:45:08,347:INFO:_master_model_container: 7
2023-07-08 09:45:08,347:INFO:_display_container: 2
2023-07-08 09:45:08,349:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-08 09:45:08,349:INFO:create_model() successfully completed......................................
2023-07-08 09:45:08,428:INFO:SubProcess create_model() end ==================================
2023-07-08 09:45:08,428:INFO:Creating metrics dataframe
2023-07-08 09:45:08,445:INFO:Initializing Quadratic Discriminant Analysis
2023-07-08 09:45:08,445:INFO:Total runtime is 0.3956791162490844 minutes
2023-07-08 09:45:08,451:INFO:SubProcess create_model() called ==================================
2023-07-08 09:45:08,451:INFO:Initializing create_model()
2023-07-08 09:45:08,451:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E30CF406A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 09:45:08,452:INFO:Checking exceptions
2023-07-08 09:45:08,452:INFO:Importing libraries
2023-07-08 09:45:08,452:INFO:Copying training dataset
2023-07-08 09:45:08,461:INFO:Defining folds
2023-07-08 09:45:08,461:INFO:Declaring metric variables
2023-07-08 09:45:08,468:INFO:Importing untrained model
2023-07-08 09:45:08,474:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-08 09:45:08,484:INFO:Starting cross validation
2023-07-08 09:45:08,488:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 09:45:08,665:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 09:45:08,672:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 09:45:08,678:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 09:45:08,679:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 09:45:08,711:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 09:45:08,718:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 09:45:08,724:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 09:45:08,743:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 09:45:08,784:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 09:45:08,822:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 09:45:09,137:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 09:45:09,146:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 09:45:09,211:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 09:45:09,216:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 09:45:10,123:INFO:Calculating mean and std
2023-07-08 09:45:10,124:INFO:Creating metrics dataframe
2023-07-08 09:45:10,300:INFO:Uploading results into container
2023-07-08 09:45:10,301:INFO:Uploading model into container now
2023-07-08 09:45:10,301:INFO:_master_model_container: 8
2023-07-08 09:45:10,301:INFO:_display_container: 2
2023-07-08 09:45:10,302:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-08 09:45:10,302:INFO:create_model() successfully completed......................................
2023-07-08 09:45:10,370:INFO:SubProcess create_model() end ==================================
2023-07-08 09:45:10,370:INFO:Creating metrics dataframe
2023-07-08 09:45:10,385:INFO:Initializing Ada Boost Classifier
2023-07-08 09:45:10,386:INFO:Total runtime is 0.4280280391375223 minutes
2023-07-08 09:45:10,390:INFO:SubProcess create_model() called ==================================
2023-07-08 09:45:10,391:INFO:Initializing create_model()
2023-07-08 09:45:10,391:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E30CF406A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 09:45:10,391:INFO:Checking exceptions
2023-07-08 09:45:10,391:INFO:Importing libraries
2023-07-08 09:45:10,392:INFO:Copying training dataset
2023-07-08 09:45:10,400:INFO:Defining folds
2023-07-08 09:45:10,400:INFO:Declaring metric variables
2023-07-08 09:45:10,405:INFO:Importing untrained model
2023-07-08 09:45:10,411:INFO:Ada Boost Classifier Imported successfully
2023-07-08 09:45:10,426:INFO:Starting cross validation
2023-07-08 09:45:10,428:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 09:45:12,682:INFO:Calculating mean and std
2023-07-08 09:45:12,684:INFO:Creating metrics dataframe
2023-07-08 09:45:12,869:INFO:Uploading results into container
2023-07-08 09:45:12,870:INFO:Uploading model into container now
2023-07-08 09:45:12,871:INFO:_master_model_container: 9
2023-07-08 09:45:12,871:INFO:_display_container: 2
2023-07-08 09:45:12,871:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2023-07-08 09:45:12,871:INFO:create_model() successfully completed......................................
2023-07-08 09:45:12,938:INFO:SubProcess create_model() end ==================================
2023-07-08 09:45:12,939:INFO:Creating metrics dataframe
2023-07-08 09:45:12,955:INFO:Initializing Gradient Boosting Classifier
2023-07-08 09:45:12,956:INFO:Total runtime is 0.4708570639292398 minutes
2023-07-08 09:45:12,961:INFO:SubProcess create_model() called ==================================
2023-07-08 09:45:12,961:INFO:Initializing create_model()
2023-07-08 09:45:12,961:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E30CF406A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 09:45:12,962:INFO:Checking exceptions
2023-07-08 09:45:12,962:INFO:Importing libraries
2023-07-08 09:45:12,962:INFO:Copying training dataset
2023-07-08 09:45:12,970:INFO:Defining folds
2023-07-08 09:45:12,972:INFO:Declaring metric variables
2023-07-08 09:45:12,980:INFO:Importing untrained model
2023-07-08 09:45:12,987:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 09:45:12,998:INFO:Starting cross validation
2023-07-08 09:45:13,000:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 09:45:15,566:INFO:Calculating mean and std
2023-07-08 09:45:15,569:INFO:Creating metrics dataframe
2023-07-08 09:45:15,769:INFO:Uploading results into container
2023-07-08 09:45:15,770:INFO:Uploading model into container now
2023-07-08 09:45:15,771:INFO:_master_model_container: 10
2023-07-08 09:45:15,771:INFO:_display_container: 2
2023-07-08 09:45:15,772:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 09:45:15,772:INFO:create_model() successfully completed......................................
2023-07-08 09:45:15,839:INFO:SubProcess create_model() end ==================================
2023-07-08 09:45:15,839:INFO:Creating metrics dataframe
2023-07-08 09:45:15,852:INFO:Initializing Linear Discriminant Analysis
2023-07-08 09:45:15,852:INFO:Total runtime is 0.519123880068461 minutes
2023-07-08 09:45:15,856:INFO:SubProcess create_model() called ==================================
2023-07-08 09:45:15,857:INFO:Initializing create_model()
2023-07-08 09:45:15,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E30CF406A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 09:45:15,857:INFO:Checking exceptions
2023-07-08 09:45:15,857:INFO:Importing libraries
2023-07-08 09:45:15,857:INFO:Copying training dataset
2023-07-08 09:45:15,863:INFO:Defining folds
2023-07-08 09:45:15,863:INFO:Declaring metric variables
2023-07-08 09:45:15,867:INFO:Importing untrained model
2023-07-08 09:45:15,872:INFO:Linear Discriminant Analysis Imported successfully
2023-07-08 09:45:15,885:INFO:Starting cross validation
2023-07-08 09:45:15,888:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 09:45:17,531:INFO:Calculating mean and std
2023-07-08 09:45:17,533:INFO:Creating metrics dataframe
2023-07-08 09:45:17,743:INFO:Uploading results into container
2023-07-08 09:45:17,743:INFO:Uploading model into container now
2023-07-08 09:45:17,744:INFO:_master_model_container: 11
2023-07-08 09:45:17,744:INFO:_display_container: 2
2023-07-08 09:45:17,744:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-08 09:45:17,744:INFO:create_model() successfully completed......................................
2023-07-08 09:45:17,811:INFO:SubProcess create_model() end ==================================
2023-07-08 09:45:17,811:INFO:Creating metrics dataframe
2023-07-08 09:45:17,828:INFO:Initializing Extra Trees Classifier
2023-07-08 09:45:17,828:INFO:Total runtime is 0.5520665884017943 minutes
2023-07-08 09:45:17,834:INFO:SubProcess create_model() called ==================================
2023-07-08 09:45:17,835:INFO:Initializing create_model()
2023-07-08 09:45:17,835:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E30CF406A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 09:45:17,835:INFO:Checking exceptions
2023-07-08 09:45:17,836:INFO:Importing libraries
2023-07-08 09:45:17,836:INFO:Copying training dataset
2023-07-08 09:45:17,843:INFO:Defining folds
2023-07-08 09:45:17,843:INFO:Declaring metric variables
2023-07-08 09:45:17,847:INFO:Importing untrained model
2023-07-08 09:45:17,853:INFO:Extra Trees Classifier Imported successfully
2023-07-08 09:45:17,864:INFO:Starting cross validation
2023-07-08 09:45:17,867:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 09:45:21,121:INFO:Calculating mean and std
2023-07-08 09:45:21,123:INFO:Creating metrics dataframe
2023-07-08 09:45:21,338:INFO:Uploading results into container
2023-07-08 09:45:21,338:INFO:Uploading model into container now
2023-07-08 09:45:21,339:INFO:_master_model_container: 12
2023-07-08 09:45:21,339:INFO:_display_container: 2
2023-07-08 09:45:21,339:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-08 09:45:21,339:INFO:create_model() successfully completed......................................
2023-07-08 09:45:21,415:INFO:SubProcess create_model() end ==================================
2023-07-08 09:45:21,415:INFO:Creating metrics dataframe
2023-07-08 09:45:21,433:INFO:Initializing Light Gradient Boosting Machine
2023-07-08 09:45:21,433:INFO:Total runtime is 0.6121485710144042 minutes
2023-07-08 09:45:21,437:INFO:SubProcess create_model() called ==================================
2023-07-08 09:45:21,437:INFO:Initializing create_model()
2023-07-08 09:45:21,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E30CF406A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 09:45:21,438:INFO:Checking exceptions
2023-07-08 09:45:21,438:INFO:Importing libraries
2023-07-08 09:45:21,438:INFO:Copying training dataset
2023-07-08 09:45:21,446:INFO:Defining folds
2023-07-08 09:45:21,446:INFO:Declaring metric variables
2023-07-08 09:45:21,451:INFO:Importing untrained model
2023-07-08 09:45:21,459:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-08 09:45:21,471:INFO:Starting cross validation
2023-07-08 09:45:21,473:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 09:45:25,588:INFO:Calculating mean and std
2023-07-08 09:45:25,590:INFO:Creating metrics dataframe
2023-07-08 09:45:25,801:INFO:Uploading results into container
2023-07-08 09:45:25,802:INFO:Uploading model into container now
2023-07-08 09:45:25,802:INFO:_master_model_container: 13
2023-07-08 09:45:25,802:INFO:_display_container: 2
2023-07-08 09:45:25,803:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-08 09:45:25,803:INFO:create_model() successfully completed......................................
2023-07-08 09:45:25,868:INFO:SubProcess create_model() end ==================================
2023-07-08 09:45:25,868:INFO:Creating metrics dataframe
2023-07-08 09:45:25,884:INFO:Initializing Dummy Classifier
2023-07-08 09:45:25,884:INFO:Total runtime is 0.686327830950419 minutes
2023-07-08 09:45:25,889:INFO:SubProcess create_model() called ==================================
2023-07-08 09:45:25,889:INFO:Initializing create_model()
2023-07-08 09:45:25,889:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E30CF406A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 09:45:25,889:INFO:Checking exceptions
2023-07-08 09:45:25,889:INFO:Importing libraries
2023-07-08 09:45:25,889:INFO:Copying training dataset
2023-07-08 09:45:25,896:INFO:Defining folds
2023-07-08 09:45:25,896:INFO:Declaring metric variables
2023-07-08 09:45:25,901:INFO:Importing untrained model
2023-07-08 09:45:25,906:INFO:Dummy Classifier Imported successfully
2023-07-08 09:45:25,919:INFO:Starting cross validation
2023-07-08 09:45:25,920:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 09:45:26,158:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 09:45:26,162:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 09:45:26,174:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 09:45:26,220:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 09:45:26,234:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 09:45:26,240:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 09:45:26,242:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 09:45:26,409:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 09:45:26,601:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 09:45:26,633:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 09:45:27,638:INFO:Calculating mean and std
2023-07-08 09:45:27,641:INFO:Creating metrics dataframe
2023-07-08 09:45:27,857:INFO:Uploading results into container
2023-07-08 09:45:27,857:INFO:Uploading model into container now
2023-07-08 09:45:27,858:INFO:_master_model_container: 14
2023-07-08 09:45:27,858:INFO:_display_container: 2
2023-07-08 09:45:27,858:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-08 09:45:27,858:INFO:create_model() successfully completed......................................
2023-07-08 09:45:27,929:INFO:SubProcess create_model() end ==================================
2023-07-08 09:45:27,929:INFO:Creating metrics dataframe
2023-07-08 09:45:27,955:INFO:Initializing create_model()
2023-07-08 09:45:27,956:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-08 09:45:27,956:INFO:Checking exceptions
2023-07-08 09:45:27,959:INFO:Importing libraries
2023-07-08 09:45:27,959:INFO:Copying training dataset
2023-07-08 09:45:27,964:INFO:Defining folds
2023-07-08 09:45:27,964:INFO:Declaring metric variables
2023-07-08 09:45:27,964:INFO:Importing untrained model
2023-07-08 09:45:27,964:INFO:Declaring custom model
2023-07-08 09:45:27,966:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 09:45:27,967:INFO:Cross validation set to False
2023-07-08 09:45:27,967:INFO:Fitting Model
2023-07-08 09:45:28,678:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 09:45:28,678:INFO:create_model() successfully completed......................................
2023-07-08 09:45:28,780:INFO:_master_model_container: 14
2023-07-08 09:45:28,780:INFO:_display_container: 2
2023-07-08 09:45:28,781:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 09:45:28,781:INFO:compare_models() successfully completed......................................
2023-07-08 10:00:11,353:INFO:Initializing tune_model()
2023-07-08 10:00:11,353:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>)
2023-07-08 10:00:11,354:INFO:Checking exceptions
2023-07-08 10:00:11,392:INFO:Copying training dataset
2023-07-08 10:00:11,396:INFO:Checking base model
2023-07-08 10:00:11,396:INFO:Base model : Gradient Boosting Classifier
2023-07-08 10:00:11,402:INFO:Declaring metric variables
2023-07-08 10:00:11,406:INFO:Defining Hyperparameters
2023-07-08 10:00:11,476:INFO:Tuning with n_jobs=-1
2023-07-08 10:00:11,476:INFO:Initializing RandomizedSearchCV
2023-07-08 10:00:42,669:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 270, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.05}
2023-07-08 10:00:42,671:INFO:Hyperparameter search completed
2023-07-08 10:00:42,671:INFO:SubProcess create_model() called ==================================
2023-07-08 10:00:42,672:INFO:Initializing create_model()
2023-07-08 10:00:42,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E3024693A0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.7, 'n_estimators': 270, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 6, 'learning_rate': 0.05})
2023-07-08 10:00:42,672:INFO:Checking exceptions
2023-07-08 10:00:42,672:INFO:Importing libraries
2023-07-08 10:00:42,672:INFO:Copying training dataset
2023-07-08 10:00:42,679:INFO:Defining folds
2023-07-08 10:00:42,679:INFO:Declaring metric variables
2023-07-08 10:00:42,683:INFO:Importing untrained model
2023-07-08 10:00:42,683:INFO:Declaring custom model
2023-07-08 10:00:42,688:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 10:00:42,697:INFO:Starting cross validation
2023-07-08 10:00:42,699:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 10:00:45,593:INFO:Calculating mean and std
2023-07-08 10:00:45,594:INFO:Creating metrics dataframe
2023-07-08 10:00:45,601:INFO:Finalizing model
2023-07-08 10:00:46,410:INFO:Uploading results into container
2023-07-08 10:00:46,411:INFO:Uploading model into container now
2023-07-08 10:00:46,412:INFO:_master_model_container: 15
2023-07-08 10:00:46,413:INFO:_display_container: 3
2023-07-08 10:00:46,413:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='deviance', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=270, n_iter_no_change=None,
                           random_state=42, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 10:00:46,413:INFO:create_model() successfully completed......................................
2023-07-08 10:00:46,477:INFO:SubProcess create_model() end ==================================
2023-07-08 10:00:46,477:INFO:choose_better activated
2023-07-08 10:00:46,481:INFO:SubProcess create_model() called ==================================
2023-07-08 10:00:46,482:INFO:Initializing create_model()
2023-07-08 10:00:46,482:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-08 10:00:46,482:INFO:Checking exceptions
2023-07-08 10:00:46,485:INFO:Importing libraries
2023-07-08 10:00:46,485:INFO:Copying training dataset
2023-07-08 10:00:46,489:INFO:Defining folds
2023-07-08 10:00:46,490:INFO:Declaring metric variables
2023-07-08 10:00:46,490:INFO:Importing untrained model
2023-07-08 10:00:46,490:INFO:Declaring custom model
2023-07-08 10:00:46,491:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 10:00:46,492:INFO:Starting cross validation
2023-07-08 10:00:46,493:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 10:00:49,545:INFO:Calculating mean and std
2023-07-08 10:00:49,546:INFO:Creating metrics dataframe
2023-07-08 10:00:49,548:INFO:Finalizing model
2023-07-08 10:00:49,907:INFO:Uploading results into container
2023-07-08 10:00:49,908:INFO:Uploading model into container now
2023-07-08 10:00:49,908:INFO:_master_model_container: 16
2023-07-08 10:00:49,908:INFO:_display_container: 4
2023-07-08 10:00:49,909:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 10:00:49,909:INFO:create_model() successfully completed......................................
2023-07-08 10:00:49,975:INFO:SubProcess create_model() end ==================================
2023-07-08 10:00:49,975:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8251
2023-07-08 10:00:49,976:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='deviance', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=270, n_iter_no_change=None,
                           random_state=42, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8271
2023-07-08 10:00:49,976:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='deviance', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=270, n_iter_no_change=None,
                           random_state=42, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-07-08 10:00:49,976:INFO:choose_better completed
2023-07-08 10:00:49,988:INFO:_master_model_container: 16
2023-07-08 10:00:49,988:INFO:_display_container: 3
2023-07-08 10:00:49,988:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='deviance', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=270, n_iter_no_change=None,
                           random_state=42, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 10:00:49,989:INFO:tune_model() successfully completed......................................
2023-07-08 10:04:14,376:INFO:Initializing evaluate_model()
2023-07-08 10:04:14,376:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='deviance', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=270, n_iter_no_change=None,
                           random_state=42, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-08 10:04:14,407:INFO:Initializing plot_model()
2023-07-08 10:04:14,408:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='deviance', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=270, n_iter_no_change=None,
                           random_state=42, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, system=True)
2023-07-08 10:04:14,408:INFO:Checking exceptions
2023-07-08 10:04:14,411:INFO:Preloading libraries
2023-07-08 10:04:14,432:INFO:Copying training dataset
2023-07-08 10:04:14,432:INFO:Plot type: pipeline
2023-07-08 10:04:14,591:INFO:Visual Rendered Successfully
2023-07-08 10:04:14,666:INFO:plot_model() successfully completed......................................
2023-07-08 10:04:25,524:INFO:Initializing plot_model()
2023-07-08 10:04:25,524:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='deviance', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=270, n_iter_no_change=None,
                           random_state=42, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, system=True)
2023-07-08 10:04:25,525:INFO:Checking exceptions
2023-07-08 10:04:25,528:INFO:Preloading libraries
2023-07-08 10:04:25,550:INFO:Copying training dataset
2023-07-08 10:04:25,550:INFO:Plot type: parameter
2023-07-08 10:04:25,553:INFO:Visual Rendered Successfully
2023-07-08 10:04:25,613:INFO:plot_model() successfully completed......................................
2023-07-08 10:04:29,487:INFO:Initializing plot_model()
2023-07-08 10:04:29,487:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='deviance', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=270, n_iter_no_change=None,
                           random_state=42, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, system=True)
2023-07-08 10:04:29,487:INFO:Checking exceptions
2023-07-08 10:04:29,490:INFO:Preloading libraries
2023-07-08 10:04:29,512:INFO:Copying training dataset
2023-07-08 10:04:29,512:INFO:Plot type: auc
2023-07-08 10:04:29,580:INFO:Fitting Model
2023-07-08 10:04:29,583:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-07-08 10:04:29,583:INFO:Scoring test/hold-out set
2023-07-08 10:04:29,791:INFO:Visual Rendered Successfully
2023-07-08 10:04:29,864:INFO:plot_model() successfully completed......................................
2023-07-08 10:04:34,675:INFO:Initializing plot_model()
2023-07-08 10:04:34,676:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='deviance', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=270, n_iter_no_change=None,
                           random_state=42, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, system=True)
2023-07-08 10:04:34,676:INFO:Checking exceptions
2023-07-08 10:04:34,680:INFO:Preloading libraries
2023-07-08 10:04:34,703:INFO:Copying training dataset
2023-07-08 10:04:34,703:INFO:Plot type: confusion_matrix
2023-07-08 10:04:34,776:INFO:Fitting Model
2023-07-08 10:04:34,776:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-07-08 10:04:34,776:INFO:Scoring test/hold-out set
2023-07-08 10:04:34,887:INFO:Visual Rendered Successfully
2023-07-08 10:04:34,948:INFO:plot_model() successfully completed......................................
2023-07-08 10:05:02,382:INFO:Initializing plot_model()
2023-07-08 10:05:02,382:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='deviance', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=270, n_iter_no_change=None,
                           random_state=42, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, system=True)
2023-07-08 10:05:02,382:INFO:Checking exceptions
2023-07-08 10:05:02,387:INFO:Preloading libraries
2023-07-08 10:05:02,408:INFO:Copying training dataset
2023-07-08 10:05:02,408:INFO:Plot type: threshold
2023-07-08 10:05:02,470:INFO:Fitting Model
2023-07-08 10:05:18,336:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-07-08 10:05:18,353:INFO:Scoring test/hold-out set
2023-07-08 10:05:18,720:INFO:Visual Rendered Successfully
2023-07-08 10:05:18,780:INFO:plot_model() successfully completed......................................
2023-07-08 10:05:18,789:INFO:Initializing plot_model()
2023-07-08 10:05:18,789:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='deviance', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=270, n_iter_no_change=None,
                           random_state=42, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, system=True)
2023-07-08 10:05:18,789:INFO:Checking exceptions
2023-07-08 10:05:18,794:INFO:Preloading libraries
2023-07-08 10:05:18,821:INFO:Copying training dataset
2023-07-08 10:05:18,821:INFO:Plot type: pr
2023-07-08 10:05:18,888:INFO:Fitting Model
2023-07-08 10:05:18,888:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-07-08 10:05:18,888:INFO:Scoring test/hold-out set
2023-07-08 10:05:19,035:INFO:Visual Rendered Successfully
2023-07-08 10:05:19,095:INFO:plot_model() successfully completed......................................
2023-07-08 10:05:19,106:INFO:Initializing plot_model()
2023-07-08 10:05:19,106:INFO:plot_model(plot=rfe, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='deviance', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=270, n_iter_no_change=None,
                           random_state=42, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E30D120AC0>, system=True)
2023-07-08 10:05:19,107:INFO:Checking exceptions
2023-07-08 10:05:19,110:INFO:Preloading libraries
2023-07-08 10:05:19,130:INFO:Copying training dataset
2023-07-08 10:05:19,130:INFO:Plot type: rfe
2023-07-08 10:05:19,216:INFO:Fitting Model
2023-07-08 10:08:52,242:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_4de4c4dbaca2414197a8368b33d21999_7c858abefef24263af9f2605cf069a6c
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,242:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_9e861200e3ce47f88caf34e7d74d2620_c3033b496aa943a3bcbc3c616f3cc2e5
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,242:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_4de4c4dbaca2414197a8368b33d21999_c56178b1a5b44e72acec4367a10e3e2c
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,243:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_5753325587b94fd4b9d2867f0a626cae_0740a9e005574079af4da427d486e2c4
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,244:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_4de4c4dbaca2414197a8368b33d21999_2123e6c045be46eab0698587bd59fb19
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,244:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_79f369dced334840be4b9249cc636de7_793375db5cab41dbaf26d12c76d23a49
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,244:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_4de4c4dbaca2414197a8368b33d21999_d1868a1fe22f4789b7410cc8f6d39661
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,244:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_44d0a01640354ad798c12cb289c50576_85050745a92249a8b269cae7b941af1e
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,244:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_4de4c4dbaca2414197a8368b33d21999_bb59dc616f1a430290252a909b9a3b67
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,244:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_df66621f04584e38b5470a6d51552e2f_acdb69dc05844171be5e89930b269531
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,244:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_4de4c4dbaca2414197a8368b33d21999_37bb8636562548e583ca08afc87a078d
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,244:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_a9fb962ba9824b56a11ee73a505fca66_94d436e8aa11448bac2cd2fffddf38d7
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,244:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_4de4c4dbaca2414197a8368b33d21999_6d01fea999d24f15948b5b65cedfc051
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,244:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_9448060c236e4ec08ed3ba71514e8c68_c2a141dcdfab4af48c31bff542d38dea
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,244:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_4de4c4dbaca2414197a8368b33d21999_79d2e76d11774a0da0821b94884ce7b3
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,244:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_a6482d6408224e68a9a2188bd51397ff_77b199c80e1147d6bed3963eb712a3e2
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,245:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_4de4c4dbaca2414197a8368b33d21999_9cdb3ab49ae744f9a108a25568201641
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,245:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_d7d57a75d06c48b0b5a2bdf9e0eac84b_0ce1313e59b64137bc5d36fa3ddea834
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,245:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_4de4c4dbaca2414197a8368b33d21999_5c66c4121f2343d08d570c5cb1a5555a
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,245:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_8df1c2aeff0448c6a341599ce3df0f6b_9f4a1945a66249659001b274fe711cba
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,245:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_4de4c4dbaca2414197a8368b33d21999_641cc28d76e64d8babba7af8e0cb5ac9
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,245:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_31a37b0ad21742bb81c331e7910a5ca7_a8f840a20faa45648c6d39bc5d877fbd
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,245:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_4de4c4dbaca2414197a8368b33d21999_cd1cda7189804ef4bb25d74c221a82ec
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,246:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_8dc7d0bd437c4f479800e4cea5829582_f20e6659f88745b4a9eb2523c69a4cbe
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,246:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_4de4c4dbaca2414197a8368b33d21999_2d65862a632d4d67a218abbc098f64ff
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,246:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_e3cb945c239c47b8bf3a05ebcdf9ed93_7f57ea66d2cc4c30b4fada6a8ada6d57
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,246:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_4de4c4dbaca2414197a8368b33d21999_3d70cccb9cd84fa3876b174bc25c02d9
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,246:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_cb5bf7118a144599b4963396fcf3e098_6a744d05bb7e4ddf911e4a96ace7695d
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,246:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_4de4c4dbaca2414197a8368b33d21999_14ee7579fdbc401d8d66ef5e3c15670b
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,246:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_a31ccbe5bcd54a908b7607b7e045867c_c5e0ad0b55264688878b014f9b906704
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,246:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_4de4c4dbaca2414197a8368b33d21999_7129a073211644ddb3e7e5360dc36585
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,246:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_63319ea6b13f49f086fdf3c62bead95b_5d772541264c4ed786af6f576767458e
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,247:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_4de4c4dbaca2414197a8368b33d21999_a6ddef6729644d3780127b43425370f0
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:08:52,247:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\Users\hamim\AppData\Local\Temp\joblib_memmapping_folder_13248_4de4c4dbaca2414197a8368b33d21999_77857a3990dd4fe2b762bc4472dadde9
  warnings.warn("Failed to delete temporary folder: {}"

2023-07-08 10:10:17,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-08 10:10:17,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-08 10:10:17,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-08 10:10:17,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-08 10:10:59,353:INFO:PyCaret ClassificationExperiment
2023-07-08 10:10:59,353:INFO:Logging name: clf-default-name
2023-07-08 10:10:59,353:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-08 10:10:59,354:INFO:version 3.0.4
2023-07-08 10:10:59,354:INFO:Initializing setup()
2023-07-08 10:10:59,354:INFO:self.USI: 91c0
2023-07-08 10:10:59,354:INFO:self._variable_keys: {'seed', 'y_train', 'exp_id', '_available_plots', 'USI', 'pipeline', 'X_test', 'fix_imbalance', 'fold_generator', '_ml_usecase', 'memory', 'idx', 'html_param', 'fold_shuffle_param', 'X_train', 'X', 'gpu_param', 'y', 'y_test', 'data', 'fold_groups_param', 'n_jobs_param', 'target_param', 'is_multiclass', 'gpu_n_jobs_param', 'logging_param', 'log_plots_param', 'exp_name_log'}
2023-07-08 10:10:59,354:INFO:Checking environment
2023-07-08 10:10:59,354:INFO:python_version: 3.9.13
2023-07-08 10:10:59,354:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-07-08 10:10:59,354:INFO:machine: AMD64
2023-07-08 10:10:59,354:INFO:platform: Windows-10-10.0.19045-SP0
2023-07-08 10:10:59,354:INFO:Memory: svmem(total=17125732352, available=10247974912, percent=40.2, used=6877757440, free=10247974912)
2023-07-08 10:10:59,354:INFO:Physical Core: 4
2023-07-08 10:10:59,354:INFO:Logical Core: 8
2023-07-08 10:10:59,354:INFO:Checking libraries
2023-07-08 10:10:59,354:INFO:System:
2023-07-08 10:10:59,354:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-07-08 10:10:59,354:INFO:executable: C:\Users\hamim\anaconda3\python.exe
2023-07-08 10:10:59,354:INFO:   machine: Windows-10-10.0.19045-SP0
2023-07-08 10:10:59,354:INFO:PyCaret required dependencies:
2023-07-08 10:10:59,357:INFO:                 pip: 22.2.2
2023-07-08 10:10:59,357:INFO:          setuptools: 63.4.1
2023-07-08 10:10:59,357:INFO:             pycaret: 3.0.4
2023-07-08 10:10:59,357:INFO:             IPython: 7.31.1
2023-07-08 10:10:59,357:INFO:          ipywidgets: 7.6.5
2023-07-08 10:10:59,357:INFO:                tqdm: 4.64.1
2023-07-08 10:10:59,357:INFO:               numpy: 1.21.5
2023-07-08 10:10:59,357:INFO:              pandas: 1.4.4
2023-07-08 10:10:59,357:INFO:              jinja2: 2.11.3
2023-07-08 10:10:59,358:INFO:               scipy: 1.9.1
2023-07-08 10:10:59,358:INFO:              joblib: 1.2.0
2023-07-08 10:10:59,358:INFO:             sklearn: 1.0.2
2023-07-08 10:10:59,358:INFO:                pyod: 1.1.0
2023-07-08 10:10:59,358:INFO:            imblearn: 0.10.1
2023-07-08 10:10:59,358:INFO:   category_encoders: 2.6.1
2023-07-08 10:10:59,358:INFO:            lightgbm: 3.3.5
2023-07-08 10:10:59,358:INFO:               numba: 0.55.1
2023-07-08 10:10:59,358:INFO:            requests: 2.28.1
2023-07-08 10:10:59,358:INFO:          matplotlib: 3.5.2
2023-07-08 10:10:59,358:INFO:          scikitplot: 0.3.7
2023-07-08 10:10:59,358:INFO:         yellowbrick: 1.5
2023-07-08 10:10:59,358:INFO:              plotly: 5.9.0
2023-07-08 10:10:59,358:INFO:    plotly-resampler: Not installed
2023-07-08 10:10:59,358:INFO:             kaleido: 0.2.1
2023-07-08 10:10:59,358:INFO:           schemdraw: 0.15
2023-07-08 10:10:59,358:INFO:         statsmodels: 0.13.2
2023-07-08 10:10:59,358:INFO:              sktime: 0.20.0
2023-07-08 10:10:59,358:INFO:               tbats: 1.1.3
2023-07-08 10:10:59,358:INFO:            pmdarima: 2.0.3
2023-07-08 10:10:59,359:INFO:              psutil: 5.9.0
2023-07-08 10:10:59,359:INFO:          markupsafe: 2.0.1
2023-07-08 10:10:59,359:INFO:             pickle5: Not installed
2023-07-08 10:10:59,359:INFO:         cloudpickle: 2.0.0
2023-07-08 10:10:59,359:INFO:         deprecation: 2.1.0
2023-07-08 10:10:59,359:INFO:              xxhash: 3.2.0
2023-07-08 10:10:59,359:INFO:           wurlitzer: Not installed
2023-07-08 10:10:59,359:INFO:PyCaret optional dependencies:
2023-07-08 10:10:59,380:INFO:                shap: Not installed
2023-07-08 10:10:59,380:INFO:           interpret: Not installed
2023-07-08 10:10:59,380:INFO:                umap: Not installed
2023-07-08 10:10:59,380:INFO:    pandas_profiling: Not installed
2023-07-08 10:10:59,380:INFO:  explainerdashboard: Not installed
2023-07-08 10:10:59,380:INFO:             autoviz: Not installed
2023-07-08 10:10:59,380:INFO:           fairlearn: Not installed
2023-07-08 10:10:59,380:INFO:          deepchecks: Not installed
2023-07-08 10:10:59,380:INFO:             xgboost: Not installed
2023-07-08 10:10:59,380:INFO:            catboost: Not installed
2023-07-08 10:10:59,380:INFO:              kmodes: Not installed
2023-07-08 10:10:59,380:INFO:             mlxtend: Not installed
2023-07-08 10:10:59,380:INFO:       statsforecast: Not installed
2023-07-08 10:10:59,381:INFO:        tune_sklearn: Not installed
2023-07-08 10:10:59,381:INFO:                 ray: Not installed
2023-07-08 10:10:59,381:INFO:            hyperopt: Not installed
2023-07-08 10:10:59,381:INFO:              optuna: Not installed
2023-07-08 10:10:59,381:INFO:               skopt: Not installed
2023-07-08 10:10:59,381:INFO:              mlflow: Not installed
2023-07-08 10:10:59,381:INFO:              gradio: Not installed
2023-07-08 10:10:59,381:INFO:             fastapi: Not installed
2023-07-08 10:10:59,381:INFO:             uvicorn: Not installed
2023-07-08 10:10:59,381:INFO:              m2cgen: Not installed
2023-07-08 10:10:59,381:INFO:           evidently: Not installed
2023-07-08 10:10:59,381:INFO:               fugue: Not installed
2023-07-08 10:10:59,381:INFO:           streamlit: Not installed
2023-07-08 10:10:59,381:INFO:             prophet: Not installed
2023-07-08 10:10:59,381:INFO:None
2023-07-08 10:10:59,381:INFO:Set up data.
2023-07-08 10:10:59,396:INFO:Set up train/test split.
2023-07-08 10:10:59,402:INFO:Set up index.
2023-07-08 10:10:59,402:INFO:Set up folding strategy.
2023-07-08 10:10:59,402:INFO:Assigning column types.
2023-07-08 10:10:59,406:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-08 10:10:59,458:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-08 10:10:59,461:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 10:10:59,502:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 10:10:59,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 10:10:59,715:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-08 10:10:59,716:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 10:10:59,748:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 10:10:59,749:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 10:10:59,749:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-08 10:10:59,807:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 10:10:59,841:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 10:10:59,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 10:10:59,893:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 10:10:59,921:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 10:10:59,921:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 10:10:59,921:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-08 10:10:59,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 10:10:59,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 10:11:00,064:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 10:11:00,064:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 10:11:00,066:INFO:Preparing preprocessing pipeline...
2023-07-08 10:11:00,068:INFO:Set up simple imputation.
2023-07-08 10:11:00,068:INFO:Set up imbalanced handling.
2023-07-08 10:11:00,069:INFO:Set up column name cleaning.
2023-07-08 10:11:00,203:INFO:Finished creating preprocessing pipeline.
2023-07-08 10:11:00,217:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-08 10:11:00,217:INFO:Creating final display dataframe.
2023-07-08 10:11:00,306:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Target
2                   Target type            Binary
3           Original data shape        (2802, 34)
4        Transformed data shape        (3825, 34)
5   Transformed train set shape        (2984, 34)
6    Transformed test set shape         (841, 34)
7              Numeric features                33
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              91c0
2023-07-08 10:11:00,387:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 10:11:00,387:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 10:11:00,466:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 10:11:00,466:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 10:11:00,467:INFO:setup() successfully completed in 1.29s...............
2023-07-08 10:11:04,829:INFO:Initializing compare_models()
2023-07-08 10:11:04,829:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-08 10:11:04,830:INFO:Checking exceptions
2023-07-08 10:11:04,835:INFO:Preparing display monitor
2023-07-08 10:11:04,880:INFO:Initializing Logistic Regression
2023-07-08 10:11:04,880:INFO:Total runtime is 0.0 minutes
2023-07-08 10:11:04,884:INFO:SubProcess create_model() called ==================================
2023-07-08 10:11:04,884:INFO:Initializing create_model()
2023-07-08 10:11:04,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002041B8E9580>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 10:11:04,884:INFO:Checking exceptions
2023-07-08 10:11:04,884:INFO:Importing libraries
2023-07-08 10:11:04,885:INFO:Copying training dataset
2023-07-08 10:11:04,890:INFO:Defining folds
2023-07-08 10:11:04,890:INFO:Declaring metric variables
2023-07-08 10:11:04,894:INFO:Importing untrained model
2023-07-08 10:11:04,898:INFO:Logistic Regression Imported successfully
2023-07-08 10:11:04,907:INFO:Starting cross validation
2023-07-08 10:11:04,909:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 10:11:14,596:INFO:Calculating mean and std
2023-07-08 10:11:14,597:INFO:Creating metrics dataframe
2023-07-08 10:11:14,895:INFO:Uploading results into container
2023-07-08 10:11:14,896:INFO:Uploading model into container now
2023-07-08 10:11:14,896:INFO:_master_model_container: 1
2023-07-08 10:11:14,897:INFO:_display_container: 2
2023-07-08 10:11:14,897:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-08 10:11:14,897:INFO:create_model() successfully completed......................................
2023-07-08 10:11:14,967:INFO:SubProcess create_model() end ==================================
2023-07-08 10:11:14,967:INFO:Creating metrics dataframe
2023-07-08 10:11:14,978:INFO:Initializing K Neighbors Classifier
2023-07-08 10:11:14,978:INFO:Total runtime is 0.1682959794998169 minutes
2023-07-08 10:11:14,983:INFO:SubProcess create_model() called ==================================
2023-07-08 10:11:14,983:INFO:Initializing create_model()
2023-07-08 10:11:14,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002041B8E9580>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 10:11:14,984:INFO:Checking exceptions
2023-07-08 10:11:14,984:INFO:Importing libraries
2023-07-08 10:11:14,984:INFO:Copying training dataset
2023-07-08 10:11:14,990:INFO:Defining folds
2023-07-08 10:11:14,990:INFO:Declaring metric variables
2023-07-08 10:11:14,995:INFO:Importing untrained model
2023-07-08 10:11:15,001:INFO:K Neighbors Classifier Imported successfully
2023-07-08 10:11:15,013:INFO:Starting cross validation
2023-07-08 10:11:15,016:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 10:11:15,247:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 10:11:15,248:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 10:11:15,267:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 10:11:15,278:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 10:11:15,310:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 10:11:15,314:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 10:11:15,315:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 10:11:15,318:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 10:11:15,931:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 10:11:15,962:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 10:11:17,272:INFO:Calculating mean and std
2023-07-08 10:11:17,273:INFO:Creating metrics dataframe
2023-07-08 10:11:17,533:INFO:Uploading results into container
2023-07-08 10:11:17,534:INFO:Uploading model into container now
2023-07-08 10:11:17,534:INFO:_master_model_container: 2
2023-07-08 10:11:17,534:INFO:_display_container: 2
2023-07-08 10:11:17,534:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-08 10:11:17,535:INFO:create_model() successfully completed......................................
2023-07-08 10:11:17,598:INFO:SubProcess create_model() end ==================================
2023-07-08 10:11:17,598:INFO:Creating metrics dataframe
2023-07-08 10:11:17,608:INFO:Initializing Naive Bayes
2023-07-08 10:11:17,608:INFO:Total runtime is 0.21212622324625652 minutes
2023-07-08 10:11:17,612:INFO:SubProcess create_model() called ==================================
2023-07-08 10:11:17,612:INFO:Initializing create_model()
2023-07-08 10:11:17,613:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002041B8E9580>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 10:11:17,613:INFO:Checking exceptions
2023-07-08 10:11:17,613:INFO:Importing libraries
2023-07-08 10:11:17,613:INFO:Copying training dataset
2023-07-08 10:11:17,618:INFO:Defining folds
2023-07-08 10:11:17,618:INFO:Declaring metric variables
2023-07-08 10:11:17,622:INFO:Importing untrained model
2023-07-08 10:11:17,627:INFO:Naive Bayes Imported successfully
2023-07-08 10:11:17,639:INFO:Starting cross validation
2023-07-08 10:11:17,641:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 10:11:19,622:INFO:Calculating mean and std
2023-07-08 10:11:19,623:INFO:Creating metrics dataframe
2023-07-08 10:11:19,879:INFO:Uploading results into container
2023-07-08 10:11:19,880:INFO:Uploading model into container now
2023-07-08 10:11:19,881:INFO:_master_model_container: 3
2023-07-08 10:11:19,881:INFO:_display_container: 2
2023-07-08 10:11:19,881:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-08 10:11:19,881:INFO:create_model() successfully completed......................................
2023-07-08 10:11:19,944:INFO:SubProcess create_model() end ==================================
2023-07-08 10:11:19,944:INFO:Creating metrics dataframe
2023-07-08 10:11:19,953:INFO:Initializing Decision Tree Classifier
2023-07-08 10:11:19,954:INFO:Total runtime is 0.25122895240783694 minutes
2023-07-08 10:11:19,958:INFO:SubProcess create_model() called ==================================
2023-07-08 10:11:19,959:INFO:Initializing create_model()
2023-07-08 10:11:19,959:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002041B8E9580>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 10:11:19,959:INFO:Checking exceptions
2023-07-08 10:11:19,959:INFO:Importing libraries
2023-07-08 10:11:19,959:INFO:Copying training dataset
2023-07-08 10:11:19,965:INFO:Defining folds
2023-07-08 10:11:19,965:INFO:Declaring metric variables
2023-07-08 10:11:19,970:INFO:Importing untrained model
2023-07-08 10:11:19,976:INFO:Decision Tree Classifier Imported successfully
2023-07-08 10:11:19,986:INFO:Starting cross validation
2023-07-08 10:11:19,988:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 10:11:21,972:INFO:Calculating mean and std
2023-07-08 10:11:21,974:INFO:Creating metrics dataframe
2023-07-08 10:11:22,229:INFO:Uploading results into container
2023-07-08 10:11:22,230:INFO:Uploading model into container now
2023-07-08 10:11:22,231:INFO:_master_model_container: 4
2023-07-08 10:11:22,231:INFO:_display_container: 2
2023-07-08 10:11:22,231:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-08 10:11:22,231:INFO:create_model() successfully completed......................................
2023-07-08 10:11:22,294:INFO:SubProcess create_model() end ==================================
2023-07-08 10:11:22,294:INFO:Creating metrics dataframe
2023-07-08 10:11:22,304:INFO:Initializing SVM - Linear Kernel
2023-07-08 10:11:22,304:INFO:Total runtime is 0.29040343761444093 minutes
2023-07-08 10:11:22,308:INFO:SubProcess create_model() called ==================================
2023-07-08 10:11:22,309:INFO:Initializing create_model()
2023-07-08 10:11:22,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002041B8E9580>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 10:11:22,309:INFO:Checking exceptions
2023-07-08 10:11:22,309:INFO:Importing libraries
2023-07-08 10:11:22,309:INFO:Copying training dataset
2023-07-08 10:11:22,314:INFO:Defining folds
2023-07-08 10:11:22,315:INFO:Declaring metric variables
2023-07-08 10:11:22,318:INFO:Importing untrained model
2023-07-08 10:11:22,324:INFO:SVM - Linear Kernel Imported successfully
2023-07-08 10:11:22,333:INFO:Starting cross validation
2023-07-08 10:11:22,335:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 10:11:22,542:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 10:11:22,573:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 10:11:22,639:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 10:11:22,662:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 10:11:23,097:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 10:11:23,104:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 10:11:24,342:INFO:Calculating mean and std
2023-07-08 10:11:24,343:INFO:Creating metrics dataframe
2023-07-08 10:11:24,611:INFO:Uploading results into container
2023-07-08 10:11:24,611:INFO:Uploading model into container now
2023-07-08 10:11:24,612:INFO:_master_model_container: 5
2023-07-08 10:11:24,612:INFO:_display_container: 2
2023-07-08 10:11:24,612:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-08 10:11:24,613:INFO:create_model() successfully completed......................................
2023-07-08 10:11:24,675:INFO:SubProcess create_model() end ==================================
2023-07-08 10:11:24,675:INFO:Creating metrics dataframe
2023-07-08 10:11:24,688:INFO:Initializing Ridge Classifier
2023-07-08 10:11:24,688:INFO:Total runtime is 0.3301380435625712 minutes
2023-07-08 10:11:24,693:INFO:SubProcess create_model() called ==================================
2023-07-08 10:11:24,694:INFO:Initializing create_model()
2023-07-08 10:11:24,694:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002041B8E9580>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 10:11:24,694:INFO:Checking exceptions
2023-07-08 10:11:24,694:INFO:Importing libraries
2023-07-08 10:11:24,694:INFO:Copying training dataset
2023-07-08 10:11:24,699:INFO:Defining folds
2023-07-08 10:11:24,700:INFO:Declaring metric variables
2023-07-08 10:11:24,705:INFO:Importing untrained model
2023-07-08 10:11:24,712:INFO:Ridge Classifier Imported successfully
2023-07-08 10:11:24,727:INFO:Starting cross validation
2023-07-08 10:11:24,728:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 10:11:24,885:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 10:11:24,906:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 10:11:24,926:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 10:11:24,934:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 10:11:24,937:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 10:11:24,953:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 10:11:24,973:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 10:11:25,007:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 10:11:25,431:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 10:11:25,459:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 10:11:26,947:INFO:Calculating mean and std
2023-07-08 10:11:26,948:INFO:Creating metrics dataframe
2023-07-08 10:11:27,260:INFO:Uploading results into container
2023-07-08 10:11:27,260:INFO:Uploading model into container now
2023-07-08 10:11:27,261:INFO:_master_model_container: 6
2023-07-08 10:11:27,261:INFO:_display_container: 2
2023-07-08 10:11:27,261:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=42, solver='auto', tol=0.001)
2023-07-08 10:11:27,261:INFO:create_model() successfully completed......................................
2023-07-08 10:11:27,345:INFO:SubProcess create_model() end ==================================
2023-07-08 10:11:27,346:INFO:Creating metrics dataframe
2023-07-08 10:11:27,371:INFO:Initializing Random Forest Classifier
2023-07-08 10:11:27,372:INFO:Total runtime is 0.3748693029085795 minutes
2023-07-08 10:11:27,378:INFO:SubProcess create_model() called ==================================
2023-07-08 10:11:27,379:INFO:Initializing create_model()
2023-07-08 10:11:27,379:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002041B8E9580>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 10:11:27,379:INFO:Checking exceptions
2023-07-08 10:11:27,380:INFO:Importing libraries
2023-07-08 10:11:27,380:INFO:Copying training dataset
2023-07-08 10:11:27,395:INFO:Defining folds
2023-07-08 10:11:27,396:INFO:Declaring metric variables
2023-07-08 10:11:27,404:INFO:Importing untrained model
2023-07-08 10:11:27,413:INFO:Random Forest Classifier Imported successfully
2023-07-08 10:11:27,430:INFO:Starting cross validation
2023-07-08 10:11:27,433:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 10:11:31,247:INFO:Calculating mean and std
2023-07-08 10:11:31,249:INFO:Creating metrics dataframe
2023-07-08 10:11:31,530:INFO:Uploading results into container
2023-07-08 10:11:31,531:INFO:Uploading model into container now
2023-07-08 10:11:31,532:INFO:_master_model_container: 7
2023-07-08 10:11:31,532:INFO:_display_container: 2
2023-07-08 10:11:31,532:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-08 10:11:31,532:INFO:create_model() successfully completed......................................
2023-07-08 10:11:31,600:INFO:SubProcess create_model() end ==================================
2023-07-08 10:11:31,600:INFO:Creating metrics dataframe
2023-07-08 10:11:31,611:INFO:Initializing Quadratic Discriminant Analysis
2023-07-08 10:11:31,611:INFO:Total runtime is 0.4455100218454997 minutes
2023-07-08 10:11:31,616:INFO:SubProcess create_model() called ==================================
2023-07-08 10:11:31,617:INFO:Initializing create_model()
2023-07-08 10:11:31,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002041B8E9580>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 10:11:31,617:INFO:Checking exceptions
2023-07-08 10:11:31,617:INFO:Importing libraries
2023-07-08 10:11:31,617:INFO:Copying training dataset
2023-07-08 10:11:31,623:INFO:Defining folds
2023-07-08 10:11:31,623:INFO:Declaring metric variables
2023-07-08 10:11:31,627:INFO:Importing untrained model
2023-07-08 10:11:31,633:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-08 10:11:31,646:INFO:Starting cross validation
2023-07-08 10:11:31,648:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 10:11:31,807:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 10:11:31,812:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 10:11:31,862:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 10:11:31,863:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 10:11:31,872:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 10:11:31,876:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 10:11:31,888:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 10:11:31,890:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 10:11:31,959:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 10:11:32,055:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 10:11:32,568:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 10:11:32,570:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 10:11:32,636:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 10:11:32,644:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 10:11:34,134:INFO:Calculating mean and std
2023-07-08 10:11:34,135:INFO:Creating metrics dataframe
2023-07-08 10:11:34,406:INFO:Uploading results into container
2023-07-08 10:11:34,407:INFO:Uploading model into container now
2023-07-08 10:11:34,407:INFO:_master_model_container: 8
2023-07-08 10:11:34,408:INFO:_display_container: 2
2023-07-08 10:11:34,408:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-08 10:11:34,408:INFO:create_model() successfully completed......................................
2023-07-08 10:11:34,479:INFO:SubProcess create_model() end ==================================
2023-07-08 10:11:34,479:INFO:Creating metrics dataframe
2023-07-08 10:11:34,492:INFO:Initializing Ada Boost Classifier
2023-07-08 10:11:34,492:INFO:Total runtime is 0.493533209959666 minutes
2023-07-08 10:11:34,497:INFO:SubProcess create_model() called ==================================
2023-07-08 10:11:34,497:INFO:Initializing create_model()
2023-07-08 10:11:34,497:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002041B8E9580>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 10:11:34,498:INFO:Checking exceptions
2023-07-08 10:11:34,498:INFO:Importing libraries
2023-07-08 10:11:34,498:INFO:Copying training dataset
2023-07-08 10:11:34,504:INFO:Defining folds
2023-07-08 10:11:34,504:INFO:Declaring metric variables
2023-07-08 10:11:34,508:INFO:Importing untrained model
2023-07-08 10:11:34,514:INFO:Ada Boost Classifier Imported successfully
2023-07-08 10:11:34,528:INFO:Starting cross validation
2023-07-08 10:11:34,531:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 10:11:37,576:INFO:Calculating mean and std
2023-07-08 10:11:37,578:INFO:Creating metrics dataframe
2023-07-08 10:11:37,893:INFO:Uploading results into container
2023-07-08 10:11:37,894:INFO:Uploading model into container now
2023-07-08 10:11:37,894:INFO:_master_model_container: 9
2023-07-08 10:11:37,894:INFO:_display_container: 2
2023-07-08 10:11:37,895:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2023-07-08 10:11:37,895:INFO:create_model() successfully completed......................................
2023-07-08 10:11:37,957:INFO:SubProcess create_model() end ==================================
2023-07-08 10:11:37,957:INFO:Creating metrics dataframe
2023-07-08 10:11:37,968:INFO:Initializing Gradient Boosting Classifier
2023-07-08 10:11:37,968:INFO:Total runtime is 0.5514673511187236 minutes
2023-07-08 10:11:37,972:INFO:SubProcess create_model() called ==================================
2023-07-08 10:11:37,972:INFO:Initializing create_model()
2023-07-08 10:11:37,972:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002041B8E9580>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 10:11:37,973:INFO:Checking exceptions
2023-07-08 10:11:37,973:INFO:Importing libraries
2023-07-08 10:11:37,974:INFO:Copying training dataset
2023-07-08 10:11:37,979:INFO:Defining folds
2023-07-08 10:11:37,979:INFO:Declaring metric variables
2023-07-08 10:11:37,982:INFO:Importing untrained model
2023-07-08 10:11:37,987:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 10:11:37,996:INFO:Starting cross validation
2023-07-08 10:11:37,998:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 10:11:40,831:INFO:Calculating mean and std
2023-07-08 10:11:40,833:INFO:Creating metrics dataframe
2023-07-08 10:11:41,115:INFO:Uploading results into container
2023-07-08 10:11:41,115:INFO:Uploading model into container now
2023-07-08 10:11:41,116:INFO:_master_model_container: 10
2023-07-08 10:11:41,116:INFO:_display_container: 2
2023-07-08 10:11:41,117:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 10:11:41,117:INFO:create_model() successfully completed......................................
2023-07-08 10:11:41,185:INFO:SubProcess create_model() end ==================================
2023-07-08 10:11:41,185:INFO:Creating metrics dataframe
2023-07-08 10:11:41,198:INFO:Initializing Linear Discriminant Analysis
2023-07-08 10:11:41,198:INFO:Total runtime is 0.6052987496058146 minutes
2023-07-08 10:11:41,202:INFO:SubProcess create_model() called ==================================
2023-07-08 10:11:41,203:INFO:Initializing create_model()
2023-07-08 10:11:41,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002041B8E9580>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 10:11:41,203:INFO:Checking exceptions
2023-07-08 10:11:41,203:INFO:Importing libraries
2023-07-08 10:11:41,203:INFO:Copying training dataset
2023-07-08 10:11:41,210:INFO:Defining folds
2023-07-08 10:11:41,210:INFO:Declaring metric variables
2023-07-08 10:11:41,214:INFO:Importing untrained model
2023-07-08 10:11:41,220:INFO:Linear Discriminant Analysis Imported successfully
2023-07-08 10:11:41,233:INFO:Starting cross validation
2023-07-08 10:11:41,235:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 10:11:43,436:INFO:Calculating mean and std
2023-07-08 10:11:43,438:INFO:Creating metrics dataframe
2023-07-08 10:11:43,757:INFO:Uploading results into container
2023-07-08 10:11:43,757:INFO:Uploading model into container now
2023-07-08 10:11:43,758:INFO:_master_model_container: 11
2023-07-08 10:11:43,758:INFO:_display_container: 2
2023-07-08 10:11:43,759:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-08 10:11:43,759:INFO:create_model() successfully completed......................................
2023-07-08 10:11:43,831:INFO:SubProcess create_model() end ==================================
2023-07-08 10:11:43,831:INFO:Creating metrics dataframe
2023-07-08 10:11:43,847:INFO:Initializing Extra Trees Classifier
2023-07-08 10:11:43,847:INFO:Total runtime is 0.6494465788205465 minutes
2023-07-08 10:11:43,851:INFO:SubProcess create_model() called ==================================
2023-07-08 10:11:43,852:INFO:Initializing create_model()
2023-07-08 10:11:43,852:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002041B8E9580>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 10:11:43,852:INFO:Checking exceptions
2023-07-08 10:11:43,852:INFO:Importing libraries
2023-07-08 10:11:43,853:INFO:Copying training dataset
2023-07-08 10:11:43,861:INFO:Defining folds
2023-07-08 10:11:43,861:INFO:Declaring metric variables
2023-07-08 10:11:43,866:INFO:Importing untrained model
2023-07-08 10:11:43,871:INFO:Extra Trees Classifier Imported successfully
2023-07-08 10:11:43,883:INFO:Starting cross validation
2023-07-08 10:11:43,884:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 10:11:47,795:INFO:Calculating mean and std
2023-07-08 10:11:47,797:INFO:Creating metrics dataframe
2023-07-08 10:11:48,117:INFO:Uploading results into container
2023-07-08 10:11:48,118:INFO:Uploading model into container now
2023-07-08 10:11:48,119:INFO:_master_model_container: 12
2023-07-08 10:11:48,119:INFO:_display_container: 2
2023-07-08 10:11:48,120:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-08 10:11:48,120:INFO:create_model() successfully completed......................................
2023-07-08 10:11:48,191:INFO:SubProcess create_model() end ==================================
2023-07-08 10:11:48,191:INFO:Creating metrics dataframe
2023-07-08 10:11:48,205:INFO:Initializing Light Gradient Boosting Machine
2023-07-08 10:11:48,206:INFO:Total runtime is 0.7220971345901489 minutes
2023-07-08 10:11:48,211:INFO:SubProcess create_model() called ==================================
2023-07-08 10:11:48,212:INFO:Initializing create_model()
2023-07-08 10:11:48,212:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002041B8E9580>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 10:11:48,213:INFO:Checking exceptions
2023-07-08 10:11:48,213:INFO:Importing libraries
2023-07-08 10:11:48,213:INFO:Copying training dataset
2023-07-08 10:11:48,219:INFO:Defining folds
2023-07-08 10:11:48,220:INFO:Declaring metric variables
2023-07-08 10:11:48,228:INFO:Importing untrained model
2023-07-08 10:11:48,235:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-08 10:11:48,247:INFO:Starting cross validation
2023-07-08 10:11:48,249:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 10:11:52,748:INFO:Calculating mean and std
2023-07-08 10:11:52,749:INFO:Creating metrics dataframe
2023-07-08 10:11:53,043:INFO:Uploading results into container
2023-07-08 10:11:53,043:INFO:Uploading model into container now
2023-07-08 10:11:53,044:INFO:_master_model_container: 13
2023-07-08 10:11:53,044:INFO:_display_container: 2
2023-07-08 10:11:53,045:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-08 10:11:53,045:INFO:create_model() successfully completed......................................
2023-07-08 10:11:53,107:INFO:SubProcess create_model() end ==================================
2023-07-08 10:11:53,107:INFO:Creating metrics dataframe
2023-07-08 10:11:53,121:INFO:Initializing Dummy Classifier
2023-07-08 10:11:53,121:INFO:Total runtime is 0.8040199955304463 minutes
2023-07-08 10:11:53,125:INFO:SubProcess create_model() called ==================================
2023-07-08 10:11:53,125:INFO:Initializing create_model()
2023-07-08 10:11:53,126:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002041B8E9580>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 10:11:53,126:INFO:Checking exceptions
2023-07-08 10:11:53,127:INFO:Importing libraries
2023-07-08 10:11:53,127:INFO:Copying training dataset
2023-07-08 10:11:53,133:INFO:Defining folds
2023-07-08 10:11:53,133:INFO:Declaring metric variables
2023-07-08 10:11:53,138:INFO:Importing untrained model
2023-07-08 10:11:53,143:INFO:Dummy Classifier Imported successfully
2023-07-08 10:11:53,156:INFO:Starting cross validation
2023-07-08 10:11:53,158:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 10:11:53,323:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 10:11:53,372:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 10:11:53,384:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 10:11:53,425:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 10:11:53,433:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 10:11:53,448:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 10:11:53,454:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 10:11:53,466:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 10:11:53,923:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 10:11:53,934:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 10:11:55,345:INFO:Calculating mean and std
2023-07-08 10:11:55,347:INFO:Creating metrics dataframe
2023-07-08 10:11:55,636:INFO:Uploading results into container
2023-07-08 10:11:55,637:INFO:Uploading model into container now
2023-07-08 10:11:55,638:INFO:_master_model_container: 14
2023-07-08 10:11:55,638:INFO:_display_container: 2
2023-07-08 10:11:55,638:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-08 10:11:55,638:INFO:create_model() successfully completed......................................
2023-07-08 10:11:55,701:INFO:SubProcess create_model() end ==================================
2023-07-08 10:11:55,701:INFO:Creating metrics dataframe
2023-07-08 10:11:55,722:INFO:Initializing create_model()
2023-07-08 10:11:55,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-08 10:11:55,723:INFO:Checking exceptions
2023-07-08 10:11:55,725:INFO:Importing libraries
2023-07-08 10:11:55,726:INFO:Copying training dataset
2023-07-08 10:11:55,730:INFO:Defining folds
2023-07-08 10:11:55,731:INFO:Declaring metric variables
2023-07-08 10:11:55,731:INFO:Importing untrained model
2023-07-08 10:11:55,731:INFO:Declaring custom model
2023-07-08 10:11:55,733:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 10:11:55,736:INFO:Cross validation set to False
2023-07-08 10:11:55,736:INFO:Fitting Model
2023-07-08 10:11:56,028:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 10:11:56,028:INFO:create_model() successfully completed......................................
2023-07-08 10:11:56,124:INFO:_master_model_container: 14
2023-07-08 10:11:56,124:INFO:_display_container: 2
2023-07-08 10:11:56,125:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 10:11:56,125:INFO:compare_models() successfully completed......................................
2023-07-08 10:12:23,964:INFO:Initializing tune_model()
2023-07-08 10:12:23,964:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>)
2023-07-08 10:12:23,965:INFO:Checking exceptions
2023-07-08 10:12:24,000:INFO:Copying training dataset
2023-07-08 10:12:24,005:INFO:Checking base model
2023-07-08 10:12:24,006:INFO:Base model : Gradient Boosting Classifier
2023-07-08 10:12:24,011:INFO:Declaring metric variables
2023-07-08 10:12:24,017:INFO:Defining Hyperparameters
2023-07-08 10:12:24,082:INFO:Tuning with n_jobs=-1
2023-07-08 10:12:24,082:INFO:Initializing RandomizedSearchCV
2023-07-08 10:12:57,377:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__n_estimators': 110, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 4, 'actual_estimator__learning_rate': 0.4}
2023-07-08 10:12:57,379:INFO:Hyperparameter search completed
2023-07-08 10:12:57,379:INFO:SubProcess create_model() called ==================================
2023-07-08 10:12:57,380:INFO:Initializing create_model()
2023-07-08 10:12:57,380:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002041C04FAC0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.8, 'n_estimators': 110, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0, 'max_features': 'log2', 'max_depth': 4, 'learning_rate': 0.4})
2023-07-08 10:12:57,381:INFO:Checking exceptions
2023-07-08 10:12:57,381:INFO:Importing libraries
2023-07-08 10:12:57,382:INFO:Copying training dataset
2023-07-08 10:12:57,389:INFO:Defining folds
2023-07-08 10:12:57,389:INFO:Declaring metric variables
2023-07-08 10:12:57,393:INFO:Importing untrained model
2023-07-08 10:12:57,394:INFO:Declaring custom model
2023-07-08 10:12:57,399:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 10:12:57,410:INFO:Starting cross validation
2023-07-08 10:12:57,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 10:13:00,547:INFO:Calculating mean and std
2023-07-08 10:13:00,549:INFO:Creating metrics dataframe
2023-07-08 10:13:00,561:INFO:Finalizing model
2023-07-08 10:13:01,298:INFO:Uploading results into container
2023-07-08 10:13:01,300:INFO:Uploading model into container now
2023-07-08 10:13:01,300:INFO:_master_model_container: 15
2023-07-08 10:13:01,301:INFO:_display_container: 3
2023-07-08 10:13:01,301:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='deviance', max_depth=4,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0, min_samples_leaf=2,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=110, n_iter_no_change=None,
                           random_state=42, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 10:13:01,301:INFO:create_model() successfully completed......................................
2023-07-08 10:13:01,381:INFO:SubProcess create_model() end ==================================
2023-07-08 10:13:01,381:INFO:choose_better activated
2023-07-08 10:13:01,385:INFO:SubProcess create_model() called ==================================
2023-07-08 10:13:01,386:INFO:Initializing create_model()
2023-07-08 10:13:01,386:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-08 10:13:01,387:INFO:Checking exceptions
2023-07-08 10:13:01,389:INFO:Importing libraries
2023-07-08 10:13:01,389:INFO:Copying training dataset
2023-07-08 10:13:01,394:INFO:Defining folds
2023-07-08 10:13:01,395:INFO:Declaring metric variables
2023-07-08 10:13:01,395:INFO:Importing untrained model
2023-07-08 10:13:01,395:INFO:Declaring custom model
2023-07-08 10:13:01,395:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 10:13:01,396:INFO:Starting cross validation
2023-07-08 10:13:01,397:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 10:13:04,867:INFO:Calculating mean and std
2023-07-08 10:13:04,868:INFO:Creating metrics dataframe
2023-07-08 10:13:04,870:INFO:Finalizing model
2023-07-08 10:13:05,344:INFO:Uploading results into container
2023-07-08 10:13:05,344:INFO:Uploading model into container now
2023-07-08 10:13:05,345:INFO:_master_model_container: 16
2023-07-08 10:13:05,345:INFO:_display_container: 4
2023-07-08 10:13:05,345:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 10:13:05,345:INFO:create_model() successfully completed......................................
2023-07-08 10:13:05,412:INFO:SubProcess create_model() end ==================================
2023-07-08 10:13:05,413:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8235
2023-07-08 10:13:05,414:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='deviance', max_depth=4,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0, min_samples_leaf=2,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=110, n_iter_no_change=None,
                           random_state=42, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8169
2023-07-08 10:13:05,414:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-07-08 10:13:05,415:INFO:choose_better completed
2023-07-08 10:13:05,415:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-08 10:13:05,427:INFO:_master_model_container: 16
2023-07-08 10:13:05,427:INFO:_display_container: 3
2023-07-08 10:13:05,428:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 10:13:05,428:INFO:tune_model() successfully completed......................................
2023-07-08 10:14:13,359:INFO:Initializing evaluate_model()
2023-07-08 10:14:13,359:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-08 10:14:13,390:INFO:Initializing plot_model()
2023-07-08 10:14:13,391:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, system=True)
2023-07-08 10:14:13,391:INFO:Checking exceptions
2023-07-08 10:14:13,396:INFO:Preloading libraries
2023-07-08 10:14:13,404:INFO:Copying training dataset
2023-07-08 10:14:13,404:INFO:Plot type: pipeline
2023-07-08 10:14:13,536:INFO:Visual Rendered Successfully
2023-07-08 10:14:13,611:INFO:plot_model() successfully completed......................................
2023-07-08 10:14:17,754:INFO:Initializing predict_model()
2023-07-08 10:14:17,755:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041B7AAEE0>)
2023-07-08 10:14:17,755:INFO:Checking exceptions
2023-07-08 10:14:17,755:INFO:Preloading libraries
2023-07-08 10:31:08,384:INFO:Initializing plot_model()
2023-07-08 10:31:08,384:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, system=True)
2023-07-08 10:31:08,386:INFO:Checking exceptions
2023-07-08 10:31:08,388:INFO:Preloading libraries
2023-07-08 10:31:08,399:INFO:Copying training dataset
2023-07-08 10:31:08,399:INFO:Plot type: parameter
2023-07-08 10:31:08,403:INFO:Visual Rendered Successfully
2023-07-08 10:31:08,471:INFO:plot_model() successfully completed......................................
2023-07-08 10:31:11,061:INFO:Initializing plot_model()
2023-07-08 10:31:11,061:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, system=True)
2023-07-08 10:31:11,061:INFO:Checking exceptions
2023-07-08 10:31:11,064:INFO:Preloading libraries
2023-07-08 10:31:11,074:INFO:Copying training dataset
2023-07-08 10:31:11,074:INFO:Plot type: confusion_matrix
2023-07-08 10:31:11,147:INFO:Fitting Model
2023-07-08 10:31:11,148:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-07-08 10:31:11,149:INFO:Scoring test/hold-out set
2023-07-08 10:31:11,273:INFO:Visual Rendered Successfully
2023-07-08 10:31:11,345:INFO:plot_model() successfully completed......................................
2023-07-08 10:31:52,137:INFO:Initializing evaluate_model()
2023-07-08 10:31:52,138:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-08 10:31:52,163:INFO:Initializing plot_model()
2023-07-08 10:31:52,163:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, system=True)
2023-07-08 10:31:52,163:INFO:Checking exceptions
2023-07-08 10:31:52,167:INFO:Preloading libraries
2023-07-08 10:31:52,176:INFO:Copying training dataset
2023-07-08 10:31:52,177:INFO:Plot type: pipeline
2023-07-08 10:31:52,274:INFO:Visual Rendered Successfully
2023-07-08 10:31:52,346:INFO:plot_model() successfully completed......................................
2023-07-08 10:31:53,981:INFO:Initializing plot_model()
2023-07-08 10:31:53,982:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, system=True)
2023-07-08 10:31:53,982:INFO:Checking exceptions
2023-07-08 10:31:53,985:INFO:Preloading libraries
2023-07-08 10:31:53,994:INFO:Copying training dataset
2023-07-08 10:31:53,994:INFO:Plot type: confusion_matrix
2023-07-08 10:31:54,061:INFO:Fitting Model
2023-07-08 10:31:54,062:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-07-08 10:31:54,062:INFO:Scoring test/hold-out set
2023-07-08 10:31:54,186:INFO:Visual Rendered Successfully
2023-07-08 10:31:54,254:INFO:plot_model() successfully completed......................................
2023-07-08 10:32:17,639:INFO:Initializing plot_model()
2023-07-08 10:32:17,639:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, system=True)
2023-07-08 10:32:17,639:INFO:Checking exceptions
2023-07-08 10:32:17,644:INFO:Preloading libraries
2023-07-08 10:32:17,654:INFO:Copying training dataset
2023-07-08 10:32:17,655:INFO:Plot type: feature
2023-07-08 10:32:17,655:WARNING:No coef_ found. Trying feature_importances_
2023-07-08 10:32:17,801:INFO:Visual Rendered Successfully
2023-07-08 10:32:17,870:INFO:plot_model() successfully completed......................................
2023-07-08 10:32:20,966:INFO:Initializing plot_model()
2023-07-08 10:32:20,967:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, system=True)
2023-07-08 10:32:20,967:INFO:Checking exceptions
2023-07-08 10:32:20,970:INFO:Preloading libraries
2023-07-08 10:32:20,981:INFO:Copying training dataset
2023-07-08 10:32:20,981:INFO:Plot type: feature
2023-07-08 10:32:20,982:WARNING:No coef_ found. Trying feature_importances_
2023-07-08 10:32:21,125:INFO:Visual Rendered Successfully
2023-07-08 10:32:21,198:INFO:plot_model() successfully completed......................................
2023-07-08 10:34:32,769:INFO:Initializing predict_model()
2023-07-08 10:34:32,769:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041B8D3F70>)
2023-07-08 10:34:32,769:INFO:Checking exceptions
2023-07-08 10:34:32,769:INFO:Preloading libraries
2023-07-08 10:35:40,771:INFO:Initializing predict_model()
2023-07-08 10:35:40,771:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041C0DF5E0>)
2023-07-08 10:35:40,772:INFO:Checking exceptions
2023-07-08 10:35:40,772:INFO:Preloading libraries
2023-07-08 10:36:37,231:INFO:Initializing predict_model()
2023-07-08 10:36:37,231:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041B7AA820>)
2023-07-08 10:36:37,232:INFO:Checking exceptions
2023-07-08 10:36:37,232:INFO:Preloading libraries
2023-07-08 10:36:37,235:INFO:Set up data.
2023-07-08 10:36:37,250:INFO:Set up index.
2023-07-08 10:36:49,440:INFO:Initializing predict_model()
2023-07-08 10:36:49,440:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041B7B5B80>)
2023-07-08 10:36:49,440:INFO:Checking exceptions
2023-07-08 10:36:49,440:INFO:Preloading libraries
2023-07-08 10:37:05,488:INFO:Initializing predict_model()
2023-07-08 10:37:05,488:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041C357E50>)
2023-07-08 10:37:05,488:INFO:Checking exceptions
2023-07-08 10:37:05,490:INFO:Preloading libraries
2023-07-08 10:37:19,824:INFO:Initializing predict_model()
2023-07-08 10:37:19,824:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041C0DF8B0>)
2023-07-08 10:37:19,824:INFO:Checking exceptions
2023-07-08 10:37:19,825:INFO:Preloading libraries
2023-07-08 10:37:41,367:INFO:Initializing predict_model()
2023-07-08 10:37:41,367:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041B8D3F70>)
2023-07-08 10:37:41,367:INFO:Checking exceptions
2023-07-08 10:37:41,367:INFO:Preloading libraries
2023-07-08 10:39:37,405:INFO:Initializing finalize_model()
2023-07-08 10:39:37,405:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-07-08 10:39:37,406:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 10:39:37,411:INFO:Initializing create_model()
2023-07-08 10:39:37,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-07-08 10:39:37,412:INFO:Checking exceptions
2023-07-08 10:39:37,414:INFO:Importing libraries
2023-07-08 10:39:37,414:INFO:Copying training dataset
2023-07-08 10:39:37,414:INFO:Defining folds
2023-07-08 10:39:37,414:INFO:Declaring metric variables
2023-07-08 10:39:37,414:INFO:Importing untrained model
2023-07-08 10:39:37,414:INFO:Declaring custom model
2023-07-08 10:39:37,415:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 10:39:37,416:INFO:Cross validation set to False
2023-07-08 10:39:37,417:INFO:Fitting Model
2023-07-08 10:39:38,112:INFO:Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-07-08 10:39:38,112:INFO:create_model() successfully completed......................................
2023-07-08 10:39:38,175:INFO:_master_model_container: 16
2023-07-08 10:39:38,175:INFO:_display_container: 11
2023-07-08 10:39:38,185:INFO:Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-07-08 10:39:38,185:INFO:finalize_model() successfully completed......................................
2023-07-08 10:42:00,816:INFO:Initializing finalize_model()
2023-07-08 10:42:00,816:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-07-08 10:42:00,816:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 10:42:00,820:INFO:Initializing create_model()
2023-07-08 10:42:00,820:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-07-08 10:42:00,820:INFO:Checking exceptions
2023-07-08 10:42:00,822:INFO:Importing libraries
2023-07-08 10:42:00,822:INFO:Copying training dataset
2023-07-08 10:42:00,822:INFO:Defining folds
2023-07-08 10:42:00,822:INFO:Declaring metric variables
2023-07-08 10:42:00,822:INFO:Importing untrained model
2023-07-08 10:42:00,822:INFO:Declaring custom model
2023-07-08 10:42:00,823:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 10:42:00,825:INFO:Cross validation set to False
2023-07-08 10:42:00,825:INFO:Fitting Model
2023-07-08 10:42:00,916:INFO:Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-07-08 10:42:00,916:INFO:create_model() successfully completed......................................
2023-07-08 10:42:00,984:INFO:_master_model_container: 16
2023-07-08 10:42:00,984:INFO:_display_container: 11
2023-07-08 10:42:00,994:INFO:Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-07-08 10:42:00,994:INFO:finalize_model() successfully completed......................................
2023-07-08 10:43:43,321:INFO:Initializing finalize_model()
2023-07-08 10:43:43,321:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-07-08 10:43:43,322:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 10:43:43,328:INFO:Initializing create_model()
2023-07-08 10:43:43,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-07-08 10:43:43,328:INFO:Checking exceptions
2023-07-08 10:43:43,331:INFO:Importing libraries
2023-07-08 10:43:43,331:INFO:Copying training dataset
2023-07-08 10:43:43,331:INFO:Defining folds
2023-07-08 10:43:43,331:INFO:Declaring metric variables
2023-07-08 10:43:43,332:INFO:Importing untrained model
2023-07-08 10:43:43,332:INFO:Declaring custom model
2023-07-08 10:43:43,333:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 10:43:43,334:INFO:Cross validation set to False
2023-07-08 10:43:43,334:INFO:Fitting Model
2023-07-08 10:43:43,415:INFO:Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-07-08 10:43:43,416:INFO:create_model() successfully completed......................................
2023-07-08 10:43:43,505:INFO:_master_model_container: 16
2023-07-08 10:43:43,506:INFO:_display_container: 11
2023-07-08 10:43:43,523:INFO:Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-07-08 10:43:43,523:INFO:finalize_model() successfully completed......................................
2023-07-08 10:43:43,903:INFO:Initializing save_model()
2023-07-08 10:43:43,903:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=gbc, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-07-08 10:43:43,903:INFO:Adding model into prep_pipe
2023-07-08 10:43:43,912:INFO:gbc.pkl saved in current working directory
2023-07-08 10:43:43,921:INFO:Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-07-08 10:43:43,921:INFO:save_model() successfully completed......................................
2023-07-08 10:47:50,267:INFO:Initializing load_model()
2023-07-08 10:47:50,268:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 10:47:50,289:INFO:Initializing predict_model()
2023-07-08 10:47:50,289:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041C0DAA60>)
2023-07-08 10:47:50,289:INFO:Checking exceptions
2023-07-08 10:47:50,290:INFO:Preloading libraries
2023-07-08 10:47:50,293:INFO:Set up data.
2023-07-08 10:47:50,297:INFO:Set up index.
2023-07-08 10:54:09,785:INFO:Initializing load_model()
2023-07-08 10:54:09,786:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 10:54:09,815:INFO:Initializing predict_model()
2023-07-08 10:54:09,815:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041C357E50>)
2023-07-08 10:54:09,815:INFO:Checking exceptions
2023-07-08 10:54:09,815:INFO:Preloading libraries
2023-07-08 10:54:09,818:INFO:Set up data.
2023-07-08 10:54:09,824:INFO:Set up index.
2023-07-08 11:04:52,466:INFO:Initializing load_model()
2023-07-08 11:04:52,466:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 11:04:52,493:INFO:Initializing predict_model()
2023-07-08 11:04:52,494:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041BD1F160>)
2023-07-08 11:04:52,494:INFO:Checking exceptions
2023-07-08 11:04:52,494:INFO:Preloading libraries
2023-07-08 11:04:52,496:INFO:Set up data.
2023-07-08 11:04:52,502:INFO:Set up index.
2023-07-08 11:08:58,965:INFO:Initializing load_model()
2023-07-08 11:08:58,966:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 11:08:58,989:INFO:Initializing predict_model()
2023-07-08 11:08:58,989:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041BACC9D0>)
2023-07-08 11:08:58,989:INFO:Checking exceptions
2023-07-08 11:08:58,989:INFO:Preloading libraries
2023-07-08 11:08:58,993:INFO:Set up data.
2023-07-08 11:08:59,005:INFO:Set up index.
2023-07-08 11:09:53,196:INFO:Initializing load_model()
2023-07-08 11:09:53,197:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 11:09:53,225:INFO:Initializing predict_model()
2023-07-08 11:09:53,225:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041B8B3700>)
2023-07-08 11:09:53,225:INFO:Checking exceptions
2023-07-08 11:09:53,225:INFO:Preloading libraries
2023-07-08 11:09:53,228:INFO:Set up data.
2023-07-08 11:09:53,237:INFO:Set up index.
2023-07-08 11:10:51,817:INFO:Initializing load_model()
2023-07-08 11:10:51,817:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 11:10:51,839:INFO:Initializing predict_model()
2023-07-08 11:10:51,839:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041BD1F940>)
2023-07-08 11:10:51,839:INFO:Checking exceptions
2023-07-08 11:10:51,839:INFO:Preloading libraries
2023-07-08 11:10:51,842:INFO:Set up data.
2023-07-08 11:10:51,850:INFO:Set up index.
2023-07-08 11:11:53,317:INFO:Initializing load_model()
2023-07-08 11:11:53,318:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 11:11:53,340:INFO:Initializing predict_model()
2023-07-08 11:11:53,340:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041BD1F790>)
2023-07-08 11:11:53,340:INFO:Checking exceptions
2023-07-08 11:11:53,341:INFO:Preloading libraries
2023-07-08 11:11:53,343:INFO:Set up data.
2023-07-08 11:11:53,354:INFO:Set up index.
2023-07-08 11:13:28,350:INFO:Initializing load_model()
2023-07-08 11:13:28,351:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 11:13:28,380:INFO:Initializing predict_model()
2023-07-08 11:13:28,380:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041B84A940>)
2023-07-08 11:13:28,380:INFO:Checking exceptions
2023-07-08 11:13:28,380:INFO:Preloading libraries
2023-07-08 11:13:28,383:INFO:Set up data.
2023-07-08 11:13:28,397:INFO:Set up index.
2023-07-08 11:14:28,620:INFO:Initializing load_model()
2023-07-08 11:14:28,620:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 11:14:28,643:INFO:Initializing predict_model()
2023-07-08 11:14:28,644:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041BD1FB80>)
2023-07-08 11:14:28,644:INFO:Checking exceptions
2023-07-08 11:14:28,644:INFO:Preloading libraries
2023-07-08 11:14:28,646:INFO:Set up data.
2023-07-08 11:14:28,656:INFO:Set up index.
2023-07-08 11:15:14,148:INFO:Initializing load_model()
2023-07-08 11:15:14,149:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 11:15:14,172:INFO:Initializing predict_model()
2023-07-08 11:15:14,173:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041C0DFB80>)
2023-07-08 11:15:14,173:INFO:Checking exceptions
2023-07-08 11:15:14,173:INFO:Preloading libraries
2023-07-08 11:15:14,176:INFO:Set up data.
2023-07-08 11:15:14,189:INFO:Set up index.
2023-07-08 11:17:29,168:INFO:Initializing load_model()
2023-07-08 11:17:29,169:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 11:17:29,450:INFO:Initializing predict_model()
2023-07-08 11:17:29,451:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041BD1F0D0>)
2023-07-08 11:17:29,451:INFO:Checking exceptions
2023-07-08 11:17:29,451:INFO:Preloading libraries
2023-07-08 11:17:29,453:INFO:Set up data.
2023-07-08 11:17:29,462:INFO:Set up index.
2023-07-08 11:17:43,722:INFO:Initializing load_model()
2023-07-08 11:17:43,722:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 11:17:44,019:INFO:Initializing predict_model()
2023-07-08 11:17:44,019:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041B7B5B80>)
2023-07-08 11:17:44,019:INFO:Checking exceptions
2023-07-08 11:17:44,019:INFO:Preloading libraries
2023-07-08 11:17:44,021:INFO:Set up data.
2023-07-08 11:17:44,030:INFO:Set up index.
2023-07-08 11:18:51,530:INFO:Initializing load_model()
2023-07-08 11:18:51,530:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 11:18:51,818:INFO:Initializing predict_model()
2023-07-08 11:18:51,818:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041B84A940>)
2023-07-08 11:18:51,818:INFO:Checking exceptions
2023-07-08 11:18:51,818:INFO:Preloading libraries
2023-07-08 11:18:51,820:INFO:Set up data.
2023-07-08 11:18:51,830:INFO:Set up index.
2023-07-08 11:19:05,671:INFO:Initializing load_model()
2023-07-08 11:19:05,671:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 11:19:05,970:INFO:Initializing predict_model()
2023-07-08 11:19:05,970:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041B7AA820>)
2023-07-08 11:19:05,970:INFO:Checking exceptions
2023-07-08 11:19:05,970:INFO:Preloading libraries
2023-07-08 11:19:05,972:INFO:Set up data.
2023-07-08 11:19:05,982:INFO:Set up index.
2023-07-08 11:19:06,014:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py:586: UserWarning: Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 567, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 337, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 567, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 337, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2023-07-08 11:19:06,017:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 11:19:42,970:INFO:Initializing load_model()
2023-07-08 11:19:42,970:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 11:19:43,263:INFO:Initializing predict_model()
2023-07-08 11:19:43,263:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041BD1FA60>)
2023-07-08 11:19:43,263:INFO:Checking exceptions
2023-07-08 11:19:43,263:INFO:Preloading libraries
2023-07-08 11:19:43,265:INFO:Set up data.
2023-07-08 11:19:43,271:INFO:Set up index.
2023-07-08 11:19:52,206:INFO:Initializing load_model()
2023-07-08 11:19:52,207:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 11:19:52,528:INFO:Initializing predict_model()
2023-07-08 11:19:52,529:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041C0DF4C0>)
2023-07-08 11:19:52,529:INFO:Checking exceptions
2023-07-08 11:19:52,529:INFO:Preloading libraries
2023-07-08 11:19:52,531:INFO:Set up data.
2023-07-08 11:19:52,541:INFO:Set up index.
2023-07-08 11:19:52,569:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py:586: UserWarning: Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 567, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 337, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 567, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 337, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2023-07-08 11:19:52,571:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 11:20:15,919:INFO:Initializing load_model()
2023-07-08 11:20:15,920:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 11:20:16,202:INFO:Initializing predict_model()
2023-07-08 11:20:16,202:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041BD1FDC0>)
2023-07-08 11:20:16,202:INFO:Checking exceptions
2023-07-08 11:20:16,202:INFO:Preloading libraries
2023-07-08 11:20:16,204:INFO:Set up data.
2023-07-08 11:20:16,214:INFO:Set up index.
2023-07-08 11:20:16,240:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py:586: UserWarning: Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 567, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 337, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 567, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 337, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2023-07-08 11:20:16,242:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 11:20:20,275:INFO:Initializing load_model()
2023-07-08 11:20:20,275:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 11:20:20,576:INFO:Initializing predict_model()
2023-07-08 11:20:20,576:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041BD1FCA0>)
2023-07-08 11:20:20,576:INFO:Checking exceptions
2023-07-08 11:20:20,576:INFO:Preloading libraries
2023-07-08 11:20:20,578:INFO:Set up data.
2023-07-08 11:20:20,589:INFO:Set up index.
2023-07-08 11:20:20,620:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py:586: UserWarning: Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 567, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 337, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 567, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 337, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2023-07-08 11:20:20,622:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 11:21:32,978:INFO:Initializing load_model()
2023-07-08 11:21:32,978:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 11:21:33,276:INFO:Initializing predict_model()
2023-07-08 11:21:33,276:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041B7AA820>)
2023-07-08 11:21:33,276:INFO:Checking exceptions
2023-07-08 11:21:33,276:INFO:Preloading libraries
2023-07-08 11:21:33,278:INFO:Set up data.
2023-07-08 11:21:33,288:INFO:Set up index.
2023-07-08 11:21:33,318:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py:586: UserWarning: Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 567, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 337, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 567, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 337, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2023-07-08 11:21:33,321:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 11:24:52,749:INFO:Initializing predict_model()
2023-07-08 11:24:52,749:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041C1EFDC0>)
2023-07-08 11:24:52,749:INFO:Checking exceptions
2023-07-08 11:24:52,749:INFO:Preloading libraries
2023-07-08 11:25:18,770:INFO:Initializing load_model()
2023-07-08 11:25:18,771:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 11:25:19,063:INFO:Initializing predict_model()
2023-07-08 11:25:19,064:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041BD1FCA0>)
2023-07-08 11:25:19,064:INFO:Checking exceptions
2023-07-08 11:25:19,064:INFO:Preloading libraries
2023-07-08 11:25:19,065:INFO:Set up data.
2023-07-08 11:25:19,075:INFO:Set up index.
2023-07-08 11:25:19,106:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py:586: UserWarning: Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 567, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 337, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 567, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 337, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2023-07-08 11:25:19,110:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:663: RuntimeWarning: invalid value encountered in true_divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-07-08 12:43:45,313:INFO:Initializing load_model()
2023-07-08 12:43:45,313:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 12:43:45,662:INFO:Initializing predict_model()
2023-07-08 12:43:45,662:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041BD1FDC0>)
2023-07-08 12:43:45,662:INFO:Checking exceptions
2023-07-08 12:43:45,662:INFO:Preloading libraries
2023-07-08 12:43:45,664:INFO:Set up data.
2023-07-08 12:43:45,676:INFO:Set up index.
2023-07-08 12:53:19,094:INFO:Initializing load_model()
2023-07-08 12:53:19,095:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 12:53:19,352:INFO:Initializing predict_model()
2023-07-08 12:53:19,352:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041C0DF4C0>)
2023-07-08 12:53:19,352:INFO:Checking exceptions
2023-07-08 12:53:19,352:INFO:Preloading libraries
2023-07-08 12:53:19,354:INFO:Set up data.
2023-07-08 12:53:19,364:INFO:Set up index.
2023-07-08 13:00:18,486:INFO:Initializing load_model()
2023-07-08 13:00:18,486:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 13:00:18,827:INFO:Initializing predict_model()
2023-07-08 13:00:18,827:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002041B844760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002041C1EFCA0>)
2023-07-08 13:00:18,827:INFO:Checking exceptions
2023-07-08 13:00:18,827:INFO:Preloading libraries
2023-07-08 13:00:18,830:INFO:Set up data.
2023-07-08 13:00:18,841:INFO:Set up index.
2023-07-08 21:38:15,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-08 21:38:15,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-08 21:38:15,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-08 21:38:15,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-08 21:38:59,730:INFO:PyCaret ClassificationExperiment
2023-07-08 21:38:59,730:INFO:Logging name: clf-default-name
2023-07-08 21:38:59,730:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-08 21:38:59,730:INFO:version 3.0.4
2023-07-08 21:38:59,730:INFO:Initializing setup()
2023-07-08 21:38:59,730:INFO:self.USI: 2911
2023-07-08 21:38:59,730:INFO:self._variable_keys: {'n_jobs_param', 'data', 'y_test', '_ml_usecase', 'memory', 'fold_groups_param', 'fix_imbalance', 'y', 'X_train', 'target_param', 'seed', 'y_train', 'exp_id', '_available_plots', 'html_param', 'X_test', 'fold_shuffle_param', 'logging_param', 'exp_name_log', 'gpu_param', 'USI', 'gpu_n_jobs_param', 'is_multiclass', 'fold_generator', 'idx', 'X', 'pipeline', 'log_plots_param'}
2023-07-08 21:38:59,730:INFO:Checking environment
2023-07-08 21:38:59,730:INFO:python_version: 3.9.13
2023-07-08 21:38:59,730:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-07-08 21:38:59,730:INFO:machine: AMD64
2023-07-08 21:38:59,730:INFO:platform: Windows-10-10.0.19045-SP0
2023-07-08 21:38:59,730:INFO:Memory: svmem(total=17125732352, available=10009198592, percent=41.6, used=7116533760, free=10009198592)
2023-07-08 21:38:59,730:INFO:Physical Core: 4
2023-07-08 21:38:59,730:INFO:Logical Core: 8
2023-07-08 21:38:59,730:INFO:Checking libraries
2023-07-08 21:38:59,731:INFO:System:
2023-07-08 21:38:59,731:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-07-08 21:38:59,731:INFO:executable: C:\Users\hamim\anaconda3\python.exe
2023-07-08 21:38:59,731:INFO:   machine: Windows-10-10.0.19045-SP0
2023-07-08 21:38:59,731:INFO:PyCaret required dependencies:
2023-07-08 21:38:59,733:INFO:                 pip: 22.2.2
2023-07-08 21:38:59,733:INFO:          setuptools: 63.4.1
2023-07-08 21:38:59,733:INFO:             pycaret: 3.0.4
2023-07-08 21:38:59,733:INFO:             IPython: 7.31.1
2023-07-08 21:38:59,733:INFO:          ipywidgets: 7.6.5
2023-07-08 21:38:59,733:INFO:                tqdm: 4.64.1
2023-07-08 21:38:59,733:INFO:               numpy: 1.21.5
2023-07-08 21:38:59,733:INFO:              pandas: 1.4.4
2023-07-08 21:38:59,733:INFO:              jinja2: 2.11.3
2023-07-08 21:38:59,733:INFO:               scipy: 1.9.1
2023-07-08 21:38:59,733:INFO:              joblib: 1.2.0
2023-07-08 21:38:59,733:INFO:             sklearn: 1.0.2
2023-07-08 21:38:59,733:INFO:                pyod: 1.1.0
2023-07-08 21:38:59,734:INFO:            imblearn: 0.10.1
2023-07-08 21:38:59,734:INFO:   category_encoders: 2.6.1
2023-07-08 21:38:59,734:INFO:            lightgbm: 3.3.5
2023-07-08 21:38:59,734:INFO:               numba: 0.55.1
2023-07-08 21:38:59,734:INFO:            requests: 2.28.1
2023-07-08 21:38:59,734:INFO:          matplotlib: 3.5.2
2023-07-08 21:38:59,734:INFO:          scikitplot: 0.3.7
2023-07-08 21:38:59,734:INFO:         yellowbrick: 1.5
2023-07-08 21:38:59,734:INFO:              plotly: 5.9.0
2023-07-08 21:38:59,734:INFO:    plotly-resampler: Not installed
2023-07-08 21:38:59,734:INFO:             kaleido: 0.2.1
2023-07-08 21:38:59,734:INFO:           schemdraw: 0.15
2023-07-08 21:38:59,734:INFO:         statsmodels: 0.13.2
2023-07-08 21:38:59,734:INFO:              sktime: 0.20.0
2023-07-08 21:38:59,734:INFO:               tbats: 1.1.3
2023-07-08 21:38:59,734:INFO:            pmdarima: 2.0.3
2023-07-08 21:38:59,735:INFO:              psutil: 5.9.0
2023-07-08 21:38:59,735:INFO:          markupsafe: 2.0.1
2023-07-08 21:38:59,735:INFO:             pickle5: Not installed
2023-07-08 21:38:59,735:INFO:         cloudpickle: 2.0.0
2023-07-08 21:38:59,735:INFO:         deprecation: 2.1.0
2023-07-08 21:38:59,735:INFO:              xxhash: 3.2.0
2023-07-08 21:38:59,735:INFO:           wurlitzer: Not installed
2023-07-08 21:38:59,735:INFO:PyCaret optional dependencies:
2023-07-08 21:38:59,758:INFO:                shap: Not installed
2023-07-08 21:38:59,758:INFO:           interpret: Not installed
2023-07-08 21:38:59,758:INFO:                umap: Not installed
2023-07-08 21:38:59,758:INFO:    pandas_profiling: Not installed
2023-07-08 21:38:59,758:INFO:  explainerdashboard: Not installed
2023-07-08 21:38:59,759:INFO:             autoviz: Not installed
2023-07-08 21:38:59,759:INFO:           fairlearn: Not installed
2023-07-08 21:38:59,759:INFO:          deepchecks: Not installed
2023-07-08 21:38:59,759:INFO:             xgboost: Not installed
2023-07-08 21:38:59,759:INFO:            catboost: Not installed
2023-07-08 21:38:59,759:INFO:              kmodes: Not installed
2023-07-08 21:38:59,759:INFO:             mlxtend: Not installed
2023-07-08 21:38:59,759:INFO:       statsforecast: Not installed
2023-07-08 21:38:59,759:INFO:        tune_sklearn: Not installed
2023-07-08 21:38:59,759:INFO:                 ray: Not installed
2023-07-08 21:38:59,759:INFO:            hyperopt: Not installed
2023-07-08 21:38:59,759:INFO:              optuna: Not installed
2023-07-08 21:38:59,759:INFO:               skopt: Not installed
2023-07-08 21:38:59,759:INFO:              mlflow: Not installed
2023-07-08 21:38:59,759:INFO:              gradio: Not installed
2023-07-08 21:38:59,759:INFO:             fastapi: Not installed
2023-07-08 21:38:59,759:INFO:             uvicorn: Not installed
2023-07-08 21:38:59,759:INFO:              m2cgen: Not installed
2023-07-08 21:38:59,759:INFO:           evidently: Not installed
2023-07-08 21:38:59,759:INFO:               fugue: Not installed
2023-07-08 21:38:59,759:INFO:           streamlit: Not installed
2023-07-08 21:38:59,760:INFO:             prophet: Not installed
2023-07-08 21:38:59,760:INFO:None
2023-07-08 21:38:59,760:INFO:Set up data.
2023-07-08 21:38:59,774:INFO:Set up train/test split.
2023-07-08 21:38:59,781:INFO:Set up index.
2023-07-08 21:38:59,781:INFO:Set up folding strategy.
2023-07-08 21:38:59,781:INFO:Assigning column types.
2023-07-08 21:38:59,786:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-08 21:38:59,836:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-08 21:38:59,839:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 21:38:59,876:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 21:39:00,038:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 21:39:00,083:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-08 21:39:00,084:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 21:39:00,111:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 21:39:00,111:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 21:39:00,111:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-08 21:39:00,162:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 21:39:00,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 21:39:00,196:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 21:39:00,246:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 21:39:00,273:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 21:39:00,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 21:39:00,273:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-08 21:39:00,346:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 21:39:00,346:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 21:39:00,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 21:39:00,426:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 21:39:00,440:INFO:Preparing preprocessing pipeline...
2023-07-08 21:39:00,441:INFO:Set up simple imputation.
2023-07-08 21:39:00,441:INFO:Set up imbalanced handling.
2023-07-08 21:39:00,442:INFO:Set up column name cleaning.
2023-07-08 21:39:00,643:INFO:Finished creating preprocessing pipeline.
2023-07-08 21:39:00,651:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-08 21:39:00,651:INFO:Creating final display dataframe.
2023-07-08 21:39:00,754:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Target
2                   Target type            Binary
3           Original data shape        (2802, 34)
4        Transformed data shape        (3825, 34)
5   Transformed train set shape        (2984, 34)
6    Transformed test set shape         (841, 34)
7              Numeric features                33
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              2911
2023-07-08 21:39:00,861:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 21:39:00,861:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 21:39:00,955:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 21:39:00,955:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 21:39:00,956:INFO:setup() successfully completed in 1.54s...............
2023-07-08 21:39:02,292:INFO:Initializing compare_models()
2023-07-08 21:39:02,292:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-08 21:39:02,293:INFO:Checking exceptions
2023-07-08 21:39:02,307:INFO:Preparing display monitor
2023-07-08 21:39:02,361:INFO:Initializing Logistic Regression
2023-07-08 21:39:02,361:INFO:Total runtime is 0.0 minutes
2023-07-08 21:39:02,367:INFO:SubProcess create_model() called ==================================
2023-07-08 21:39:02,368:INFO:Initializing create_model()
2023-07-08 21:39:02,368:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A13A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 21:39:02,368:INFO:Checking exceptions
2023-07-08 21:39:02,368:INFO:Importing libraries
2023-07-08 21:39:02,368:INFO:Copying training dataset
2023-07-08 21:39:02,375:INFO:Defining folds
2023-07-08 21:39:02,375:INFO:Declaring metric variables
2023-07-08 21:39:02,380:INFO:Importing untrained model
2023-07-08 21:39:02,387:INFO:Logistic Regression Imported successfully
2023-07-08 21:39:02,396:INFO:Starting cross validation
2023-07-08 21:39:02,399:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 21:39:13,668:INFO:Calculating mean and std
2023-07-08 21:39:13,670:INFO:Creating metrics dataframe
2023-07-08 21:39:14,041:INFO:Uploading results into container
2023-07-08 21:39:14,041:INFO:Uploading model into container now
2023-07-08 21:39:14,042:INFO:_master_model_container: 1
2023-07-08 21:39:14,042:INFO:_display_container: 2
2023-07-08 21:39:14,043:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-08 21:39:14,043:INFO:create_model() successfully completed......................................
2023-07-08 21:39:14,111:INFO:SubProcess create_model() end ==================================
2023-07-08 21:39:14,111:INFO:Creating metrics dataframe
2023-07-08 21:39:14,122:INFO:Initializing K Neighbors Classifier
2023-07-08 21:39:14,122:INFO:Total runtime is 0.19601158698399862 minutes
2023-07-08 21:39:14,128:INFO:SubProcess create_model() called ==================================
2023-07-08 21:39:14,129:INFO:Initializing create_model()
2023-07-08 21:39:14,129:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A13A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 21:39:14,129:INFO:Checking exceptions
2023-07-08 21:39:14,129:INFO:Importing libraries
2023-07-08 21:39:14,129:INFO:Copying training dataset
2023-07-08 21:39:14,134:INFO:Defining folds
2023-07-08 21:39:14,134:INFO:Declaring metric variables
2023-07-08 21:39:14,138:INFO:Importing untrained model
2023-07-08 21:39:14,144:INFO:K Neighbors Classifier Imported successfully
2023-07-08 21:39:14,156:INFO:Starting cross validation
2023-07-08 21:39:14,158:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 21:39:14,405:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 21:39:14,406:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 21:39:14,414:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 21:39:14,421:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 21:39:14,432:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 21:39:14,449:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 21:39:14,456:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 21:39:14,460:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 21:39:15,213:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 21:39:15,223:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 21:39:17,077:INFO:Calculating mean and std
2023-07-08 21:39:17,078:INFO:Creating metrics dataframe
2023-07-08 21:39:17,446:INFO:Uploading results into container
2023-07-08 21:39:17,447:INFO:Uploading model into container now
2023-07-08 21:39:17,448:INFO:_master_model_container: 2
2023-07-08 21:39:17,448:INFO:_display_container: 2
2023-07-08 21:39:17,449:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-08 21:39:17,449:INFO:create_model() successfully completed......................................
2023-07-08 21:39:17,522:INFO:SubProcess create_model() end ==================================
2023-07-08 21:39:17,523:INFO:Creating metrics dataframe
2023-07-08 21:39:17,538:INFO:Initializing Naive Bayes
2023-07-08 21:39:17,538:INFO:Total runtime is 0.2529449661572774 minutes
2023-07-08 21:39:17,542:INFO:SubProcess create_model() called ==================================
2023-07-08 21:39:17,543:INFO:Initializing create_model()
2023-07-08 21:39:17,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A13A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 21:39:17,543:INFO:Checking exceptions
2023-07-08 21:39:17,544:INFO:Importing libraries
2023-07-08 21:39:17,544:INFO:Copying training dataset
2023-07-08 21:39:17,551:INFO:Defining folds
2023-07-08 21:39:17,552:INFO:Declaring metric variables
2023-07-08 21:39:17,558:INFO:Importing untrained model
2023-07-08 21:39:17,565:INFO:Naive Bayes Imported successfully
2023-07-08 21:39:17,578:INFO:Starting cross validation
2023-07-08 21:39:17,579:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 21:39:21,108:INFO:Calculating mean and std
2023-07-08 21:39:21,110:INFO:Creating metrics dataframe
2023-07-08 21:39:21,529:INFO:Uploading results into container
2023-07-08 21:39:21,530:INFO:Uploading model into container now
2023-07-08 21:39:21,531:INFO:_master_model_container: 3
2023-07-08 21:39:21,531:INFO:_display_container: 2
2023-07-08 21:39:21,532:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-08 21:39:21,532:INFO:create_model() successfully completed......................................
2023-07-08 21:39:21,619:INFO:SubProcess create_model() end ==================================
2023-07-08 21:39:21,619:INFO:Creating metrics dataframe
2023-07-08 21:39:21,634:INFO:Initializing Decision Tree Classifier
2023-07-08 21:39:21,635:INFO:Total runtime is 0.3212437629699707 minutes
2023-07-08 21:39:21,641:INFO:SubProcess create_model() called ==================================
2023-07-08 21:39:21,641:INFO:Initializing create_model()
2023-07-08 21:39:21,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A13A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 21:39:21,642:INFO:Checking exceptions
2023-07-08 21:39:21,642:INFO:Importing libraries
2023-07-08 21:39:21,642:INFO:Copying training dataset
2023-07-08 21:39:21,655:INFO:Defining folds
2023-07-08 21:39:21,655:INFO:Declaring metric variables
2023-07-08 21:39:21,664:INFO:Importing untrained model
2023-07-08 21:39:21,672:INFO:Decision Tree Classifier Imported successfully
2023-07-08 21:39:21,684:INFO:Starting cross validation
2023-07-08 21:39:21,686:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 21:39:25,457:INFO:Calculating mean and std
2023-07-08 21:39:25,459:INFO:Creating metrics dataframe
2023-07-08 21:39:25,858:INFO:Uploading results into container
2023-07-08 21:39:25,859:INFO:Uploading model into container now
2023-07-08 21:39:25,859:INFO:_master_model_container: 4
2023-07-08 21:39:25,859:INFO:_display_container: 2
2023-07-08 21:39:25,860:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-08 21:39:25,860:INFO:create_model() successfully completed......................................
2023-07-08 21:39:25,926:INFO:SubProcess create_model() end ==================================
2023-07-08 21:39:25,927:INFO:Creating metrics dataframe
2023-07-08 21:39:25,941:INFO:Initializing SVM - Linear Kernel
2023-07-08 21:39:25,941:INFO:Total runtime is 0.3929961601893107 minutes
2023-07-08 21:39:25,945:INFO:SubProcess create_model() called ==================================
2023-07-08 21:39:25,946:INFO:Initializing create_model()
2023-07-08 21:39:25,946:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A13A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 21:39:25,946:INFO:Checking exceptions
2023-07-08 21:39:25,947:INFO:Importing libraries
2023-07-08 21:39:25,947:INFO:Copying training dataset
2023-07-08 21:39:25,954:INFO:Defining folds
2023-07-08 21:39:25,954:INFO:Declaring metric variables
2023-07-08 21:39:25,958:INFO:Importing untrained model
2023-07-08 21:39:25,963:INFO:SVM - Linear Kernel Imported successfully
2023-07-08 21:39:25,977:INFO:Starting cross validation
2023-07-08 21:39:25,979:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 21:39:26,236:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 21:39:26,258:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 21:39:26,263:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 21:39:26,275:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 21:39:26,343:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 21:39:26,348:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 21:39:26,373:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 21:39:26,479:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 21:39:27,058:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 21:39:27,074:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 21:39:29,306:INFO:Calculating mean and std
2023-07-08 21:39:29,309:INFO:Creating metrics dataframe
2023-07-08 21:39:29,691:INFO:Uploading results into container
2023-07-08 21:39:29,692:INFO:Uploading model into container now
2023-07-08 21:39:29,692:INFO:_master_model_container: 5
2023-07-08 21:39:29,692:INFO:_display_container: 2
2023-07-08 21:39:29,693:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-08 21:39:29,693:INFO:create_model() successfully completed......................................
2023-07-08 21:39:29,762:INFO:SubProcess create_model() end ==================================
2023-07-08 21:39:29,762:INFO:Creating metrics dataframe
2023-07-08 21:39:29,777:INFO:Initializing Ridge Classifier
2023-07-08 21:39:29,777:INFO:Total runtime is 0.45693790912628174 minutes
2023-07-08 21:39:29,781:INFO:SubProcess create_model() called ==================================
2023-07-08 21:39:29,782:INFO:Initializing create_model()
2023-07-08 21:39:29,782:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A13A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 21:39:29,782:INFO:Checking exceptions
2023-07-08 21:39:29,783:INFO:Importing libraries
2023-07-08 21:39:29,783:INFO:Copying training dataset
2023-07-08 21:39:29,789:INFO:Defining folds
2023-07-08 21:39:29,790:INFO:Declaring metric variables
2023-07-08 21:39:29,795:INFO:Importing untrained model
2023-07-08 21:39:29,803:INFO:Ridge Classifier Imported successfully
2023-07-08 21:39:29,819:INFO:Starting cross validation
2023-07-08 21:39:29,821:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 21:39:30,021:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 21:39:30,050:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 21:39:30,054:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 21:39:30,070:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 21:39:30,082:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 21:39:30,092:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 21:39:30,110:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 21:39:30,138:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 21:39:30,769:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 21:39:30,801:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 21:39:32,842:INFO:Calculating mean and std
2023-07-08 21:39:32,843:INFO:Creating metrics dataframe
2023-07-08 21:39:33,230:INFO:Uploading results into container
2023-07-08 21:39:33,231:INFO:Uploading model into container now
2023-07-08 21:39:33,231:INFO:_master_model_container: 6
2023-07-08 21:39:33,231:INFO:_display_container: 2
2023-07-08 21:39:33,232:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=42, solver='auto', tol=0.001)
2023-07-08 21:39:33,232:INFO:create_model() successfully completed......................................
2023-07-08 21:39:33,300:INFO:SubProcess create_model() end ==================================
2023-07-08 21:39:33,301:INFO:Creating metrics dataframe
2023-07-08 21:39:33,314:INFO:Initializing Random Forest Classifier
2023-07-08 21:39:33,314:INFO:Total runtime is 0.515884526570638 minutes
2023-07-08 21:39:33,319:INFO:SubProcess create_model() called ==================================
2023-07-08 21:39:33,319:INFO:Initializing create_model()
2023-07-08 21:39:33,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A13A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 21:39:33,320:INFO:Checking exceptions
2023-07-08 21:39:33,320:INFO:Importing libraries
2023-07-08 21:39:33,320:INFO:Copying training dataset
2023-07-08 21:39:33,325:INFO:Defining folds
2023-07-08 21:39:33,325:INFO:Declaring metric variables
2023-07-08 21:39:33,331:INFO:Importing untrained model
2023-07-08 21:39:33,335:INFO:Random Forest Classifier Imported successfully
2023-07-08 21:39:33,349:INFO:Starting cross validation
2023-07-08 21:39:33,350:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 21:39:38,089:INFO:Calculating mean and std
2023-07-08 21:39:38,090:INFO:Creating metrics dataframe
2023-07-08 21:39:38,525:INFO:Uploading results into container
2023-07-08 21:39:38,526:INFO:Uploading model into container now
2023-07-08 21:39:38,526:INFO:_master_model_container: 7
2023-07-08 21:39:38,526:INFO:_display_container: 2
2023-07-08 21:39:38,527:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-08 21:39:38,527:INFO:create_model() successfully completed......................................
2023-07-08 21:39:38,598:INFO:SubProcess create_model() end ==================================
2023-07-08 21:39:38,598:INFO:Creating metrics dataframe
2023-07-08 21:39:38,615:INFO:Initializing Quadratic Discriminant Analysis
2023-07-08 21:39:38,615:INFO:Total runtime is 0.6042313774426777 minutes
2023-07-08 21:39:38,621:INFO:SubProcess create_model() called ==================================
2023-07-08 21:39:38,621:INFO:Initializing create_model()
2023-07-08 21:39:38,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A13A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 21:39:38,622:INFO:Checking exceptions
2023-07-08 21:39:38,622:INFO:Importing libraries
2023-07-08 21:39:38,622:INFO:Copying training dataset
2023-07-08 21:39:38,630:INFO:Defining folds
2023-07-08 21:39:38,631:INFO:Declaring metric variables
2023-07-08 21:39:38,636:INFO:Importing untrained model
2023-07-08 21:39:38,643:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-08 21:39:38,657:INFO:Starting cross validation
2023-07-08 21:39:38,659:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 21:39:38,853:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 21:39:38,874:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 21:39:38,878:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 21:39:38,891:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 21:39:38,892:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 21:39:38,896:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 21:39:38,899:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 21:39:38,916:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 21:39:38,997:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 21:39:39,002:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 21:39:39,636:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 21:39:39,654:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 21:39:39,702:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 21:39:39,713:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 21:39:41,770:INFO:Calculating mean and std
2023-07-08 21:39:41,772:INFO:Creating metrics dataframe
2023-07-08 21:39:42,178:INFO:Uploading results into container
2023-07-08 21:39:42,178:INFO:Uploading model into container now
2023-07-08 21:39:42,179:INFO:_master_model_container: 8
2023-07-08 21:39:42,179:INFO:_display_container: 2
2023-07-08 21:39:42,179:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-08 21:39:42,179:INFO:create_model() successfully completed......................................
2023-07-08 21:39:42,254:INFO:SubProcess create_model() end ==================================
2023-07-08 21:39:42,255:INFO:Creating metrics dataframe
2023-07-08 21:39:42,275:INFO:Initializing Ada Boost Classifier
2023-07-08 21:39:42,275:INFO:Total runtime is 0.665229562918345 minutes
2023-07-08 21:39:42,282:INFO:SubProcess create_model() called ==================================
2023-07-08 21:39:42,282:INFO:Initializing create_model()
2023-07-08 21:39:42,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A13A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 21:39:42,283:INFO:Checking exceptions
2023-07-08 21:39:42,283:INFO:Importing libraries
2023-07-08 21:39:42,283:INFO:Copying training dataset
2023-07-08 21:39:42,293:INFO:Defining folds
2023-07-08 21:39:42,293:INFO:Declaring metric variables
2023-07-08 21:39:42,300:INFO:Importing untrained model
2023-07-08 21:39:42,308:INFO:Ada Boost Classifier Imported successfully
2023-07-08 21:39:42,322:INFO:Starting cross validation
2023-07-08 21:39:42,325:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 21:39:45,785:INFO:Calculating mean and std
2023-07-08 21:39:45,786:INFO:Creating metrics dataframe
2023-07-08 21:39:46,156:INFO:Uploading results into container
2023-07-08 21:39:46,157:INFO:Uploading model into container now
2023-07-08 21:39:46,158:INFO:_master_model_container: 9
2023-07-08 21:39:46,158:INFO:_display_container: 2
2023-07-08 21:39:46,158:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2023-07-08 21:39:46,158:INFO:create_model() successfully completed......................................
2023-07-08 21:39:46,225:INFO:SubProcess create_model() end ==================================
2023-07-08 21:39:46,225:INFO:Creating metrics dataframe
2023-07-08 21:39:46,237:INFO:Initializing Gradient Boosting Classifier
2023-07-08 21:39:46,237:INFO:Total runtime is 0.7312705953915912 minutes
2023-07-08 21:39:46,242:INFO:SubProcess create_model() called ==================================
2023-07-08 21:39:46,242:INFO:Initializing create_model()
2023-07-08 21:39:46,243:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A13A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 21:39:46,243:INFO:Checking exceptions
2023-07-08 21:39:46,243:INFO:Importing libraries
2023-07-08 21:39:46,243:INFO:Copying training dataset
2023-07-08 21:39:46,249:INFO:Defining folds
2023-07-08 21:39:46,249:INFO:Declaring metric variables
2023-07-08 21:39:46,253:INFO:Importing untrained model
2023-07-08 21:39:46,258:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 21:39:46,269:INFO:Starting cross validation
2023-07-08 21:39:46,271:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 21:39:50,343:INFO:Calculating mean and std
2023-07-08 21:39:50,345:INFO:Creating metrics dataframe
2023-07-08 21:39:50,733:INFO:Uploading results into container
2023-07-08 21:39:50,734:INFO:Uploading model into container now
2023-07-08 21:39:50,735:INFO:_master_model_container: 10
2023-07-08 21:39:50,735:INFO:_display_container: 2
2023-07-08 21:39:50,735:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 21:39:50,735:INFO:create_model() successfully completed......................................
2023-07-08 21:39:50,808:INFO:SubProcess create_model() end ==================================
2023-07-08 21:39:50,808:INFO:Creating metrics dataframe
2023-07-08 21:39:50,824:INFO:Initializing Linear Discriminant Analysis
2023-07-08 21:39:50,824:INFO:Total runtime is 0.8077259937922159 minutes
2023-07-08 21:39:50,831:INFO:SubProcess create_model() called ==================================
2023-07-08 21:39:50,831:INFO:Initializing create_model()
2023-07-08 21:39:50,832:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A13A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 21:39:50,832:INFO:Checking exceptions
2023-07-08 21:39:50,832:INFO:Importing libraries
2023-07-08 21:39:50,832:INFO:Copying training dataset
2023-07-08 21:39:50,843:INFO:Defining folds
2023-07-08 21:39:50,843:INFO:Declaring metric variables
2023-07-08 21:39:50,850:INFO:Importing untrained model
2023-07-08 21:39:50,859:INFO:Linear Discriminant Analysis Imported successfully
2023-07-08 21:39:50,872:INFO:Starting cross validation
2023-07-08 21:39:50,874:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 21:39:54,384:INFO:Calculating mean and std
2023-07-08 21:39:54,386:INFO:Creating metrics dataframe
2023-07-08 21:39:54,788:INFO:Uploading results into container
2023-07-08 21:39:54,789:INFO:Uploading model into container now
2023-07-08 21:39:54,789:INFO:_master_model_container: 11
2023-07-08 21:39:54,789:INFO:_display_container: 2
2023-07-08 21:39:54,790:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-08 21:39:54,790:INFO:create_model() successfully completed......................................
2023-07-08 21:39:54,854:INFO:SubProcess create_model() end ==================================
2023-07-08 21:39:54,854:INFO:Creating metrics dataframe
2023-07-08 21:39:54,872:INFO:Initializing Extra Trees Classifier
2023-07-08 21:39:54,872:INFO:Total runtime is 0.875185175736745 minutes
2023-07-08 21:39:54,877:INFO:SubProcess create_model() called ==================================
2023-07-08 21:39:54,877:INFO:Initializing create_model()
2023-07-08 21:39:54,877:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A13A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 21:39:54,878:INFO:Checking exceptions
2023-07-08 21:39:54,878:INFO:Importing libraries
2023-07-08 21:39:54,878:INFO:Copying training dataset
2023-07-08 21:39:54,883:INFO:Defining folds
2023-07-08 21:39:54,883:INFO:Declaring metric variables
2023-07-08 21:39:54,887:INFO:Importing untrained model
2023-07-08 21:39:54,892:INFO:Extra Trees Classifier Imported successfully
2023-07-08 21:39:54,905:INFO:Starting cross validation
2023-07-08 21:39:54,906:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 21:39:59,593:INFO:Calculating mean and std
2023-07-08 21:39:59,595:INFO:Creating metrics dataframe
2023-07-08 21:39:59,982:INFO:Uploading results into container
2023-07-08 21:39:59,983:INFO:Uploading model into container now
2023-07-08 21:39:59,983:INFO:_master_model_container: 12
2023-07-08 21:39:59,983:INFO:_display_container: 2
2023-07-08 21:39:59,984:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-08 21:39:59,984:INFO:create_model() successfully completed......................................
2023-07-08 21:40:00,056:INFO:SubProcess create_model() end ==================================
2023-07-08 21:40:00,056:INFO:Creating metrics dataframe
2023-07-08 21:40:00,071:INFO:Initializing Light Gradient Boosting Machine
2023-07-08 21:40:00,071:INFO:Total runtime is 0.9618283152580259 minutes
2023-07-08 21:40:00,076:INFO:SubProcess create_model() called ==================================
2023-07-08 21:40:00,076:INFO:Initializing create_model()
2023-07-08 21:40:00,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A13A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 21:40:00,076:INFO:Checking exceptions
2023-07-08 21:40:00,076:INFO:Importing libraries
2023-07-08 21:40:00,077:INFO:Copying training dataset
2023-07-08 21:40:00,084:INFO:Defining folds
2023-07-08 21:40:00,085:INFO:Declaring metric variables
2023-07-08 21:40:00,089:INFO:Importing untrained model
2023-07-08 21:40:00,095:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-08 21:40:00,106:INFO:Starting cross validation
2023-07-08 21:40:00,107:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 21:40:04,942:INFO:Calculating mean and std
2023-07-08 21:40:04,944:INFO:Creating metrics dataframe
2023-07-08 21:40:05,379:INFO:Uploading results into container
2023-07-08 21:40:05,380:INFO:Uploading model into container now
2023-07-08 21:40:05,381:INFO:_master_model_container: 13
2023-07-08 21:40:05,381:INFO:_display_container: 2
2023-07-08 21:40:05,382:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-08 21:40:05,383:INFO:create_model() successfully completed......................................
2023-07-08 21:40:05,456:INFO:SubProcess create_model() end ==================================
2023-07-08 21:40:05,457:INFO:Creating metrics dataframe
2023-07-08 21:40:05,471:INFO:Initializing Dummy Classifier
2023-07-08 21:40:05,471:INFO:Total runtime is 1.0518296003341674 minutes
2023-07-08 21:40:05,476:INFO:SubProcess create_model() called ==================================
2023-07-08 21:40:05,476:INFO:Initializing create_model()
2023-07-08 21:40:05,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A13A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 21:40:05,476:INFO:Checking exceptions
2023-07-08 21:40:05,476:INFO:Importing libraries
2023-07-08 21:40:05,477:INFO:Copying training dataset
2023-07-08 21:40:05,486:INFO:Defining folds
2023-07-08 21:40:05,486:INFO:Declaring metric variables
2023-07-08 21:40:05,492:INFO:Importing untrained model
2023-07-08 21:40:05,498:INFO:Dummy Classifier Imported successfully
2023-07-08 21:40:05,510:INFO:Starting cross validation
2023-07-08 21:40:05,512:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 21:40:05,819:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 21:40:05,821:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 21:40:05,852:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 21:40:05,885:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 21:40:05,886:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 21:40:05,899:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 21:40:05,912:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 21:40:05,920:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 21:40:06,630:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 21:40:06,638:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 21:40:09,080:INFO:Calculating mean and std
2023-07-08 21:40:09,081:INFO:Creating metrics dataframe
2023-07-08 21:40:09,528:INFO:Uploading results into container
2023-07-08 21:40:09,529:INFO:Uploading model into container now
2023-07-08 21:40:09,529:INFO:_master_model_container: 14
2023-07-08 21:40:09,529:INFO:_display_container: 2
2023-07-08 21:40:09,530:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-08 21:40:09,530:INFO:create_model() successfully completed......................................
2023-07-08 21:40:09,603:INFO:SubProcess create_model() end ==================================
2023-07-08 21:40:09,604:INFO:Creating metrics dataframe
2023-07-08 21:40:09,632:INFO:Initializing create_model()
2023-07-08 21:40:09,633:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-08 21:40:09,633:INFO:Checking exceptions
2023-07-08 21:40:09,636:INFO:Importing libraries
2023-07-08 21:40:09,636:INFO:Copying training dataset
2023-07-08 21:40:09,644:INFO:Defining folds
2023-07-08 21:40:09,644:INFO:Declaring metric variables
2023-07-08 21:40:09,644:INFO:Importing untrained model
2023-07-08 21:40:09,645:INFO:Declaring custom model
2023-07-08 21:40:09,646:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 21:40:09,648:INFO:Cross validation set to False
2023-07-08 21:40:09,648:INFO:Fitting Model
2023-07-08 21:40:10,068:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 21:40:10,068:INFO:create_model() successfully completed......................................
2023-07-08 21:40:10,192:INFO:_master_model_container: 14
2023-07-08 21:40:10,192:INFO:_display_container: 2
2023-07-08 21:40:10,193:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 21:40:10,194:INFO:compare_models() successfully completed......................................
2023-07-08 21:40:24,500:INFO:Initializing tune_model()
2023-07-08 21:40:24,501:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>)
2023-07-08 21:40:24,501:INFO:Checking exceptions
2023-07-08 21:40:24,544:INFO:Copying training dataset
2023-07-08 21:40:24,551:INFO:Checking base model
2023-07-08 21:40:24,551:INFO:Base model : Gradient Boosting Classifier
2023-07-08 21:40:24,558:INFO:Declaring metric variables
2023-07-08 21:40:24,564:INFO:Defining Hyperparameters
2023-07-08 21:40:24,643:INFO:Tuning with n_jobs=-1
2023-07-08 21:40:24,643:INFO:Initializing RandomizedSearchCV
2023-07-08 21:41:01,101:INFO:best_params: {'actual_estimator__subsample': 0.75, 'actual_estimator__n_estimators': 110, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__min_impurity_decrease': 0.5, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 8, 'actual_estimator__learning_rate': 0.01}
2023-07-08 21:41:01,103:INFO:Hyperparameter search completed
2023-07-08 21:41:01,103:INFO:SubProcess create_model() called ==================================
2023-07-08 21:41:01,104:INFO:Initializing create_model()
2023-07-08 21:41:01,104:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292B796DEE0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.75, 'n_estimators': 110, 'min_samples_split': 9, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.5, 'max_features': 'log2', 'max_depth': 8, 'learning_rate': 0.01})
2023-07-08 21:41:01,104:INFO:Checking exceptions
2023-07-08 21:41:01,104:INFO:Importing libraries
2023-07-08 21:41:01,104:INFO:Copying training dataset
2023-07-08 21:41:01,111:INFO:Defining folds
2023-07-08 21:41:01,111:INFO:Declaring metric variables
2023-07-08 21:41:01,114:INFO:Importing untrained model
2023-07-08 21:41:01,114:INFO:Declaring custom model
2023-07-08 21:41:01,119:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 21:41:01,129:INFO:Starting cross validation
2023-07-08 21:41:01,130:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 21:41:04,946:INFO:Calculating mean and std
2023-07-08 21:41:04,948:INFO:Creating metrics dataframe
2023-07-08 21:41:04,955:INFO:Finalizing model
2023-07-08 21:41:05,783:INFO:Uploading results into container
2023-07-08 21:41:05,784:INFO:Uploading model into container now
2023-07-08 21:41:05,785:INFO:_master_model_container: 15
2023-07-08 21:41:05,785:INFO:_display_container: 3
2023-07-08 21:41:05,786:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='deviance', max_depth=8,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.5, min_samples_leaf=1,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=110, n_iter_no_change=None,
                           random_state=42, subsample=0.75, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 21:41:05,786:INFO:create_model() successfully completed......................................
2023-07-08 21:41:05,855:INFO:SubProcess create_model() end ==================================
2023-07-08 21:41:05,855:INFO:choose_better activated
2023-07-08 21:41:05,859:INFO:SubProcess create_model() called ==================================
2023-07-08 21:41:05,859:INFO:Initializing create_model()
2023-07-08 21:41:05,859:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-08 21:41:05,859:INFO:Checking exceptions
2023-07-08 21:41:05,861:INFO:Importing libraries
2023-07-08 21:41:05,861:INFO:Copying training dataset
2023-07-08 21:41:05,867:INFO:Defining folds
2023-07-08 21:41:05,867:INFO:Declaring metric variables
2023-07-08 21:41:05,867:INFO:Importing untrained model
2023-07-08 21:41:05,867:INFO:Declaring custom model
2023-07-08 21:41:05,868:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 21:41:05,868:INFO:Starting cross validation
2023-07-08 21:41:05,870:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 21:41:09,751:INFO:Calculating mean and std
2023-07-08 21:41:09,751:INFO:Creating metrics dataframe
2023-07-08 21:41:09,754:INFO:Finalizing model
2023-07-08 21:41:10,261:INFO:Uploading results into container
2023-07-08 21:41:10,262:INFO:Uploading model into container now
2023-07-08 21:41:10,262:INFO:_master_model_container: 16
2023-07-08 21:41:10,262:INFO:_display_container: 4
2023-07-08 21:41:10,262:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 21:41:10,263:INFO:create_model() successfully completed......................................
2023-07-08 21:41:10,325:INFO:SubProcess create_model() end ==================================
2023-07-08 21:41:10,326:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8281
2023-07-08 21:41:10,327:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='deviance', max_depth=8,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.5, min_samples_leaf=1,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=110, n_iter_no_change=None,
                           random_state=42, subsample=0.75, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.822
2023-07-08 21:41:10,328:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-07-08 21:41:10,328:INFO:choose_better completed
2023-07-08 21:41:10,328:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-08 21:41:10,340:INFO:_master_model_container: 16
2023-07-08 21:41:10,341:INFO:_display_container: 3
2023-07-08 21:41:10,341:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 21:41:10,341:INFO:tune_model() successfully completed......................................
2023-07-08 21:41:34,073:INFO:Initializing evaluate_model()
2023-07-08 21:41:34,073:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-08 21:41:34,104:INFO:Initializing plot_model()
2023-07-08 21:41:34,105:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, system=True)
2023-07-08 21:41:34,105:INFO:Checking exceptions
2023-07-08 21:41:34,108:INFO:Preloading libraries
2023-07-08 21:41:34,116:INFO:Copying training dataset
2023-07-08 21:41:34,117:INFO:Plot type: pipeline
2023-07-08 21:41:34,258:INFO:Visual Rendered Successfully
2023-07-08 21:41:34,333:INFO:plot_model() successfully completed......................................
2023-07-08 21:41:38,212:INFO:Initializing plot_model()
2023-07-08 21:41:38,213:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, system=True)
2023-07-08 21:41:38,213:INFO:Checking exceptions
2023-07-08 21:41:38,216:INFO:Preloading libraries
2023-07-08 21:41:38,226:INFO:Copying training dataset
2023-07-08 21:41:38,226:INFO:Plot type: feature
2023-07-08 21:41:38,226:WARNING:No coef_ found. Trying feature_importances_
2023-07-08 21:41:38,378:INFO:Visual Rendered Successfully
2023-07-08 21:41:38,442:INFO:plot_model() successfully completed......................................
2023-07-08 21:41:55,720:INFO:Initializing evaluate_model()
2023-07-08 21:41:55,721:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-08 21:41:55,755:INFO:Initializing plot_model()
2023-07-08 21:41:55,756:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, system=True)
2023-07-08 21:41:55,756:INFO:Checking exceptions
2023-07-08 21:41:55,760:INFO:Preloading libraries
2023-07-08 21:41:55,770:INFO:Copying training dataset
2023-07-08 21:41:55,770:INFO:Plot type: pipeline
2023-07-08 21:41:55,857:INFO:Visual Rendered Successfully
2023-07-08 21:41:55,922:INFO:plot_model() successfully completed......................................
2023-07-08 21:41:59,641:INFO:Initializing predict_model()
2023-07-08 21:41:59,641:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000292BC076B80>)
2023-07-08 21:41:59,641:INFO:Checking exceptions
2023-07-08 21:41:59,641:INFO:Preloading libraries
2023-07-08 21:42:11,771:INFO:Initializing finalize_model()
2023-07-08 21:42:11,771:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-07-08 21:42:11,772:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 21:42:11,777:INFO:Initializing create_model()
2023-07-08 21:42:11,777:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-07-08 21:42:11,777:INFO:Checking exceptions
2023-07-08 21:42:11,780:INFO:Importing libraries
2023-07-08 21:42:11,780:INFO:Copying training dataset
2023-07-08 21:42:11,780:INFO:Defining folds
2023-07-08 21:42:11,780:INFO:Declaring metric variables
2023-07-08 21:42:11,780:INFO:Importing untrained model
2023-07-08 21:42:11,780:INFO:Declaring custom model
2023-07-08 21:42:11,781:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 21:42:11,782:INFO:Cross validation set to False
2023-07-08 21:42:11,783:INFO:Fitting Model
2023-07-08 21:42:11,878:INFO:Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-07-08 21:42:11,878:INFO:create_model() successfully completed......................................
2023-07-08 21:42:11,941:INFO:_master_model_container: 16
2023-07-08 21:42:11,941:INFO:_display_container: 4
2023-07-08 21:42:11,956:INFO:Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-07-08 21:42:11,956:INFO:finalize_model() successfully completed......................................
2023-07-08 21:42:12,050:INFO:Initializing save_model()
2023-07-08 21:42:12,050:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=gbc, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-07-08 21:42:12,050:INFO:Adding model into prep_pipe
2023-07-08 21:42:12,061:INFO:gbc.pkl saved in current working directory
2023-07-08 21:42:12,073:INFO:Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-07-08 21:42:12,074:INFO:save_model() successfully completed......................................
2023-07-08 21:42:21,611:INFO:Initializing load_model()
2023-07-08 21:42:21,612:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 21:42:21,638:INFO:Initializing predict_model()
2023-07-08 21:42:21,638:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000292BC076E50>)
2023-07-08 21:42:21,638:INFO:Checking exceptions
2023-07-08 21:42:21,638:INFO:Preloading libraries
2023-07-08 21:42:21,642:INFO:Set up data.
2023-07-08 21:42:21,655:INFO:Set up index.
2023-07-08 21:42:21,687:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py:586: UserWarning: Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 567, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 337, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\utils\generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 567, in roc_auc_score
    return _average_binary_score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 337, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2023-07-08 21:42:21,692:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:663: RuntimeWarning: invalid value encountered in true_divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-07-08 21:42:59,538:INFO:Initializing load_model()
2023-07-08 21:42:59,539:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 21:42:59,954:INFO:Initializing predict_model()
2023-07-08 21:42:59,954:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000292BC0765E0>)
2023-07-08 21:42:59,954:INFO:Checking exceptions
2023-07-08 21:42:59,954:INFO:Preloading libraries
2023-07-08 21:42:59,957:INFO:Set up data.
2023-07-08 21:42:59,968:INFO:Set up index.
2023-07-08 21:48:03,261:INFO:Initializing load_model()
2023-07-08 21:48:03,262:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 21:48:03,632:INFO:Initializing predict_model()
2023-07-08 21:48:03,632:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000292BAF91280>)
2023-07-08 21:48:03,632:INFO:Checking exceptions
2023-07-08 21:48:03,632:INFO:Preloading libraries
2023-07-08 21:48:03,635:INFO:Set up data.
2023-07-08 21:48:03,645:INFO:Set up index.
2023-07-08 21:48:33,217:INFO:Initializing load_model()
2023-07-08 21:48:33,217:INFO:load_model(model_name=gbc, platform=None, authentication=None, verbose=True)
2023-07-08 21:48:33,580:INFO:Initializing predict_model()
2023-07-08 21:48:33,580:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='deviance',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000292BCB83CA0>)
2023-07-08 21:48:33,580:INFO:Checking exceptions
2023-07-08 21:48:33,581:INFO:Preloading libraries
2023-07-08 21:48:33,583:INFO:Set up data.
2023-07-08 21:48:33,594:INFO:Set up index.
2023-07-08 21:51:55,238:INFO:Initializing plot_model()
2023-07-08 21:51:55,239:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, system=True)
2023-07-08 21:51:55,239:INFO:Checking exceptions
2023-07-08 21:51:55,242:INFO:Preloading libraries
2023-07-08 21:51:55,251:INFO:Copying training dataset
2023-07-08 21:51:55,251:INFO:Plot type: confusion_matrix
2023-07-08 21:51:55,318:INFO:Fitting Model
2023-07-08 21:51:55,320:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-07-08 21:51:55,321:INFO:Scoring test/hold-out set
2023-07-08 21:51:55,429:INFO:Visual Rendered Successfully
2023-07-08 21:51:55,499:INFO:plot_model() successfully completed......................................
2023-07-08 21:52:51,408:INFO:Initializing plot_model()
2023-07-08 21:52:51,408:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BC3688E0>, system=True)
2023-07-08 21:52:51,409:INFO:Checking exceptions
2023-07-08 21:52:51,411:INFO:Preloading libraries
2023-07-08 21:52:51,424:INFO:Copying training dataset
2023-07-08 21:52:51,424:INFO:Plot type: feature
2023-07-08 21:52:51,425:WARNING:No coef_ found. Trying feature_importances_
2023-07-08 21:52:51,577:INFO:Visual Rendered Successfully
2023-07-08 21:52:51,647:INFO:plot_model() successfully completed......................................
2023-07-08 22:43:28,650:INFO:PyCaret ClassificationExperiment
2023-07-08 22:43:28,650:INFO:Logging name: clf-default-name
2023-07-08 22:43:28,650:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-08 22:43:28,650:INFO:version 3.0.4
2023-07-08 22:43:28,650:INFO:Initializing setup()
2023-07-08 22:43:28,650:INFO:self.USI: 6c22
2023-07-08 22:43:28,650:INFO:self._variable_keys: {'n_jobs_param', 'data', 'y_test', '_ml_usecase', 'memory', 'fold_groups_param', 'fix_imbalance', 'y', 'X_train', 'target_param', 'seed', 'y_train', 'exp_id', '_available_plots', 'html_param', 'X_test', 'fold_shuffle_param', 'logging_param', 'exp_name_log', 'gpu_param', 'USI', 'gpu_n_jobs_param', 'is_multiclass', 'fold_generator', 'idx', 'X', 'pipeline', 'log_plots_param'}
2023-07-08 22:43:28,650:INFO:Checking environment
2023-07-08 22:43:28,650:INFO:python_version: 3.9.13
2023-07-08 22:43:28,650:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-07-08 22:43:28,650:INFO:machine: AMD64
2023-07-08 22:43:28,650:INFO:platform: Windows-10-10.0.19045-SP0
2023-07-08 22:43:28,650:INFO:Memory: svmem(total=17125732352, available=9385873408, percent=45.2, used=7739858944, free=9385873408)
2023-07-08 22:43:28,650:INFO:Physical Core: 4
2023-07-08 22:43:28,650:INFO:Logical Core: 8
2023-07-08 22:43:28,650:INFO:Checking libraries
2023-07-08 22:43:28,651:INFO:System:
2023-07-08 22:43:28,651:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-07-08 22:43:28,651:INFO:executable: C:\Users\hamim\anaconda3\python.exe
2023-07-08 22:43:28,651:INFO:   machine: Windows-10-10.0.19045-SP0
2023-07-08 22:43:28,651:INFO:PyCaret required dependencies:
2023-07-08 22:43:28,651:INFO:                 pip: 22.2.2
2023-07-08 22:43:28,651:INFO:          setuptools: 63.4.1
2023-07-08 22:43:28,651:INFO:             pycaret: 3.0.4
2023-07-08 22:43:28,651:INFO:             IPython: 7.31.1
2023-07-08 22:43:28,651:INFO:          ipywidgets: 7.6.5
2023-07-08 22:43:28,652:INFO:                tqdm: 4.64.1
2023-07-08 22:43:28,652:INFO:               numpy: 1.21.5
2023-07-08 22:43:28,652:INFO:              pandas: 1.4.4
2023-07-08 22:43:28,652:INFO:              jinja2: 2.11.3
2023-07-08 22:43:28,652:INFO:               scipy: 1.9.1
2023-07-08 22:43:28,652:INFO:              joblib: 1.2.0
2023-07-08 22:43:28,652:INFO:             sklearn: 1.0.2
2023-07-08 22:43:28,652:INFO:                pyod: 1.1.0
2023-07-08 22:43:28,652:INFO:            imblearn: 0.10.1
2023-07-08 22:43:28,652:INFO:   category_encoders: 2.6.1
2023-07-08 22:43:28,652:INFO:            lightgbm: 3.3.5
2023-07-08 22:43:28,652:INFO:               numba: 0.55.1
2023-07-08 22:43:28,652:INFO:            requests: 2.28.1
2023-07-08 22:43:28,652:INFO:          matplotlib: 3.5.2
2023-07-08 22:43:28,652:INFO:          scikitplot: 0.3.7
2023-07-08 22:43:28,652:INFO:         yellowbrick: 1.5
2023-07-08 22:43:28,653:INFO:              plotly: 5.9.0
2023-07-08 22:43:28,653:INFO:    plotly-resampler: Not installed
2023-07-08 22:43:28,653:INFO:             kaleido: 0.2.1
2023-07-08 22:43:28,653:INFO:           schemdraw: 0.15
2023-07-08 22:43:28,653:INFO:         statsmodels: 0.13.2
2023-07-08 22:43:28,653:INFO:              sktime: 0.20.0
2023-07-08 22:43:28,653:INFO:               tbats: 1.1.3
2023-07-08 22:43:28,653:INFO:            pmdarima: 2.0.3
2023-07-08 22:43:28,653:INFO:              psutil: 5.9.0
2023-07-08 22:43:28,653:INFO:          markupsafe: 2.0.1
2023-07-08 22:43:28,653:INFO:             pickle5: Not installed
2023-07-08 22:43:28,653:INFO:         cloudpickle: 2.0.0
2023-07-08 22:43:28,653:INFO:         deprecation: 2.1.0
2023-07-08 22:43:28,653:INFO:              xxhash: 3.2.0
2023-07-08 22:43:28,653:INFO:           wurlitzer: Not installed
2023-07-08 22:43:28,653:INFO:PyCaret optional dependencies:
2023-07-08 22:43:28,653:INFO:                shap: Not installed
2023-07-08 22:43:28,653:INFO:           interpret: Not installed
2023-07-08 22:43:28,653:INFO:                umap: Not installed
2023-07-08 22:43:28,653:INFO:    pandas_profiling: Not installed
2023-07-08 22:43:28,654:INFO:  explainerdashboard: Not installed
2023-07-08 22:43:28,654:INFO:             autoviz: Not installed
2023-07-08 22:43:28,654:INFO:           fairlearn: Not installed
2023-07-08 22:43:28,654:INFO:          deepchecks: Not installed
2023-07-08 22:43:28,654:INFO:             xgboost: Not installed
2023-07-08 22:43:28,654:INFO:            catboost: Not installed
2023-07-08 22:43:28,654:INFO:              kmodes: Not installed
2023-07-08 22:43:28,654:INFO:             mlxtend: Not installed
2023-07-08 22:43:28,654:INFO:       statsforecast: Not installed
2023-07-08 22:43:28,654:INFO:        tune_sklearn: Not installed
2023-07-08 22:43:28,654:INFO:                 ray: Not installed
2023-07-08 22:43:28,654:INFO:            hyperopt: Not installed
2023-07-08 22:43:28,654:INFO:              optuna: Not installed
2023-07-08 22:43:28,654:INFO:               skopt: Not installed
2023-07-08 22:43:28,654:INFO:              mlflow: Not installed
2023-07-08 22:43:28,654:INFO:              gradio: Not installed
2023-07-08 22:43:28,654:INFO:             fastapi: Not installed
2023-07-08 22:43:28,654:INFO:             uvicorn: Not installed
2023-07-08 22:43:28,654:INFO:              m2cgen: Not installed
2023-07-08 22:43:28,654:INFO:           evidently: Not installed
2023-07-08 22:43:28,654:INFO:               fugue: Not installed
2023-07-08 22:43:28,655:INFO:           streamlit: Not installed
2023-07-08 22:43:28,655:INFO:             prophet: Not installed
2023-07-08 22:43:28,655:INFO:None
2023-07-08 22:43:28,655:INFO:Set up data.
2023-07-08 22:43:28,667:INFO:Set up train/test split.
2023-07-08 22:43:28,673:INFO:Set up index.
2023-07-08 22:43:28,673:INFO:Set up folding strategy.
2023-07-08 22:43:28,673:INFO:Assigning column types.
2023-07-08 22:43:28,678:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-08 22:43:28,731:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-08 22:43:28,732:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 22:43:28,766:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:43:28,766:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:43:28,816:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-08 22:43:28,817:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 22:43:28,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:43:28,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:43:28,850:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-08 22:43:28,903:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 22:43:28,933:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:43:28,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:43:28,979:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 22:43:29,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:43:29,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:43:29,018:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-08 22:43:29,098:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:43:29,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:43:29,172:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:43:29,172:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:43:29,173:INFO:Preparing preprocessing pipeline...
2023-07-08 22:43:29,174:INFO:Set up simple imputation.
2023-07-08 22:43:29,174:INFO:Set up imbalanced handling.
2023-07-08 22:43:29,175:INFO:Set up column name cleaning.
2023-07-08 22:43:29,214:INFO:Finished creating preprocessing pipeline.
2023-07-08 22:43:29,220:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-08 22:43:29,220:INFO:Creating final display dataframe.
2023-07-08 22:43:29,332:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Target
2                   Target type            Binary
3           Original data shape        (2802, 34)
4        Transformed data shape        (3825, 34)
5   Transformed train set shape        (2984, 34)
6    Transformed test set shape         (841, 34)
7              Numeric features                33
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              6c22
2023-07-08 22:43:29,423:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:43:29,423:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:43:29,495:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:43:29,495:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:43:29,496:INFO:setup() successfully completed in 1.23s...............
2023-07-08 22:43:42,247:INFO:Initializing compare_models()
2023-07-08 22:43:42,248:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-08 22:43:42,248:INFO:Checking exceptions
2023-07-08 22:43:42,254:INFO:Preparing display monitor
2023-07-08 22:43:42,316:INFO:Initializing Logistic Regression
2023-07-08 22:43:42,316:INFO:Total runtime is 0.0 minutes
2023-07-08 22:43:42,322:INFO:SubProcess create_model() called ==================================
2023-07-08 22:43:42,323:INFO:Initializing create_model()
2023-07-08 22:43:42,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC17BA00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 22:43:42,324:INFO:Checking exceptions
2023-07-08 22:43:42,324:INFO:Importing libraries
2023-07-08 22:43:42,324:INFO:Copying training dataset
2023-07-08 22:43:42,331:INFO:Defining folds
2023-07-08 22:43:42,331:INFO:Declaring metric variables
2023-07-08 22:43:42,336:INFO:Importing untrained model
2023-07-08 22:43:42,342:INFO:Logistic Regression Imported successfully
2023-07-08 22:43:42,354:INFO:Starting cross validation
2023-07-08 22:43:42,356:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 22:43:53,482:INFO:Calculating mean and std
2023-07-08 22:43:53,484:INFO:Creating metrics dataframe
2023-07-08 22:43:53,939:INFO:Uploading results into container
2023-07-08 22:43:53,940:INFO:Uploading model into container now
2023-07-08 22:43:53,940:INFO:_master_model_container: 1
2023-07-08 22:43:53,941:INFO:_display_container: 2
2023-07-08 22:43:53,941:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-08 22:43:53,941:INFO:create_model() successfully completed......................................
2023-07-08 22:43:54,028:INFO:SubProcess create_model() end ==================================
2023-07-08 22:43:54,028:INFO:Creating metrics dataframe
2023-07-08 22:43:54,043:INFO:Initializing K Neighbors Classifier
2023-07-08 22:43:54,043:INFO:Total runtime is 0.19546362559000652 minutes
2023-07-08 22:43:54,048:INFO:SubProcess create_model() called ==================================
2023-07-08 22:43:54,049:INFO:Initializing create_model()
2023-07-08 22:43:54,049:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC17BA00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 22:43:54,049:INFO:Checking exceptions
2023-07-08 22:43:54,049:INFO:Importing libraries
2023-07-08 22:43:54,049:INFO:Copying training dataset
2023-07-08 22:43:54,056:INFO:Defining folds
2023-07-08 22:43:54,056:INFO:Declaring metric variables
2023-07-08 22:43:54,062:INFO:Importing untrained model
2023-07-08 22:43:54,069:INFO:K Neighbors Classifier Imported successfully
2023-07-08 22:43:54,081:INFO:Starting cross validation
2023-07-08 22:43:54,082:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 22:43:54,266:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 22:43:54,278:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 22:43:54,304:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 22:43:54,309:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 22:43:54,324:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 22:43:54,328:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 22:43:54,345:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 22:43:54,364:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 22:43:55,118:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 22:43:55,139:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 22:43:57,378:INFO:Calculating mean and std
2023-07-08 22:43:57,380:INFO:Creating metrics dataframe
2023-07-08 22:43:57,806:INFO:Uploading results into container
2023-07-08 22:43:57,807:INFO:Uploading model into container now
2023-07-08 22:43:57,807:INFO:_master_model_container: 2
2023-07-08 22:43:57,807:INFO:_display_container: 2
2023-07-08 22:43:57,807:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-08 22:43:57,808:INFO:create_model() successfully completed......................................
2023-07-08 22:43:57,880:INFO:SubProcess create_model() end ==================================
2023-07-08 22:43:57,881:INFO:Creating metrics dataframe
2023-07-08 22:43:57,894:INFO:Initializing Naive Bayes
2023-07-08 22:43:57,894:INFO:Total runtime is 0.2596396128336589 minutes
2023-07-08 22:43:57,899:INFO:SubProcess create_model() called ==================================
2023-07-08 22:43:57,899:INFO:Initializing create_model()
2023-07-08 22:43:57,899:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC17BA00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 22:43:57,899:INFO:Checking exceptions
2023-07-08 22:43:57,900:INFO:Importing libraries
2023-07-08 22:43:57,900:INFO:Copying training dataset
2023-07-08 22:43:57,907:INFO:Defining folds
2023-07-08 22:43:57,907:INFO:Declaring metric variables
2023-07-08 22:43:57,912:INFO:Importing untrained model
2023-07-08 22:43:57,917:INFO:Naive Bayes Imported successfully
2023-07-08 22:43:57,931:INFO:Starting cross validation
2023-07-08 22:43:57,933:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 22:44:01,092:INFO:Calculating mean and std
2023-07-08 22:44:01,093:INFO:Creating metrics dataframe
2023-07-08 22:44:01,524:INFO:Uploading results into container
2023-07-08 22:44:01,525:INFO:Uploading model into container now
2023-07-08 22:44:01,525:INFO:_master_model_container: 3
2023-07-08 22:44:01,525:INFO:_display_container: 2
2023-07-08 22:44:01,526:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-08 22:44:01,526:INFO:create_model() successfully completed......................................
2023-07-08 22:44:01,590:INFO:SubProcess create_model() end ==================================
2023-07-08 22:44:01,590:INFO:Creating metrics dataframe
2023-07-08 22:44:01,599:INFO:Initializing Decision Tree Classifier
2023-07-08 22:44:01,600:INFO:Total runtime is 0.32141149044036865 minutes
2023-07-08 22:44:01,604:INFO:SubProcess create_model() called ==================================
2023-07-08 22:44:01,604:INFO:Initializing create_model()
2023-07-08 22:44:01,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC17BA00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 22:44:01,605:INFO:Checking exceptions
2023-07-08 22:44:01,606:INFO:Importing libraries
2023-07-08 22:44:01,606:INFO:Copying training dataset
2023-07-08 22:44:01,614:INFO:Defining folds
2023-07-08 22:44:01,614:INFO:Declaring metric variables
2023-07-08 22:44:01,617:INFO:Importing untrained model
2023-07-08 22:44:01,621:INFO:Decision Tree Classifier Imported successfully
2023-07-08 22:44:01,631:INFO:Starting cross validation
2023-07-08 22:44:01,632:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 22:44:05,166:INFO:Calculating mean and std
2023-07-08 22:44:05,168:INFO:Creating metrics dataframe
2023-07-08 22:44:05,691:INFO:Uploading results into container
2023-07-08 22:44:05,692:INFO:Uploading model into container now
2023-07-08 22:44:05,692:INFO:_master_model_container: 4
2023-07-08 22:44:05,692:INFO:_display_container: 2
2023-07-08 22:44:05,693:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-08 22:44:05,693:INFO:create_model() successfully completed......................................
2023-07-08 22:44:05,769:INFO:SubProcess create_model() end ==================================
2023-07-08 22:44:05,769:INFO:Creating metrics dataframe
2023-07-08 22:44:05,782:INFO:Initializing SVM - Linear Kernel
2023-07-08 22:44:05,783:INFO:Total runtime is 0.39112826188405353 minutes
2023-07-08 22:44:05,789:INFO:SubProcess create_model() called ==================================
2023-07-08 22:44:05,790:INFO:Initializing create_model()
2023-07-08 22:44:05,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC17BA00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 22:44:05,790:INFO:Checking exceptions
2023-07-08 22:44:05,790:INFO:Importing libraries
2023-07-08 22:44:05,790:INFO:Copying training dataset
2023-07-08 22:44:05,799:INFO:Defining folds
2023-07-08 22:44:05,799:INFO:Declaring metric variables
2023-07-08 22:44:05,804:INFO:Importing untrained model
2023-07-08 22:44:05,808:INFO:SVM - Linear Kernel Imported successfully
2023-07-08 22:44:05,820:INFO:Starting cross validation
2023-07-08 22:44:05,822:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 22:44:06,045:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 22:44:06,110:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 22:44:06,129:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 22:44:06,130:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 22:44:06,157:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 22:44:06,187:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 22:44:06,188:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 22:44:06,239:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 22:44:07,252:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 22:44:07,283:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 22:44:09,932:INFO:Calculating mean and std
2023-07-08 22:44:09,934:INFO:Creating metrics dataframe
2023-07-08 22:44:10,458:INFO:Uploading results into container
2023-07-08 22:44:10,459:INFO:Uploading model into container now
2023-07-08 22:44:10,460:INFO:_master_model_container: 5
2023-07-08 22:44:10,460:INFO:_display_container: 2
2023-07-08 22:44:10,461:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-08 22:44:10,461:INFO:create_model() successfully completed......................................
2023-07-08 22:44:10,557:INFO:SubProcess create_model() end ==================================
2023-07-08 22:44:10,557:INFO:Creating metrics dataframe
2023-07-08 22:44:10,574:INFO:Initializing Ridge Classifier
2023-07-08 22:44:10,574:INFO:Total runtime is 0.47096997102101645 minutes
2023-07-08 22:44:10,580:INFO:SubProcess create_model() called ==================================
2023-07-08 22:44:10,581:INFO:Initializing create_model()
2023-07-08 22:44:10,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC17BA00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 22:44:10,581:INFO:Checking exceptions
2023-07-08 22:44:10,581:INFO:Importing libraries
2023-07-08 22:44:10,581:INFO:Copying training dataset
2023-07-08 22:44:10,594:INFO:Defining folds
2023-07-08 22:44:10,595:INFO:Declaring metric variables
2023-07-08 22:44:10,601:INFO:Importing untrained model
2023-07-08 22:44:10,609:INFO:Ridge Classifier Imported successfully
2023-07-08 22:44:10,622:INFO:Starting cross validation
2023-07-08 22:44:10,624:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 22:44:10,795:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 22:44:10,823:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 22:44:10,824:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 22:44:10,863:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 22:44:10,867:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 22:44:10,882:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 22:44:10,888:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 22:44:10,908:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 22:44:11,563:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 22:44:11,576:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 22:44:14,217:INFO:Calculating mean and std
2023-07-08 22:44:14,218:INFO:Creating metrics dataframe
2023-07-08 22:44:14,649:INFO:Uploading results into container
2023-07-08 22:44:14,650:INFO:Uploading model into container now
2023-07-08 22:44:14,651:INFO:_master_model_container: 6
2023-07-08 22:44:14,651:INFO:_display_container: 2
2023-07-08 22:44:14,651:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=42, solver='auto', tol=0.001)
2023-07-08 22:44:14,651:INFO:create_model() successfully completed......................................
2023-07-08 22:44:14,717:INFO:SubProcess create_model() end ==================================
2023-07-08 22:44:14,717:INFO:Creating metrics dataframe
2023-07-08 22:44:14,730:INFO:Initializing Random Forest Classifier
2023-07-08 22:44:14,730:INFO:Total runtime is 0.540244174003601 minutes
2023-07-08 22:44:14,734:INFO:SubProcess create_model() called ==================================
2023-07-08 22:44:14,735:INFO:Initializing create_model()
2023-07-08 22:44:14,735:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC17BA00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 22:44:14,735:INFO:Checking exceptions
2023-07-08 22:44:14,735:INFO:Importing libraries
2023-07-08 22:44:14,735:INFO:Copying training dataset
2023-07-08 22:44:14,741:INFO:Defining folds
2023-07-08 22:44:14,741:INFO:Declaring metric variables
2023-07-08 22:44:14,745:INFO:Importing untrained model
2023-07-08 22:44:14,750:INFO:Random Forest Classifier Imported successfully
2023-07-08 22:44:14,761:INFO:Starting cross validation
2023-07-08 22:44:14,762:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 22:44:19,556:INFO:Calculating mean and std
2023-07-08 22:44:19,558:INFO:Creating metrics dataframe
2023-07-08 22:44:20,006:INFO:Uploading results into container
2023-07-08 22:44:20,007:INFO:Uploading model into container now
2023-07-08 22:44:20,008:INFO:_master_model_container: 7
2023-07-08 22:44:20,008:INFO:_display_container: 2
2023-07-08 22:44:20,008:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-08 22:44:20,008:INFO:create_model() successfully completed......................................
2023-07-08 22:44:20,073:INFO:SubProcess create_model() end ==================================
2023-07-08 22:44:20,074:INFO:Creating metrics dataframe
2023-07-08 22:44:20,089:INFO:Initializing Quadratic Discriminant Analysis
2023-07-08 22:44:20,089:INFO:Total runtime is 0.6295519153277078 minutes
2023-07-08 22:44:20,095:INFO:SubProcess create_model() called ==================================
2023-07-08 22:44:20,096:INFO:Initializing create_model()
2023-07-08 22:44:20,096:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC17BA00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 22:44:20,096:INFO:Checking exceptions
2023-07-08 22:44:20,096:INFO:Importing libraries
2023-07-08 22:44:20,097:INFO:Copying training dataset
2023-07-08 22:44:20,105:INFO:Defining folds
2023-07-08 22:44:20,105:INFO:Declaring metric variables
2023-07-08 22:44:20,112:INFO:Importing untrained model
2023-07-08 22:44:20,117:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-08 22:44:20,132:INFO:Starting cross validation
2023-07-08 22:44:20,135:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 22:44:20,290:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 22:44:20,325:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 22:44:20,325:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 22:44:20,342:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 22:44:20,345:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 22:44:20,353:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 22:44:20,372:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 22:44:20,473:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 22:44:20,482:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 22:44:20,519:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 22:44:21,225:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 22:44:21,232:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 22:44:21,282:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 22:44:21,299:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 22:44:24,060:INFO:Calculating mean and std
2023-07-08 22:44:24,061:INFO:Creating metrics dataframe
2023-07-08 22:44:24,541:INFO:Uploading results into container
2023-07-08 22:44:24,542:INFO:Uploading model into container now
2023-07-08 22:44:24,542:INFO:_master_model_container: 8
2023-07-08 22:44:24,543:INFO:_display_container: 2
2023-07-08 22:44:24,543:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-08 22:44:24,543:INFO:create_model() successfully completed......................................
2023-07-08 22:44:24,617:INFO:SubProcess create_model() end ==================================
2023-07-08 22:44:24,617:INFO:Creating metrics dataframe
2023-07-08 22:44:24,631:INFO:Initializing Ada Boost Classifier
2023-07-08 22:44:24,631:INFO:Total runtime is 0.7052588780721027 minutes
2023-07-08 22:44:24,638:INFO:SubProcess create_model() called ==================================
2023-07-08 22:44:24,638:INFO:Initializing create_model()
2023-07-08 22:44:24,638:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC17BA00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 22:44:24,639:INFO:Checking exceptions
2023-07-08 22:44:24,639:INFO:Importing libraries
2023-07-08 22:44:24,639:INFO:Copying training dataset
2023-07-08 22:44:24,647:INFO:Defining folds
2023-07-08 22:44:24,647:INFO:Declaring metric variables
2023-07-08 22:44:24,653:INFO:Importing untrained model
2023-07-08 22:44:24,658:INFO:Ada Boost Classifier Imported successfully
2023-07-08 22:44:24,670:INFO:Starting cross validation
2023-07-08 22:44:24,671:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 22:44:28,535:INFO:Calculating mean and std
2023-07-08 22:44:28,537:INFO:Creating metrics dataframe
2023-07-08 22:44:28,977:INFO:Uploading results into container
2023-07-08 22:44:28,978:INFO:Uploading model into container now
2023-07-08 22:44:28,979:INFO:_master_model_container: 9
2023-07-08 22:44:28,979:INFO:_display_container: 2
2023-07-08 22:44:28,979:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2023-07-08 22:44:28,979:INFO:create_model() successfully completed......................................
2023-07-08 22:44:29,043:INFO:SubProcess create_model() end ==================================
2023-07-08 22:44:29,044:INFO:Creating metrics dataframe
2023-07-08 22:44:29,059:INFO:Initializing Gradient Boosting Classifier
2023-07-08 22:44:29,059:INFO:Total runtime is 0.7790636340777078 minutes
2023-07-08 22:44:29,062:INFO:SubProcess create_model() called ==================================
2023-07-08 22:44:29,063:INFO:Initializing create_model()
2023-07-08 22:44:29,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC17BA00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 22:44:29,063:INFO:Checking exceptions
2023-07-08 22:44:29,063:INFO:Importing libraries
2023-07-08 22:44:29,063:INFO:Copying training dataset
2023-07-08 22:44:29,069:INFO:Defining folds
2023-07-08 22:44:29,070:INFO:Declaring metric variables
2023-07-08 22:44:29,073:INFO:Importing untrained model
2023-07-08 22:44:29,077:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 22:44:29,089:INFO:Starting cross validation
2023-07-08 22:44:29,091:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 22:44:33,204:INFO:Calculating mean and std
2023-07-08 22:44:33,206:INFO:Creating metrics dataframe
2023-07-08 22:44:33,724:INFO:Uploading results into container
2023-07-08 22:44:33,725:INFO:Uploading model into container now
2023-07-08 22:44:33,725:INFO:_master_model_container: 10
2023-07-08 22:44:33,726:INFO:_display_container: 2
2023-07-08 22:44:33,727:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 22:44:33,727:INFO:create_model() successfully completed......................................
2023-07-08 22:44:33,802:INFO:SubProcess create_model() end ==================================
2023-07-08 22:44:33,803:INFO:Creating metrics dataframe
2023-07-08 22:44:33,820:INFO:Initializing Linear Discriminant Analysis
2023-07-08 22:44:33,821:INFO:Total runtime is 0.8584192276000976 minutes
2023-07-08 22:44:33,825:INFO:SubProcess create_model() called ==================================
2023-07-08 22:44:33,826:INFO:Initializing create_model()
2023-07-08 22:44:33,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC17BA00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 22:44:33,827:INFO:Checking exceptions
2023-07-08 22:44:33,827:INFO:Importing libraries
2023-07-08 22:44:33,827:INFO:Copying training dataset
2023-07-08 22:44:33,835:INFO:Defining folds
2023-07-08 22:44:33,835:INFO:Declaring metric variables
2023-07-08 22:44:33,841:INFO:Importing untrained model
2023-07-08 22:44:33,848:INFO:Linear Discriminant Analysis Imported successfully
2023-07-08 22:44:33,859:INFO:Starting cross validation
2023-07-08 22:44:33,863:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 22:44:37,950:INFO:Calculating mean and std
2023-07-08 22:44:37,952:INFO:Creating metrics dataframe
2023-07-08 22:44:38,462:INFO:Uploading results into container
2023-07-08 22:44:38,463:INFO:Uploading model into container now
2023-07-08 22:44:38,464:INFO:_master_model_container: 11
2023-07-08 22:44:38,464:INFO:_display_container: 2
2023-07-08 22:44:38,464:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-08 22:44:38,465:INFO:create_model() successfully completed......................................
2023-07-08 22:44:38,538:INFO:SubProcess create_model() end ==================================
2023-07-08 22:44:38,538:INFO:Creating metrics dataframe
2023-07-08 22:44:38,554:INFO:Initializing Extra Trees Classifier
2023-07-08 22:44:38,555:INFO:Total runtime is 0.9373269120852152 minutes
2023-07-08 22:44:38,560:INFO:SubProcess create_model() called ==================================
2023-07-08 22:44:38,561:INFO:Initializing create_model()
2023-07-08 22:44:38,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC17BA00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 22:44:38,561:INFO:Checking exceptions
2023-07-08 22:44:38,561:INFO:Importing libraries
2023-07-08 22:44:38,561:INFO:Copying training dataset
2023-07-08 22:44:38,569:INFO:Defining folds
2023-07-08 22:44:38,570:INFO:Declaring metric variables
2023-07-08 22:44:38,577:INFO:Importing untrained model
2023-07-08 22:44:38,582:INFO:Extra Trees Classifier Imported successfully
2023-07-08 22:44:38,593:INFO:Starting cross validation
2023-07-08 22:44:38,595:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 22:44:43,527:INFO:Calculating mean and std
2023-07-08 22:44:43,528:INFO:Creating metrics dataframe
2023-07-08 22:44:43,966:INFO:Uploading results into container
2023-07-08 22:44:43,967:INFO:Uploading model into container now
2023-07-08 22:44:43,967:INFO:_master_model_container: 12
2023-07-08 22:44:43,968:INFO:_display_container: 2
2023-07-08 22:44:43,968:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-08 22:44:43,968:INFO:create_model() successfully completed......................................
2023-07-08 22:44:44,035:INFO:SubProcess create_model() end ==================================
2023-07-08 22:44:44,035:INFO:Creating metrics dataframe
2023-07-08 22:44:44,047:INFO:Initializing Light Gradient Boosting Machine
2023-07-08 22:44:44,048:INFO:Total runtime is 1.0288749098777772 minutes
2023-07-08 22:44:44,054:INFO:SubProcess create_model() called ==================================
2023-07-08 22:44:44,054:INFO:Initializing create_model()
2023-07-08 22:44:44,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC17BA00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 22:44:44,055:INFO:Checking exceptions
2023-07-08 22:44:44,055:INFO:Importing libraries
2023-07-08 22:44:44,055:INFO:Copying training dataset
2023-07-08 22:44:44,060:INFO:Defining folds
2023-07-08 22:44:44,060:INFO:Declaring metric variables
2023-07-08 22:44:44,064:INFO:Importing untrained model
2023-07-08 22:44:44,070:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-08 22:44:44,084:INFO:Starting cross validation
2023-07-08 22:44:44,086:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 22:44:49,372:INFO:Calculating mean and std
2023-07-08 22:44:49,374:INFO:Creating metrics dataframe
2023-07-08 22:44:49,830:INFO:Uploading results into container
2023-07-08 22:44:49,830:INFO:Uploading model into container now
2023-07-08 22:44:49,831:INFO:_master_model_container: 13
2023-07-08 22:44:49,831:INFO:_display_container: 2
2023-07-08 22:44:49,832:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-08 22:44:49,832:INFO:create_model() successfully completed......................................
2023-07-08 22:44:49,900:INFO:SubProcess create_model() end ==================================
2023-07-08 22:44:49,901:INFO:Creating metrics dataframe
2023-07-08 22:44:49,913:INFO:Initializing Dummy Classifier
2023-07-08 22:44:49,913:INFO:Total runtime is 1.126629889011383 minutes
2023-07-08 22:44:49,918:INFO:SubProcess create_model() called ==================================
2023-07-08 22:44:49,918:INFO:Initializing create_model()
2023-07-08 22:44:49,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC17BA00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 22:44:49,918:INFO:Checking exceptions
2023-07-08 22:44:49,919:INFO:Importing libraries
2023-07-08 22:44:49,919:INFO:Copying training dataset
2023-07-08 22:44:49,924:INFO:Defining folds
2023-07-08 22:44:49,924:INFO:Declaring metric variables
2023-07-08 22:44:49,927:INFO:Importing untrained model
2023-07-08 22:44:49,933:INFO:Dummy Classifier Imported successfully
2023-07-08 22:44:49,944:INFO:Starting cross validation
2023-07-08 22:44:49,946:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 22:44:50,126:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 22:44:50,127:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 22:44:50,145:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 22:44:50,162:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 22:44:50,171:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 22:44:50,176:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 22:44:50,180:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 22:44:50,195:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 22:44:50,885:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 22:44:50,891:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 22:44:53,296:INFO:Calculating mean and std
2023-07-08 22:44:53,298:INFO:Creating metrics dataframe
2023-07-08 22:44:53,792:INFO:Uploading results into container
2023-07-08 22:44:53,793:INFO:Uploading model into container now
2023-07-08 22:44:53,794:INFO:_master_model_container: 14
2023-07-08 22:44:53,794:INFO:_display_container: 2
2023-07-08 22:44:53,794:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-08 22:44:53,794:INFO:create_model() successfully completed......................................
2023-07-08 22:44:53,861:INFO:SubProcess create_model() end ==================================
2023-07-08 22:44:53,862:INFO:Creating metrics dataframe
2023-07-08 22:44:53,890:INFO:Initializing create_model()
2023-07-08 22:44:53,891:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-08 22:44:53,891:INFO:Checking exceptions
2023-07-08 22:44:53,894:INFO:Importing libraries
2023-07-08 22:44:53,894:INFO:Copying training dataset
2023-07-08 22:44:53,899:INFO:Defining folds
2023-07-08 22:44:53,899:INFO:Declaring metric variables
2023-07-08 22:44:53,900:INFO:Importing untrained model
2023-07-08 22:44:53,900:INFO:Declaring custom model
2023-07-08 22:44:53,900:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 22:44:53,901:INFO:Cross validation set to False
2023-07-08 22:44:53,902:INFO:Fitting Model
2023-07-08 22:44:54,287:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 22:44:54,287:INFO:create_model() successfully completed......................................
2023-07-08 22:44:54,401:INFO:_master_model_container: 14
2023-07-08 22:44:54,401:INFO:_display_container: 2
2023-07-08 22:44:54,402:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 22:44:54,402:INFO:compare_models() successfully completed......................................
2023-07-08 22:45:17,767:INFO:Initializing tune_model()
2023-07-08 22:45:17,767:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>)
2023-07-08 22:45:17,767:INFO:Checking exceptions
2023-07-08 22:45:17,813:INFO:Copying training dataset
2023-07-08 22:45:17,818:INFO:Checking base model
2023-07-08 22:45:17,819:INFO:Base model : Gradient Boosting Classifier
2023-07-08 22:45:17,827:INFO:Declaring metric variables
2023-07-08 22:45:17,835:INFO:Defining Hyperparameters
2023-07-08 22:45:17,938:INFO:Tuning with n_jobs=-1
2023-07-08 22:45:17,938:INFO:Initializing RandomizedSearchCV
2023-07-08 22:45:21,595:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-08 22:45:58,598:INFO:best_params: {'actual_estimator__subsample': 0.75, 'actual_estimator__n_estimators': 110, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__min_impurity_decrease': 0.5, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 8, 'actual_estimator__learning_rate': 0.01}
2023-07-08 22:45:58,599:INFO:Hyperparameter search completed
2023-07-08 22:45:58,600:INFO:SubProcess create_model() called ==================================
2023-07-08 22:45:58,600:INFO:Initializing create_model()
2023-07-08 22:45:58,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292B16A0A00>, model_only=True, return_train_score=False, kwargs={'subsample': 0.75, 'n_estimators': 110, 'min_samples_split': 9, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.5, 'max_features': 'log2', 'max_depth': 8, 'learning_rate': 0.01})
2023-07-08 22:45:58,601:INFO:Checking exceptions
2023-07-08 22:45:58,601:INFO:Importing libraries
2023-07-08 22:45:58,601:INFO:Copying training dataset
2023-07-08 22:45:58,609:INFO:Defining folds
2023-07-08 22:45:58,609:INFO:Declaring metric variables
2023-07-08 22:45:58,617:INFO:Importing untrained model
2023-07-08 22:45:58,617:INFO:Declaring custom model
2023-07-08 22:45:58,624:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 22:45:58,635:INFO:Starting cross validation
2023-07-08 22:45:58,636:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 22:46:03,128:INFO:Calculating mean and std
2023-07-08 22:46:03,130:INFO:Creating metrics dataframe
2023-07-08 22:46:03,139:INFO:Finalizing model
2023-07-08 22:46:03,688:INFO:Uploading results into container
2023-07-08 22:46:03,689:INFO:Uploading model into container now
2023-07-08 22:46:03,689:INFO:_master_model_container: 15
2023-07-08 22:46:03,689:INFO:_display_container: 3
2023-07-08 22:46:03,690:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='deviance', max_depth=8,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.5, min_samples_leaf=1,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=110, n_iter_no_change=None,
                           random_state=42, subsample=0.75, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 22:46:03,690:INFO:create_model() successfully completed......................................
2023-07-08 22:46:03,761:INFO:SubProcess create_model() end ==================================
2023-07-08 22:46:03,761:INFO:choose_better activated
2023-07-08 22:46:03,766:INFO:SubProcess create_model() called ==================================
2023-07-08 22:46:03,766:INFO:Initializing create_model()
2023-07-08 22:46:03,767:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-08 22:46:03,767:INFO:Checking exceptions
2023-07-08 22:46:03,769:INFO:Importing libraries
2023-07-08 22:46:03,769:INFO:Copying training dataset
2023-07-08 22:46:03,774:INFO:Defining folds
2023-07-08 22:46:03,774:INFO:Declaring metric variables
2023-07-08 22:46:03,775:INFO:Importing untrained model
2023-07-08 22:46:03,775:INFO:Declaring custom model
2023-07-08 22:46:03,775:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 22:46:03,776:INFO:Starting cross validation
2023-07-08 22:46:03,777:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 22:46:08,119:INFO:Calculating mean and std
2023-07-08 22:46:08,119:INFO:Creating metrics dataframe
2023-07-08 22:46:08,122:INFO:Finalizing model
2023-07-08 22:46:08,658:INFO:Uploading results into container
2023-07-08 22:46:08,659:INFO:Uploading model into container now
2023-07-08 22:46:08,659:INFO:_master_model_container: 16
2023-07-08 22:46:08,659:INFO:_display_container: 4
2023-07-08 22:46:08,660:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 22:46:08,660:INFO:create_model() successfully completed......................................
2023-07-08 22:46:08,723:INFO:SubProcess create_model() end ==================================
2023-07-08 22:46:08,724:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8266
2023-07-08 22:46:08,724:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='deviance', max_depth=8,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.5, min_samples_leaf=1,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=110, n_iter_no_change=None,
                           random_state=42, subsample=0.75, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8225
2023-07-08 22:46:08,725:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-07-08 22:46:08,725:INFO:choose_better completed
2023-07-08 22:46:08,725:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-08 22:46:08,737:INFO:_master_model_container: 16
2023-07-08 22:46:08,737:INFO:_display_container: 3
2023-07-08 22:46:08,738:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 22:46:08,738:INFO:tune_model() successfully completed......................................
2023-07-08 22:47:32,825:INFO:Initializing evaluate_model()
2023-07-08 22:47:32,826:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-08 22:47:32,859:INFO:Initializing plot_model()
2023-07-08 22:47:32,859:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, system=True)
2023-07-08 22:47:32,859:INFO:Checking exceptions
2023-07-08 22:47:32,862:INFO:Preloading libraries
2023-07-08 22:47:32,875:INFO:Copying training dataset
2023-07-08 22:47:32,875:INFO:Plot type: pipeline
2023-07-08 22:47:33,004:INFO:Visual Rendered Successfully
2023-07-08 22:47:33,080:INFO:plot_model() successfully completed......................................
2023-07-08 22:47:35,550:INFO:Initializing plot_model()
2023-07-08 22:47:35,551:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, system=True)
2023-07-08 22:47:35,551:INFO:Checking exceptions
2023-07-08 22:47:35,556:INFO:Preloading libraries
2023-07-08 22:47:35,565:INFO:Copying training dataset
2023-07-08 22:47:35,566:INFO:Plot type: feature
2023-07-08 22:47:35,566:WARNING:No coef_ found. Trying feature_importances_
2023-07-08 22:47:35,746:INFO:Visual Rendered Successfully
2023-07-08 22:47:35,826:INFO:plot_model() successfully completed......................................
2023-07-08 22:48:22,972:INFO:Initializing predict_model()
2023-07-08 22:48:22,972:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000292BCBC2280>)
2023-07-08 22:48:22,972:INFO:Checking exceptions
2023-07-08 22:48:22,972:INFO:Preloading libraries
2023-07-08 22:53:42,516:INFO:Initializing predict_model()
2023-07-08 22:53:42,516:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BB02AB20>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000292BC30D8B0>)
2023-07-08 22:53:42,516:INFO:Checking exceptions
2023-07-08 22:53:42,516:INFO:Preloading libraries
2023-07-08 22:59:54,792:INFO:PyCaret ClassificationExperiment
2023-07-08 22:59:54,792:INFO:Logging name: clf-default-name
2023-07-08 22:59:54,793:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-08 22:59:54,793:INFO:version 3.0.4
2023-07-08 22:59:54,793:INFO:Initializing setup()
2023-07-08 22:59:54,793:INFO:self.USI: dea8
2023-07-08 22:59:54,793:INFO:self._variable_keys: {'n_jobs_param', 'data', 'y_test', '_ml_usecase', 'memory', 'fold_groups_param', 'fix_imbalance', 'y', 'X_train', 'target_param', 'seed', 'y_train', 'exp_id', '_available_plots', 'html_param', 'X_test', 'fold_shuffle_param', 'logging_param', 'exp_name_log', 'gpu_param', 'USI', 'gpu_n_jobs_param', 'is_multiclass', 'fold_generator', 'idx', 'X', 'pipeline', 'log_plots_param'}
2023-07-08 22:59:54,793:INFO:Checking environment
2023-07-08 22:59:54,793:INFO:python_version: 3.9.13
2023-07-08 22:59:54,793:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-07-08 22:59:54,793:INFO:machine: AMD64
2023-07-08 22:59:54,793:INFO:platform: Windows-10-10.0.19045-SP0
2023-07-08 22:59:54,793:INFO:Memory: svmem(total=17125732352, available=10517192704, percent=38.6, used=6608539648, free=10517192704)
2023-07-08 22:59:54,793:INFO:Physical Core: 4
2023-07-08 22:59:54,793:INFO:Logical Core: 8
2023-07-08 22:59:54,793:INFO:Checking libraries
2023-07-08 22:59:54,794:INFO:System:
2023-07-08 22:59:54,794:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-07-08 22:59:54,794:INFO:executable: C:\Users\hamim\anaconda3\python.exe
2023-07-08 22:59:54,794:INFO:   machine: Windows-10-10.0.19045-SP0
2023-07-08 22:59:54,794:INFO:PyCaret required dependencies:
2023-07-08 22:59:54,794:INFO:                 pip: 22.2.2
2023-07-08 22:59:54,794:INFO:          setuptools: 63.4.1
2023-07-08 22:59:54,794:INFO:             pycaret: 3.0.4
2023-07-08 22:59:54,794:INFO:             IPython: 7.31.1
2023-07-08 22:59:54,794:INFO:          ipywidgets: 7.6.5
2023-07-08 22:59:54,794:INFO:                tqdm: 4.64.1
2023-07-08 22:59:54,794:INFO:               numpy: 1.21.5
2023-07-08 22:59:54,794:INFO:              pandas: 1.4.4
2023-07-08 22:59:54,794:INFO:              jinja2: 2.11.3
2023-07-08 22:59:54,794:INFO:               scipy: 1.9.1
2023-07-08 22:59:54,794:INFO:              joblib: 1.2.0
2023-07-08 22:59:54,794:INFO:             sklearn: 1.0.2
2023-07-08 22:59:54,794:INFO:                pyod: 1.1.0
2023-07-08 22:59:54,794:INFO:            imblearn: 0.10.1
2023-07-08 22:59:54,795:INFO:   category_encoders: 2.6.1
2023-07-08 22:59:54,795:INFO:            lightgbm: 3.3.5
2023-07-08 22:59:54,795:INFO:               numba: 0.55.1
2023-07-08 22:59:54,795:INFO:            requests: 2.28.1
2023-07-08 22:59:54,795:INFO:          matplotlib: 3.5.2
2023-07-08 22:59:54,795:INFO:          scikitplot: 0.3.7
2023-07-08 22:59:54,795:INFO:         yellowbrick: 1.5
2023-07-08 22:59:54,795:INFO:              plotly: 5.9.0
2023-07-08 22:59:54,795:INFO:    plotly-resampler: Not installed
2023-07-08 22:59:54,795:INFO:             kaleido: 0.2.1
2023-07-08 22:59:54,795:INFO:           schemdraw: 0.15
2023-07-08 22:59:54,795:INFO:         statsmodels: 0.13.2
2023-07-08 22:59:54,795:INFO:              sktime: 0.20.0
2023-07-08 22:59:54,795:INFO:               tbats: 1.1.3
2023-07-08 22:59:54,795:INFO:            pmdarima: 2.0.3
2023-07-08 22:59:54,795:INFO:              psutil: 5.9.0
2023-07-08 22:59:54,795:INFO:          markupsafe: 2.0.1
2023-07-08 22:59:54,795:INFO:             pickle5: Not installed
2023-07-08 22:59:54,795:INFO:         cloudpickle: 2.0.0
2023-07-08 22:59:54,795:INFO:         deprecation: 2.1.0
2023-07-08 22:59:54,795:INFO:              xxhash: 3.2.0
2023-07-08 22:59:54,795:INFO:           wurlitzer: Not installed
2023-07-08 22:59:54,796:INFO:PyCaret optional dependencies:
2023-07-08 22:59:54,796:INFO:                shap: Not installed
2023-07-08 22:59:54,796:INFO:           interpret: Not installed
2023-07-08 22:59:54,796:INFO:                umap: Not installed
2023-07-08 22:59:54,796:INFO:    pandas_profiling: Not installed
2023-07-08 22:59:54,796:INFO:  explainerdashboard: Not installed
2023-07-08 22:59:54,796:INFO:             autoviz: Not installed
2023-07-08 22:59:54,796:INFO:           fairlearn: Not installed
2023-07-08 22:59:54,796:INFO:          deepchecks: Not installed
2023-07-08 22:59:54,796:INFO:             xgboost: Not installed
2023-07-08 22:59:54,796:INFO:            catboost: Not installed
2023-07-08 22:59:54,796:INFO:              kmodes: Not installed
2023-07-08 22:59:54,796:INFO:             mlxtend: Not installed
2023-07-08 22:59:54,796:INFO:       statsforecast: Not installed
2023-07-08 22:59:54,796:INFO:        tune_sklearn: Not installed
2023-07-08 22:59:54,796:INFO:                 ray: Not installed
2023-07-08 22:59:54,796:INFO:            hyperopt: Not installed
2023-07-08 22:59:54,796:INFO:              optuna: Not installed
2023-07-08 22:59:54,796:INFO:               skopt: Not installed
2023-07-08 22:59:54,796:INFO:              mlflow: Not installed
2023-07-08 22:59:54,796:INFO:              gradio: Not installed
2023-07-08 22:59:54,797:INFO:             fastapi: Not installed
2023-07-08 22:59:54,797:INFO:             uvicorn: Not installed
2023-07-08 22:59:54,797:INFO:              m2cgen: Not installed
2023-07-08 22:59:54,797:INFO:           evidently: Not installed
2023-07-08 22:59:54,797:INFO:               fugue: Not installed
2023-07-08 22:59:54,797:INFO:           streamlit: Not installed
2023-07-08 22:59:54,797:INFO:             prophet: Not installed
2023-07-08 22:59:54,797:INFO:None
2023-07-08 22:59:54,797:INFO:Set up data.
2023-07-08 22:59:54,805:INFO:Set up train/test split.
2023-07-08 22:59:54,810:INFO:Set up index.
2023-07-08 22:59:54,810:INFO:Set up folding strategy.
2023-07-08 22:59:54,810:INFO:Assigning column types.
2023-07-08 22:59:54,814:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-08 22:59:54,862:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-08 22:59:54,863:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 22:59:54,893:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:59:54,894:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:59:54,937:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-08 22:59:54,938:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 22:59:54,965:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:59:54,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:59:54,966:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-08 22:59:55,010:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 22:59:55,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:59:55,036:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:59:55,089:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 22:59:55,116:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:59:55,116:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:59:55,116:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-08 22:59:55,188:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:59:55,188:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:59:55,262:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:59:55,263:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:59:55,264:INFO:Preparing preprocessing pipeline...
2023-07-08 22:59:55,265:INFO:Set up simple imputation.
2023-07-08 22:59:55,265:INFO:Set up imbalanced handling.
2023-07-08 22:59:55,266:INFO:Set up column name cleaning.
2023-07-08 22:59:55,324:INFO:Finished creating preprocessing pipeline.
2023-07-08 22:59:55,331:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-08 22:59:55,331:INFO:Creating final display dataframe.
2023-07-08 22:59:55,507:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Target
2                   Target type            Binary
3           Original data shape        (2802, 23)
4        Transformed data shape        (3825, 23)
5   Transformed train set shape        (2984, 23)
6    Transformed test set shape         (841, 23)
7              Numeric features                22
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              dea8
2023-07-08 22:59:55,642:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:59:55,642:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:59:55,725:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:59:55,725:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 22:59:55,726:INFO:setup() successfully completed in 1.34s...............
2023-07-08 23:00:05,161:INFO:PyCaret ClassificationExperiment
2023-07-08 23:00:05,161:INFO:Logging name: clf-default-name
2023-07-08 23:00:05,161:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-08 23:00:05,161:INFO:version 3.0.4
2023-07-08 23:00:05,161:INFO:Initializing setup()
2023-07-08 23:00:05,161:INFO:self.USI: 6ae9
2023-07-08 23:00:05,161:INFO:self._variable_keys: {'n_jobs_param', 'data', 'y_test', '_ml_usecase', 'memory', 'fold_groups_param', 'fix_imbalance', 'y', 'X_train', 'target_param', 'seed', 'y_train', 'exp_id', '_available_plots', 'html_param', 'X_test', 'fold_shuffle_param', 'logging_param', 'exp_name_log', 'gpu_param', 'USI', 'gpu_n_jobs_param', 'is_multiclass', 'fold_generator', 'idx', 'X', 'pipeline', 'log_plots_param'}
2023-07-08 23:00:05,161:INFO:Checking environment
2023-07-08 23:00:05,161:INFO:python_version: 3.9.13
2023-07-08 23:00:05,161:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-07-08 23:00:05,161:INFO:machine: AMD64
2023-07-08 23:00:05,161:INFO:platform: Windows-10-10.0.19045-SP0
2023-07-08 23:00:05,161:INFO:Memory: svmem(total=17125732352, available=10518245376, percent=38.6, used=6607486976, free=10518245376)
2023-07-08 23:00:05,161:INFO:Physical Core: 4
2023-07-08 23:00:05,161:INFO:Logical Core: 8
2023-07-08 23:00:05,161:INFO:Checking libraries
2023-07-08 23:00:05,161:INFO:System:
2023-07-08 23:00:05,162:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-07-08 23:00:05,162:INFO:executable: C:\Users\hamim\anaconda3\python.exe
2023-07-08 23:00:05,162:INFO:   machine: Windows-10-10.0.19045-SP0
2023-07-08 23:00:05,162:INFO:PyCaret required dependencies:
2023-07-08 23:00:05,162:INFO:                 pip: 22.2.2
2023-07-08 23:00:05,162:INFO:          setuptools: 63.4.1
2023-07-08 23:00:05,162:INFO:             pycaret: 3.0.4
2023-07-08 23:00:05,162:INFO:             IPython: 7.31.1
2023-07-08 23:00:05,162:INFO:          ipywidgets: 7.6.5
2023-07-08 23:00:05,162:INFO:                tqdm: 4.64.1
2023-07-08 23:00:05,162:INFO:               numpy: 1.21.5
2023-07-08 23:00:05,162:INFO:              pandas: 1.4.4
2023-07-08 23:00:05,162:INFO:              jinja2: 2.11.3
2023-07-08 23:00:05,162:INFO:               scipy: 1.9.1
2023-07-08 23:00:05,162:INFO:              joblib: 1.2.0
2023-07-08 23:00:05,162:INFO:             sklearn: 1.0.2
2023-07-08 23:00:05,162:INFO:                pyod: 1.1.0
2023-07-08 23:00:05,162:INFO:            imblearn: 0.10.1
2023-07-08 23:00:05,162:INFO:   category_encoders: 2.6.1
2023-07-08 23:00:05,162:INFO:            lightgbm: 3.3.5
2023-07-08 23:00:05,162:INFO:               numba: 0.55.1
2023-07-08 23:00:05,162:INFO:            requests: 2.28.1
2023-07-08 23:00:05,163:INFO:          matplotlib: 3.5.2
2023-07-08 23:00:05,163:INFO:          scikitplot: 0.3.7
2023-07-08 23:00:05,163:INFO:         yellowbrick: 1.5
2023-07-08 23:00:05,163:INFO:              plotly: 5.9.0
2023-07-08 23:00:05,163:INFO:    plotly-resampler: Not installed
2023-07-08 23:00:05,163:INFO:             kaleido: 0.2.1
2023-07-08 23:00:05,163:INFO:           schemdraw: 0.15
2023-07-08 23:00:05,163:INFO:         statsmodels: 0.13.2
2023-07-08 23:00:05,163:INFO:              sktime: 0.20.0
2023-07-08 23:00:05,163:INFO:               tbats: 1.1.3
2023-07-08 23:00:05,163:INFO:            pmdarima: 2.0.3
2023-07-08 23:00:05,163:INFO:              psutil: 5.9.0
2023-07-08 23:00:05,163:INFO:          markupsafe: 2.0.1
2023-07-08 23:00:05,163:INFO:             pickle5: Not installed
2023-07-08 23:00:05,163:INFO:         cloudpickle: 2.0.0
2023-07-08 23:00:05,163:INFO:         deprecation: 2.1.0
2023-07-08 23:00:05,163:INFO:              xxhash: 3.2.0
2023-07-08 23:00:05,163:INFO:           wurlitzer: Not installed
2023-07-08 23:00:05,163:INFO:PyCaret optional dependencies:
2023-07-08 23:00:05,163:INFO:                shap: Not installed
2023-07-08 23:00:05,163:INFO:           interpret: Not installed
2023-07-08 23:00:05,163:INFO:                umap: Not installed
2023-07-08 23:00:05,163:INFO:    pandas_profiling: Not installed
2023-07-08 23:00:05,164:INFO:  explainerdashboard: Not installed
2023-07-08 23:00:05,164:INFO:             autoviz: Not installed
2023-07-08 23:00:05,164:INFO:           fairlearn: Not installed
2023-07-08 23:00:05,164:INFO:          deepchecks: Not installed
2023-07-08 23:00:05,164:INFO:             xgboost: Not installed
2023-07-08 23:00:05,164:INFO:            catboost: Not installed
2023-07-08 23:00:05,164:INFO:              kmodes: Not installed
2023-07-08 23:00:05,164:INFO:             mlxtend: Not installed
2023-07-08 23:00:05,164:INFO:       statsforecast: Not installed
2023-07-08 23:00:05,164:INFO:        tune_sklearn: Not installed
2023-07-08 23:00:05,164:INFO:                 ray: Not installed
2023-07-08 23:00:05,164:INFO:            hyperopt: Not installed
2023-07-08 23:00:05,164:INFO:              optuna: Not installed
2023-07-08 23:00:05,164:INFO:               skopt: Not installed
2023-07-08 23:00:05,164:INFO:              mlflow: Not installed
2023-07-08 23:00:05,164:INFO:              gradio: Not installed
2023-07-08 23:00:05,164:INFO:             fastapi: Not installed
2023-07-08 23:00:05,164:INFO:             uvicorn: Not installed
2023-07-08 23:00:05,164:INFO:              m2cgen: Not installed
2023-07-08 23:00:05,165:INFO:           evidently: Not installed
2023-07-08 23:00:05,165:INFO:               fugue: Not installed
2023-07-08 23:00:05,165:INFO:           streamlit: Not installed
2023-07-08 23:00:05,165:INFO:             prophet: Not installed
2023-07-08 23:00:05,165:INFO:None
2023-07-08 23:00:05,165:INFO:Set up data.
2023-07-08 23:00:05,172:INFO:Set up train/test split.
2023-07-08 23:00:05,176:INFO:Set up index.
2023-07-08 23:00:05,176:INFO:Set up folding strategy.
2023-07-08 23:00:05,176:INFO:Assigning column types.
2023-07-08 23:00:05,179:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-08 23:00:05,222:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-08 23:00:05,223:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 23:00:05,249:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:00:05,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:00:05,294:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-08 23:00:05,295:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 23:00:05,322:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:00:05,322:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:00:05,322:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-08 23:00:05,367:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 23:00:05,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:00:05,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:00:05,444:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 23:00:05,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:00:05,472:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:00:05,472:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-08 23:00:05,557:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:00:05,557:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:00:05,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:00:05,642:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:00:05,643:INFO:Preparing preprocessing pipeline...
2023-07-08 23:00:05,644:INFO:Set up simple imputation.
2023-07-08 23:00:05,644:INFO:Set up imbalanced handling.
2023-07-08 23:00:05,645:INFO:Set up column name cleaning.
2023-07-08 23:00:05,697:INFO:Finished creating preprocessing pipeline.
2023-07-08 23:00:05,709:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-08 23:00:05,709:INFO:Creating final display dataframe.
2023-07-08 23:00:05,891:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Target
2                   Target type            Binary
3           Original data shape        (2802, 23)
4        Transformed data shape        (3825, 23)
5   Transformed train set shape        (2984, 23)
6    Transformed test set shape         (841, 23)
7              Numeric features                22
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              6ae9
2023-07-08 23:00:06,031:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:00:06,031:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:00:06,110:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:00:06,111:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:00:06,111:INFO:setup() successfully completed in 1.29s...............
2023-07-08 23:00:07,044:INFO:Initializing compare_models()
2023-07-08 23:00:07,045:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-08 23:00:07,045:INFO:Checking exceptions
2023-07-08 23:00:07,050:INFO:Preparing display monitor
2023-07-08 23:00:07,106:INFO:Initializing Logistic Regression
2023-07-08 23:00:07,107:INFO:Total runtime is 1.6621748606363933e-05 minutes
2023-07-08 23:00:07,112:INFO:SubProcess create_model() called ==================================
2023-07-08 23:00:07,113:INFO:Initializing create_model()
2023-07-08 23:00:07,113:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A9D00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:00:07,113:INFO:Checking exceptions
2023-07-08 23:00:07,114:INFO:Importing libraries
2023-07-08 23:00:07,114:INFO:Copying training dataset
2023-07-08 23:00:07,120:INFO:Defining folds
2023-07-08 23:00:07,120:INFO:Declaring metric variables
2023-07-08 23:00:07,127:INFO:Importing untrained model
2023-07-08 23:00:07,133:INFO:Logistic Regression Imported successfully
2023-07-08 23:00:07,144:INFO:Starting cross validation
2023-07-08 23:00:07,146:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:00:18,500:INFO:Calculating mean and std
2023-07-08 23:00:18,502:INFO:Creating metrics dataframe
2023-07-08 23:00:18,994:INFO:Uploading results into container
2023-07-08 23:00:18,995:INFO:Uploading model into container now
2023-07-08 23:00:18,996:INFO:_master_model_container: 1
2023-07-08 23:00:18,996:INFO:_display_container: 2
2023-07-08 23:00:18,996:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-08 23:00:18,996:INFO:create_model() successfully completed......................................
2023-07-08 23:00:19,070:INFO:SubProcess create_model() end ==================================
2023-07-08 23:00:19,070:INFO:Creating metrics dataframe
2023-07-08 23:00:19,082:INFO:Initializing K Neighbors Classifier
2023-07-08 23:00:19,082:INFO:Total runtime is 0.19959853887557982 minutes
2023-07-08 23:00:19,086:INFO:SubProcess create_model() called ==================================
2023-07-08 23:00:19,086:INFO:Initializing create_model()
2023-07-08 23:00:19,087:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A9D00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:00:19,087:INFO:Checking exceptions
2023-07-08 23:00:19,087:INFO:Importing libraries
2023-07-08 23:00:19,087:INFO:Copying training dataset
2023-07-08 23:00:19,091:INFO:Defining folds
2023-07-08 23:00:19,091:INFO:Declaring metric variables
2023-07-08 23:00:19,095:INFO:Importing untrained model
2023-07-08 23:00:19,099:INFO:K Neighbors Classifier Imported successfully
2023-07-08 23:00:19,110:INFO:Starting cross validation
2023-07-08 23:00:19,112:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:00:19,283:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:00:19,300:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:00:19,307:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:00:19,316:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:00:19,327:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:00:19,340:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:00:19,348:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:00:19,372:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:00:20,206:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:00:20,227:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:00:23,083:INFO:Calculating mean and std
2023-07-08 23:00:23,084:INFO:Creating metrics dataframe
2023-07-08 23:00:23,631:INFO:Uploading results into container
2023-07-08 23:00:23,631:INFO:Uploading model into container now
2023-07-08 23:00:23,632:INFO:_master_model_container: 2
2023-07-08 23:00:23,633:INFO:_display_container: 2
2023-07-08 23:00:23,633:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-08 23:00:23,633:INFO:create_model() successfully completed......................................
2023-07-08 23:00:23,710:INFO:SubProcess create_model() end ==================================
2023-07-08 23:00:23,710:INFO:Creating metrics dataframe
2023-07-08 23:00:23,719:INFO:Initializing Naive Bayes
2023-07-08 23:00:23,719:INFO:Total runtime is 0.2768893798192342 minutes
2023-07-08 23:00:23,723:INFO:SubProcess create_model() called ==================================
2023-07-08 23:00:23,723:INFO:Initializing create_model()
2023-07-08 23:00:23,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A9D00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:00:23,724:INFO:Checking exceptions
2023-07-08 23:00:23,724:INFO:Importing libraries
2023-07-08 23:00:23,724:INFO:Copying training dataset
2023-07-08 23:00:23,729:INFO:Defining folds
2023-07-08 23:00:23,729:INFO:Declaring metric variables
2023-07-08 23:00:23,733:INFO:Importing untrained model
2023-07-08 23:00:23,738:INFO:Naive Bayes Imported successfully
2023-07-08 23:00:23,751:INFO:Starting cross validation
2023-07-08 23:00:23,754:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:00:23,986:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:00:27,563:INFO:Calculating mean and std
2023-07-08 23:00:27,563:INFO:Creating metrics dataframe
2023-07-08 23:00:28,072:INFO:Uploading results into container
2023-07-08 23:00:28,072:INFO:Uploading model into container now
2023-07-08 23:00:28,073:INFO:_master_model_container: 3
2023-07-08 23:00:28,073:INFO:_display_container: 2
2023-07-08 23:00:28,073:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-08 23:00:28,073:INFO:create_model() successfully completed......................................
2023-07-08 23:00:28,138:INFO:SubProcess create_model() end ==================================
2023-07-08 23:00:28,138:INFO:Creating metrics dataframe
2023-07-08 23:00:28,150:INFO:Initializing Decision Tree Classifier
2023-07-08 23:00:28,150:INFO:Total runtime is 0.35073107878367105 minutes
2023-07-08 23:00:28,155:INFO:SubProcess create_model() called ==================================
2023-07-08 23:00:28,155:INFO:Initializing create_model()
2023-07-08 23:00:28,156:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A9D00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:00:28,156:INFO:Checking exceptions
2023-07-08 23:00:28,156:INFO:Importing libraries
2023-07-08 23:00:28,156:INFO:Copying training dataset
2023-07-08 23:00:28,162:INFO:Defining folds
2023-07-08 23:00:28,162:INFO:Declaring metric variables
2023-07-08 23:00:28,166:INFO:Importing untrained model
2023-07-08 23:00:28,170:INFO:Decision Tree Classifier Imported successfully
2023-07-08 23:00:28,179:INFO:Starting cross validation
2023-07-08 23:00:28,182:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:00:31,831:INFO:Calculating mean and std
2023-07-08 23:00:31,833:INFO:Creating metrics dataframe
2023-07-08 23:00:32,333:INFO:Uploading results into container
2023-07-08 23:00:32,334:INFO:Uploading model into container now
2023-07-08 23:00:32,334:INFO:_master_model_container: 4
2023-07-08 23:00:32,334:INFO:_display_container: 2
2023-07-08 23:00:32,335:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-08 23:00:32,335:INFO:create_model() successfully completed......................................
2023-07-08 23:00:32,402:INFO:SubProcess create_model() end ==================================
2023-07-08 23:00:32,402:INFO:Creating metrics dataframe
2023-07-08 23:00:32,412:INFO:Initializing SVM - Linear Kernel
2023-07-08 23:00:32,412:INFO:Total runtime is 0.4217617313067118 minutes
2023-07-08 23:00:32,418:INFO:SubProcess create_model() called ==================================
2023-07-08 23:00:32,419:INFO:Initializing create_model()
2023-07-08 23:00:32,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A9D00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:00:32,419:INFO:Checking exceptions
2023-07-08 23:00:32,419:INFO:Importing libraries
2023-07-08 23:00:32,419:INFO:Copying training dataset
2023-07-08 23:00:32,424:INFO:Defining folds
2023-07-08 23:00:32,424:INFO:Declaring metric variables
2023-07-08 23:00:32,428:INFO:Importing untrained model
2023-07-08 23:00:32,431:INFO:SVM - Linear Kernel Imported successfully
2023-07-08 23:00:32,441:INFO:Starting cross validation
2023-07-08 23:00:32,443:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:00:32,607:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:00:32,608:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:00:32,637:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:00:32,638:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:00:32,648:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:00:32,672:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:00:32,683:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:00:32,689:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:00:33,441:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:00:33,453:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:00:36,087:INFO:Calculating mean and std
2023-07-08 23:00:36,089:INFO:Creating metrics dataframe
2023-07-08 23:00:36,592:INFO:Uploading results into container
2023-07-08 23:00:36,593:INFO:Uploading model into container now
2023-07-08 23:00:36,593:INFO:_master_model_container: 5
2023-07-08 23:00:36,593:INFO:_display_container: 2
2023-07-08 23:00:36,594:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-08 23:00:36,594:INFO:create_model() successfully completed......................................
2023-07-08 23:00:36,662:INFO:SubProcess create_model() end ==================================
2023-07-08 23:00:36,663:INFO:Creating metrics dataframe
2023-07-08 23:00:36,676:INFO:Initializing Ridge Classifier
2023-07-08 23:00:36,676:INFO:Total runtime is 0.4928311387697855 minutes
2023-07-08 23:00:36,680:INFO:SubProcess create_model() called ==================================
2023-07-08 23:00:36,680:INFO:Initializing create_model()
2023-07-08 23:00:36,680:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A9D00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:00:36,680:INFO:Checking exceptions
2023-07-08 23:00:36,680:INFO:Importing libraries
2023-07-08 23:00:36,680:INFO:Copying training dataset
2023-07-08 23:00:36,685:INFO:Defining folds
2023-07-08 23:00:36,685:INFO:Declaring metric variables
2023-07-08 23:00:36,688:INFO:Importing untrained model
2023-07-08 23:00:36,692:INFO:Ridge Classifier Imported successfully
2023-07-08 23:00:36,700:INFO:Starting cross validation
2023-07-08 23:00:36,701:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:00:36,863:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:00:36,864:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:00:36,869:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:00:36,879:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:00:36,887:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:00:36,891:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:00:36,901:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:00:36,924:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:00:37,703:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:00:37,727:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:00:40,743:INFO:Calculating mean and std
2023-07-08 23:00:40,745:INFO:Creating metrics dataframe
2023-07-08 23:00:41,275:INFO:Uploading results into container
2023-07-08 23:00:41,276:INFO:Uploading model into container now
2023-07-08 23:00:41,276:INFO:_master_model_container: 6
2023-07-08 23:00:41,276:INFO:_display_container: 2
2023-07-08 23:00:41,276:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=42, solver='auto', tol=0.001)
2023-07-08 23:00:41,277:INFO:create_model() successfully completed......................................
2023-07-08 23:00:41,340:INFO:SubProcess create_model() end ==================================
2023-07-08 23:00:41,340:INFO:Creating metrics dataframe
2023-07-08 23:00:41,354:INFO:Initializing Random Forest Classifier
2023-07-08 23:00:41,354:INFO:Total runtime is 0.5708078861236572 minutes
2023-07-08 23:00:41,358:INFO:SubProcess create_model() called ==================================
2023-07-08 23:00:41,359:INFO:Initializing create_model()
2023-07-08 23:00:41,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A9D00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:00:41,360:INFO:Checking exceptions
2023-07-08 23:00:41,360:INFO:Importing libraries
2023-07-08 23:00:41,360:INFO:Copying training dataset
2023-07-08 23:00:41,365:INFO:Defining folds
2023-07-08 23:00:41,366:INFO:Declaring metric variables
2023-07-08 23:00:41,369:INFO:Importing untrained model
2023-07-08 23:00:41,373:INFO:Random Forest Classifier Imported successfully
2023-07-08 23:00:41,381:INFO:Starting cross validation
2023-07-08 23:00:41,383:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:00:46,168:INFO:Calculating mean and std
2023-07-08 23:00:46,170:INFO:Creating metrics dataframe
2023-07-08 23:00:46,669:INFO:Uploading results into container
2023-07-08 23:00:46,670:INFO:Uploading model into container now
2023-07-08 23:00:46,671:INFO:_master_model_container: 7
2023-07-08 23:00:46,671:INFO:_display_container: 2
2023-07-08 23:00:46,671:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-08 23:00:46,672:INFO:create_model() successfully completed......................................
2023-07-08 23:00:46,741:INFO:SubProcess create_model() end ==================================
2023-07-08 23:00:46,741:INFO:Creating metrics dataframe
2023-07-08 23:00:46,753:INFO:Initializing Quadratic Discriminant Analysis
2023-07-08 23:00:46,753:INFO:Total runtime is 0.6607925375302632 minutes
2023-07-08 23:00:46,756:INFO:SubProcess create_model() called ==================================
2023-07-08 23:00:46,757:INFO:Initializing create_model()
2023-07-08 23:00:46,757:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A9D00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:00:46,757:INFO:Checking exceptions
2023-07-08 23:00:46,757:INFO:Importing libraries
2023-07-08 23:00:46,757:INFO:Copying training dataset
2023-07-08 23:00:46,763:INFO:Defining folds
2023-07-08 23:00:46,763:INFO:Declaring metric variables
2023-07-08 23:00:46,766:INFO:Importing untrained model
2023-07-08 23:00:46,771:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-08 23:00:46,781:INFO:Starting cross validation
2023-07-08 23:00:46,783:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:00:46,927:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:00:46,927:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:00:46,932:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:00:46,941:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:00:46,946:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:00:46,951:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:00:46,958:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:00:46,961:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,961:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,962:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:46,962:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,963:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,963:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:46,966:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,966:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,966:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:46,967:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:00:46,975:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,975:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,976:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:46,978:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,978:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,978:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:46,984:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,984:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,985:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:46,990:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,990:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,990:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:46,994:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,994:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,995:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,995:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,995:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:46,995:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:46,998:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,999:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:46,999:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:47,000:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:47,001:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:47,001:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:00:47,001:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:00:47,001:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:47,003:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:00:47,007:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:00:47,007:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:00:47,008:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:00:47,008:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:47,009:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:47,009:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:47,009:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:47,009:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:47,010:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:47,017:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:00:47,017:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:00:47,024:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:47,024:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:00:47,025:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:47,026:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:00:47,028:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:47,029:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:47,029:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:00:47,029:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:47,035:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:00:47,036:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:47,036:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:47,036:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:47,041:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:00:47,042:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:00:47,047:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:00:47,048:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:00:47,791:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:00:47,799:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:00:47,811:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:47,811:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:47,811:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:47,819:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:47,819:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:47,819:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:47,830:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:47,830:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:47,831:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:47,832:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:00:47,836:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:00:47,844:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:47,844:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:00:47,844:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:00:47,845:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:00:47,849:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:00:50,564:INFO:Calculating mean and std
2023-07-08 23:00:50,566:INFO:Creating metrics dataframe
2023-07-08 23:00:51,077:INFO:Uploading results into container
2023-07-08 23:00:51,078:INFO:Uploading model into container now
2023-07-08 23:00:51,078:INFO:_master_model_container: 8
2023-07-08 23:00:51,078:INFO:_display_container: 2
2023-07-08 23:00:51,079:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-08 23:00:51,079:INFO:create_model() successfully completed......................................
2023-07-08 23:00:51,147:INFO:SubProcess create_model() end ==================================
2023-07-08 23:00:51,147:INFO:Creating metrics dataframe
2023-07-08 23:00:51,158:INFO:Initializing Ada Boost Classifier
2023-07-08 23:00:51,158:INFO:Total runtime is 0.7342006842295329 minutes
2023-07-08 23:00:51,163:INFO:SubProcess create_model() called ==================================
2023-07-08 23:00:51,163:INFO:Initializing create_model()
2023-07-08 23:00:51,163:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A9D00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:00:51,163:INFO:Checking exceptions
2023-07-08 23:00:51,164:INFO:Importing libraries
2023-07-08 23:00:51,164:INFO:Copying training dataset
2023-07-08 23:00:51,169:INFO:Defining folds
2023-07-08 23:00:51,169:INFO:Declaring metric variables
2023-07-08 23:00:51,172:INFO:Importing untrained model
2023-07-08 23:00:51,178:INFO:Ada Boost Classifier Imported successfully
2023-07-08 23:00:51,189:INFO:Starting cross validation
2023-07-08 23:00:51,191:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:00:55,730:INFO:Calculating mean and std
2023-07-08 23:00:55,732:INFO:Creating metrics dataframe
2023-07-08 23:00:56,313:INFO:Uploading results into container
2023-07-08 23:00:56,314:INFO:Uploading model into container now
2023-07-08 23:00:56,314:INFO:_master_model_container: 9
2023-07-08 23:00:56,314:INFO:_display_container: 2
2023-07-08 23:00:56,315:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2023-07-08 23:00:56,315:INFO:create_model() successfully completed......................................
2023-07-08 23:00:56,392:INFO:SubProcess create_model() end ==================================
2023-07-08 23:00:56,392:INFO:Creating metrics dataframe
2023-07-08 23:00:56,406:INFO:Initializing Gradient Boosting Classifier
2023-07-08 23:00:56,406:INFO:Total runtime is 0.8216702938079834 minutes
2023-07-08 23:00:56,411:INFO:SubProcess create_model() called ==================================
2023-07-08 23:00:56,412:INFO:Initializing create_model()
2023-07-08 23:00:56,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A9D00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:00:56,412:INFO:Checking exceptions
2023-07-08 23:00:56,412:INFO:Importing libraries
2023-07-08 23:00:56,412:INFO:Copying training dataset
2023-07-08 23:00:56,420:INFO:Defining folds
2023-07-08 23:00:56,421:INFO:Declaring metric variables
2023-07-08 23:00:56,426:INFO:Importing untrained model
2023-07-08 23:00:56,434:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 23:00:56,445:INFO:Starting cross validation
2023-07-08 23:00:56,448:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:01:01,091:INFO:Calculating mean and std
2023-07-08 23:01:01,092:INFO:Creating metrics dataframe
2023-07-08 23:01:01,612:INFO:Uploading results into container
2023-07-08 23:01:01,613:INFO:Uploading model into container now
2023-07-08 23:01:01,613:INFO:_master_model_container: 10
2023-07-08 23:01:01,613:INFO:_display_container: 2
2023-07-08 23:01:01,614:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 23:01:01,614:INFO:create_model() successfully completed......................................
2023-07-08 23:01:01,679:INFO:SubProcess create_model() end ==================================
2023-07-08 23:01:01,679:INFO:Creating metrics dataframe
2023-07-08 23:01:01,694:INFO:Initializing Linear Discriminant Analysis
2023-07-08 23:01:01,694:INFO:Total runtime is 0.9098035415013631 minutes
2023-07-08 23:01:01,699:INFO:SubProcess create_model() called ==================================
2023-07-08 23:01:01,699:INFO:Initializing create_model()
2023-07-08 23:01:01,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A9D00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:01:01,699:INFO:Checking exceptions
2023-07-08 23:01:01,700:INFO:Importing libraries
2023-07-08 23:01:01,700:INFO:Copying training dataset
2023-07-08 23:01:01,706:INFO:Defining folds
2023-07-08 23:01:01,707:INFO:Declaring metric variables
2023-07-08 23:01:01,710:INFO:Importing untrained model
2023-07-08 23:01:01,716:INFO:Linear Discriminant Analysis Imported successfully
2023-07-08 23:01:01,726:INFO:Starting cross validation
2023-07-08 23:01:01,728:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:01:05,506:INFO:Calculating mean and std
2023-07-08 23:01:05,508:INFO:Creating metrics dataframe
2023-07-08 23:01:06,013:INFO:Uploading results into container
2023-07-08 23:01:06,014:INFO:Uploading model into container now
2023-07-08 23:01:06,014:INFO:_master_model_container: 11
2023-07-08 23:01:06,015:INFO:_display_container: 2
2023-07-08 23:01:06,015:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-08 23:01:06,015:INFO:create_model() successfully completed......................................
2023-07-08 23:01:06,083:INFO:SubProcess create_model() end ==================================
2023-07-08 23:01:06,083:INFO:Creating metrics dataframe
2023-07-08 23:01:06,096:INFO:Initializing Extra Trees Classifier
2023-07-08 23:01:06,096:INFO:Total runtime is 0.9831674853960672 minutes
2023-07-08 23:01:06,100:INFO:SubProcess create_model() called ==================================
2023-07-08 23:01:06,101:INFO:Initializing create_model()
2023-07-08 23:01:06,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A9D00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:01:06,101:INFO:Checking exceptions
2023-07-08 23:01:06,101:INFO:Importing libraries
2023-07-08 23:01:06,101:INFO:Copying training dataset
2023-07-08 23:01:06,107:INFO:Defining folds
2023-07-08 23:01:06,107:INFO:Declaring metric variables
2023-07-08 23:01:06,112:INFO:Importing untrained model
2023-07-08 23:01:06,115:INFO:Extra Trees Classifier Imported successfully
2023-07-08 23:01:06,124:INFO:Starting cross validation
2023-07-08 23:01:06,126:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:01:11,146:INFO:Calculating mean and std
2023-07-08 23:01:11,147:INFO:Creating metrics dataframe
2023-07-08 23:01:11,711:INFO:Uploading results into container
2023-07-08 23:01:11,711:INFO:Uploading model into container now
2023-07-08 23:01:11,712:INFO:_master_model_container: 12
2023-07-08 23:01:11,712:INFO:_display_container: 2
2023-07-08 23:01:11,713:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-08 23:01:11,713:INFO:create_model() successfully completed......................................
2023-07-08 23:01:11,790:INFO:SubProcess create_model() end ==================================
2023-07-08 23:01:11,790:INFO:Creating metrics dataframe
2023-07-08 23:01:11,805:INFO:Initializing Light Gradient Boosting Machine
2023-07-08 23:01:11,805:INFO:Total runtime is 1.0783236940701801 minutes
2023-07-08 23:01:11,818:INFO:SubProcess create_model() called ==================================
2023-07-08 23:01:11,819:INFO:Initializing create_model()
2023-07-08 23:01:11,819:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A9D00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:01:11,820:INFO:Checking exceptions
2023-07-08 23:01:11,820:INFO:Importing libraries
2023-07-08 23:01:11,820:INFO:Copying training dataset
2023-07-08 23:01:11,833:INFO:Defining folds
2023-07-08 23:01:11,833:INFO:Declaring metric variables
2023-07-08 23:01:11,839:INFO:Importing untrained model
2023-07-08 23:01:11,845:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-08 23:01:11,854:INFO:Starting cross validation
2023-07-08 23:01:11,856:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:01:17,757:INFO:Calculating mean and std
2023-07-08 23:01:17,759:INFO:Creating metrics dataframe
2023-07-08 23:01:18,306:INFO:Uploading results into container
2023-07-08 23:01:18,307:INFO:Uploading model into container now
2023-07-08 23:01:18,307:INFO:_master_model_container: 13
2023-07-08 23:01:18,308:INFO:_display_container: 2
2023-07-08 23:01:18,308:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-08 23:01:18,308:INFO:create_model() successfully completed......................................
2023-07-08 23:01:18,377:INFO:SubProcess create_model() end ==================================
2023-07-08 23:01:18,378:INFO:Creating metrics dataframe
2023-07-08 23:01:18,389:INFO:Initializing Dummy Classifier
2023-07-08 23:01:18,390:INFO:Total runtime is 1.1880597949028013 minutes
2023-07-08 23:01:18,393:INFO:SubProcess create_model() called ==================================
2023-07-08 23:01:18,394:INFO:Initializing create_model()
2023-07-08 23:01:18,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC1A9D00>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:01:18,394:INFO:Checking exceptions
2023-07-08 23:01:18,394:INFO:Importing libraries
2023-07-08 23:01:18,394:INFO:Copying training dataset
2023-07-08 23:01:18,400:INFO:Defining folds
2023-07-08 23:01:18,401:INFO:Declaring metric variables
2023-07-08 23:01:18,405:INFO:Importing untrained model
2023-07-08 23:01:18,409:INFO:Dummy Classifier Imported successfully
2023-07-08 23:01:18,422:INFO:Starting cross validation
2023-07-08 23:01:18,423:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:01:18,595:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:01:18,597:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:01:18,607:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:01:18,620:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:01:18,629:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:01:18,632:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:01:18,658:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:01:18,672:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:01:19,456:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:01:19,475:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:01:22,377:INFO:Calculating mean and std
2023-07-08 23:01:22,380:INFO:Creating metrics dataframe
2023-07-08 23:01:22,968:INFO:Uploading results into container
2023-07-08 23:01:22,969:INFO:Uploading model into container now
2023-07-08 23:01:22,969:INFO:_master_model_container: 14
2023-07-08 23:01:22,969:INFO:_display_container: 2
2023-07-08 23:01:22,970:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-08 23:01:22,970:INFO:create_model() successfully completed......................................
2023-07-08 23:01:23,039:INFO:SubProcess create_model() end ==================================
2023-07-08 23:01:23,040:INFO:Creating metrics dataframe
2023-07-08 23:01:23,064:INFO:Initializing create_model()
2023-07-08 23:01:23,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:01:23,064:INFO:Checking exceptions
2023-07-08 23:01:23,067:INFO:Importing libraries
2023-07-08 23:01:23,067:INFO:Copying training dataset
2023-07-08 23:01:23,073:INFO:Defining folds
2023-07-08 23:01:23,073:INFO:Declaring metric variables
2023-07-08 23:01:23,073:INFO:Importing untrained model
2023-07-08 23:01:23,074:INFO:Declaring custom model
2023-07-08 23:01:23,074:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 23:01:23,076:INFO:Cross validation set to False
2023-07-08 23:01:23,076:INFO:Fitting Model
2023-07-08 23:01:23,792:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 23:01:23,792:INFO:create_model() successfully completed......................................
2023-07-08 23:01:23,892:INFO:_master_model_container: 14
2023-07-08 23:01:23,892:INFO:_display_container: 2
2023-07-08 23:01:23,893:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 23:01:23,893:INFO:compare_models() successfully completed......................................
2023-07-08 23:01:27,107:INFO:Initializing tune_model()
2023-07-08 23:01:27,107:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>)
2023-07-08 23:01:27,108:INFO:Checking exceptions
2023-07-08 23:01:27,149:INFO:Copying training dataset
2023-07-08 23:01:27,156:INFO:Checking base model
2023-07-08 23:01:27,156:INFO:Base model : Gradient Boosting Classifier
2023-07-08 23:01:27,163:INFO:Declaring metric variables
2023-07-08 23:01:27,170:INFO:Defining Hyperparameters
2023-07-08 23:01:27,261:INFO:Tuning with n_jobs=-1
2023-07-08 23:01:27,261:INFO:Initializing RandomizedSearchCV
2023-07-08 23:02:15,588:INFO:best_params: {'actual_estimator__subsample': 0.75, 'actual_estimator__n_estimators': 110, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__min_impurity_decrease': 0.5, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 8, 'actual_estimator__learning_rate': 0.01}
2023-07-08 23:02:15,590:INFO:Hyperparameter search completed
2023-07-08 23:02:15,590:INFO:SubProcess create_model() called ==================================
2023-07-08 23:02:15,591:INFO:Initializing create_model()
2023-07-08 23:02:15,591:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC8B95B0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.75, 'n_estimators': 110, 'min_samples_split': 9, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.5, 'max_features': 'log2', 'max_depth': 8, 'learning_rate': 0.01})
2023-07-08 23:02:15,591:INFO:Checking exceptions
2023-07-08 23:02:15,592:INFO:Importing libraries
2023-07-08 23:02:15,592:INFO:Copying training dataset
2023-07-08 23:02:15,601:INFO:Defining folds
2023-07-08 23:02:15,601:INFO:Declaring metric variables
2023-07-08 23:02:15,605:INFO:Importing untrained model
2023-07-08 23:02:15,605:INFO:Declaring custom model
2023-07-08 23:02:15,612:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 23:02:15,621:INFO:Starting cross validation
2023-07-08 23:02:15,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:02:20,743:INFO:Calculating mean and std
2023-07-08 23:02:20,744:INFO:Creating metrics dataframe
2023-07-08 23:02:20,751:INFO:Finalizing model
2023-07-08 23:02:21,644:INFO:Uploading results into container
2023-07-08 23:02:21,645:INFO:Uploading model into container now
2023-07-08 23:02:21,645:INFO:_master_model_container: 15
2023-07-08 23:02:21,645:INFO:_display_container: 3
2023-07-08 23:02:21,646:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='deviance', max_depth=8,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.5, min_samples_leaf=1,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=110, n_iter_no_change=None,
                           random_state=42, subsample=0.75, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 23:02:21,646:INFO:create_model() successfully completed......................................
2023-07-08 23:02:21,715:INFO:SubProcess create_model() end ==================================
2023-07-08 23:02:21,715:INFO:choose_better activated
2023-07-08 23:02:21,718:INFO:SubProcess create_model() called ==================================
2023-07-08 23:02:21,719:INFO:Initializing create_model()
2023-07-08 23:02:21,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCBCA790>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:02:21,720:INFO:Checking exceptions
2023-07-08 23:02:21,722:INFO:Importing libraries
2023-07-08 23:02:21,722:INFO:Copying training dataset
2023-07-08 23:02:21,726:INFO:Defining folds
2023-07-08 23:02:21,726:INFO:Declaring metric variables
2023-07-08 23:02:21,727:INFO:Importing untrained model
2023-07-08 23:02:21,727:INFO:Declaring custom model
2023-07-08 23:02:21,728:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 23:02:21,729:INFO:Starting cross validation
2023-07-08 23:02:21,730:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:02:26,661:INFO:Calculating mean and std
2023-07-08 23:02:26,661:INFO:Creating metrics dataframe
2023-07-08 23:02:26,664:INFO:Finalizing model
2023-07-08 23:02:27,334:INFO:Uploading results into container
2023-07-08 23:02:27,335:INFO:Uploading model into container now
2023-07-08 23:02:27,335:INFO:_master_model_container: 16
2023-07-08 23:02:27,335:INFO:_display_container: 4
2023-07-08 23:02:27,336:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 23:02:27,336:INFO:create_model() successfully completed......................................
2023-07-08 23:02:27,399:INFO:SubProcess create_model() end ==================================
2023-07-08 23:02:27,400:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.7491
2023-07-08 23:02:27,400:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='deviance', max_depth=8,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.5, min_samples_leaf=1,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=110, n_iter_no_change=None,
                           random_state=42, subsample=0.75, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.7465
2023-07-08 23:02:27,401:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-07-08 23:02:27,401:INFO:choose_better completed
2023-07-08 23:02:27,401:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-08 23:02:27,411:INFO:_master_model_container: 16
2023-07-08 23:02:27,411:INFO:_display_container: 3
2023-07-08 23:02:27,412:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 23:02:27,412:INFO:tune_model() successfully completed......................................
2023-07-08 23:11:24,101:INFO:PyCaret ClassificationExperiment
2023-07-08 23:11:24,101:INFO:Logging name: clf-default-name
2023-07-08 23:11:24,101:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-08 23:11:24,101:INFO:version 3.0.4
2023-07-08 23:11:24,101:INFO:Initializing setup()
2023-07-08 23:11:24,101:INFO:self.USI: 3d1d
2023-07-08 23:11:24,102:INFO:self._variable_keys: {'n_jobs_param', 'data', 'y_test', '_ml_usecase', 'memory', 'fold_groups_param', 'fix_imbalance', 'y', 'X_train', 'target_param', 'seed', 'y_train', 'exp_id', '_available_plots', 'html_param', 'X_test', 'fold_shuffle_param', 'logging_param', 'exp_name_log', 'gpu_param', 'USI', 'gpu_n_jobs_param', 'is_multiclass', 'fold_generator', 'idx', 'X', 'pipeline', 'log_plots_param'}
2023-07-08 23:11:24,102:INFO:Checking environment
2023-07-08 23:11:24,102:INFO:python_version: 3.9.13
2023-07-08 23:11:24,102:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-07-08 23:11:24,102:INFO:machine: AMD64
2023-07-08 23:11:24,102:INFO:platform: Windows-10-10.0.19045-SP0
2023-07-08 23:11:24,102:INFO:Memory: svmem(total=17125732352, available=10551193600, percent=38.4, used=6574538752, free=10551193600)
2023-07-08 23:11:24,102:INFO:Physical Core: 4
2023-07-08 23:11:24,102:INFO:Logical Core: 8
2023-07-08 23:11:24,102:INFO:Checking libraries
2023-07-08 23:11:24,102:INFO:System:
2023-07-08 23:11:24,102:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-07-08 23:11:24,102:INFO:executable: C:\Users\hamim\anaconda3\python.exe
2023-07-08 23:11:24,102:INFO:   machine: Windows-10-10.0.19045-SP0
2023-07-08 23:11:24,102:INFO:PyCaret required dependencies:
2023-07-08 23:11:24,103:INFO:                 pip: 22.2.2
2023-07-08 23:11:24,103:INFO:          setuptools: 63.4.1
2023-07-08 23:11:24,103:INFO:             pycaret: 3.0.4
2023-07-08 23:11:24,103:INFO:             IPython: 7.31.1
2023-07-08 23:11:24,103:INFO:          ipywidgets: 7.6.5
2023-07-08 23:11:24,103:INFO:                tqdm: 4.64.1
2023-07-08 23:11:24,103:INFO:               numpy: 1.21.5
2023-07-08 23:11:24,103:INFO:              pandas: 1.4.4
2023-07-08 23:11:24,103:INFO:              jinja2: 2.11.3
2023-07-08 23:11:24,103:INFO:               scipy: 1.9.1
2023-07-08 23:11:24,103:INFO:              joblib: 1.2.0
2023-07-08 23:11:24,103:INFO:             sklearn: 1.0.2
2023-07-08 23:11:24,103:INFO:                pyod: 1.1.0
2023-07-08 23:11:24,103:INFO:            imblearn: 0.10.1
2023-07-08 23:11:24,103:INFO:   category_encoders: 2.6.1
2023-07-08 23:11:24,103:INFO:            lightgbm: 3.3.5
2023-07-08 23:11:24,104:INFO:               numba: 0.55.1
2023-07-08 23:11:24,104:INFO:            requests: 2.28.1
2023-07-08 23:11:24,104:INFO:          matplotlib: 3.5.2
2023-07-08 23:11:24,104:INFO:          scikitplot: 0.3.7
2023-07-08 23:11:24,104:INFO:         yellowbrick: 1.5
2023-07-08 23:11:24,104:INFO:              plotly: 5.9.0
2023-07-08 23:11:24,104:INFO:    plotly-resampler: Not installed
2023-07-08 23:11:24,104:INFO:             kaleido: 0.2.1
2023-07-08 23:11:24,104:INFO:           schemdraw: 0.15
2023-07-08 23:11:24,104:INFO:         statsmodels: 0.13.2
2023-07-08 23:11:24,104:INFO:              sktime: 0.20.0
2023-07-08 23:11:24,104:INFO:               tbats: 1.1.3
2023-07-08 23:11:24,104:INFO:            pmdarima: 2.0.3
2023-07-08 23:11:24,104:INFO:              psutil: 5.9.0
2023-07-08 23:11:24,104:INFO:          markupsafe: 2.0.1
2023-07-08 23:11:24,104:INFO:             pickle5: Not installed
2023-07-08 23:11:24,104:INFO:         cloudpickle: 2.0.0
2023-07-08 23:11:24,105:INFO:         deprecation: 2.1.0
2023-07-08 23:11:24,105:INFO:              xxhash: 3.2.0
2023-07-08 23:11:24,105:INFO:           wurlitzer: Not installed
2023-07-08 23:11:24,105:INFO:PyCaret optional dependencies:
2023-07-08 23:11:24,105:INFO:                shap: Not installed
2023-07-08 23:11:24,105:INFO:           interpret: Not installed
2023-07-08 23:11:24,105:INFO:                umap: Not installed
2023-07-08 23:11:24,105:INFO:    pandas_profiling: Not installed
2023-07-08 23:11:24,105:INFO:  explainerdashboard: Not installed
2023-07-08 23:11:24,105:INFO:             autoviz: Not installed
2023-07-08 23:11:24,105:INFO:           fairlearn: Not installed
2023-07-08 23:11:24,105:INFO:          deepchecks: Not installed
2023-07-08 23:11:24,105:INFO:             xgboost: Not installed
2023-07-08 23:11:24,105:INFO:            catboost: Not installed
2023-07-08 23:11:24,105:INFO:              kmodes: Not installed
2023-07-08 23:11:24,105:INFO:             mlxtend: Not installed
2023-07-08 23:11:24,105:INFO:       statsforecast: Not installed
2023-07-08 23:11:24,105:INFO:        tune_sklearn: Not installed
2023-07-08 23:11:24,105:INFO:                 ray: Not installed
2023-07-08 23:11:24,106:INFO:            hyperopt: Not installed
2023-07-08 23:11:24,106:INFO:              optuna: Not installed
2023-07-08 23:11:24,106:INFO:               skopt: Not installed
2023-07-08 23:11:24,106:INFO:              mlflow: Not installed
2023-07-08 23:11:24,106:INFO:              gradio: Not installed
2023-07-08 23:11:24,106:INFO:             fastapi: Not installed
2023-07-08 23:11:24,106:INFO:             uvicorn: Not installed
2023-07-08 23:11:24,106:INFO:              m2cgen: Not installed
2023-07-08 23:11:24,106:INFO:           evidently: Not installed
2023-07-08 23:11:24,106:INFO:               fugue: Not installed
2023-07-08 23:11:24,106:INFO:           streamlit: Not installed
2023-07-08 23:11:24,106:INFO:             prophet: Not installed
2023-07-08 23:11:24,106:INFO:None
2023-07-08 23:11:24,106:INFO:Set up data.
2023-07-08 23:11:24,116:INFO:Set up train/test split.
2023-07-08 23:11:24,124:INFO:Set up index.
2023-07-08 23:11:24,124:INFO:Set up folding strategy.
2023-07-08 23:11:24,125:INFO:Assigning column types.
2023-07-08 23:11:24,131:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-08 23:11:24,190:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-08 23:11:24,192:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 23:11:24,223:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:24,224:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:24,277:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-08 23:11:24,278:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 23:11:24,309:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:24,309:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:24,309:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-08 23:11:24,366:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 23:11:24,402:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:24,403:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:24,456:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 23:11:24,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:24,487:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:24,487:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-08 23:11:24,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:24,571:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:24,650:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:24,650:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:24,653:INFO:Preparing preprocessing pipeline...
2023-07-08 23:11:24,654:INFO:Set up simple imputation.
2023-07-08 23:11:24,654:INFO:Set up imbalanced handling.
2023-07-08 23:11:24,654:INFO:Set up column name cleaning.
2023-07-08 23:11:24,720:INFO:Finished creating preprocessing pipeline.
2023-07-08 23:11:24,729:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-08 23:11:24,729:INFO:Creating final display dataframe.
2023-07-08 23:11:24,883:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Target
2                   Target type            Binary
3           Original data shape        (2802, 23)
4        Transformed data shape        (3825, 23)
5   Transformed train set shape        (2984, 23)
6    Transformed test set shape         (841, 23)
7              Numeric features                22
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              3d1d
2023-07-08 23:11:24,975:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:24,976:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:25,068:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:25,068:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:25,069:INFO:setup() successfully completed in 1.54s...............
2023-07-08 23:11:30,127:INFO:PyCaret ClassificationExperiment
2023-07-08 23:11:30,127:INFO:Logging name: clf-default-name
2023-07-08 23:11:30,127:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-08 23:11:30,127:INFO:version 3.0.4
2023-07-08 23:11:30,127:INFO:Initializing setup()
2023-07-08 23:11:30,127:INFO:self.USI: 23d3
2023-07-08 23:11:30,127:INFO:self._variable_keys: {'n_jobs_param', 'data', 'y_test', '_ml_usecase', 'memory', 'fold_groups_param', 'fix_imbalance', 'y', 'X_train', 'target_param', 'seed', 'y_train', 'exp_id', '_available_plots', 'html_param', 'X_test', 'fold_shuffle_param', 'logging_param', 'exp_name_log', 'gpu_param', 'USI', 'gpu_n_jobs_param', 'is_multiclass', 'fold_generator', 'idx', 'X', 'pipeline', 'log_plots_param'}
2023-07-08 23:11:30,127:INFO:Checking environment
2023-07-08 23:11:30,127:INFO:python_version: 3.9.13
2023-07-08 23:11:30,127:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-07-08 23:11:30,127:INFO:machine: AMD64
2023-07-08 23:11:30,127:INFO:platform: Windows-10-10.0.19045-SP0
2023-07-08 23:11:30,127:INFO:Memory: svmem(total=17125732352, available=10545999872, percent=38.4, used=6579732480, free=10545999872)
2023-07-08 23:11:30,127:INFO:Physical Core: 4
2023-07-08 23:11:30,127:INFO:Logical Core: 8
2023-07-08 23:11:30,127:INFO:Checking libraries
2023-07-08 23:11:30,128:INFO:System:
2023-07-08 23:11:30,128:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-07-08 23:11:30,128:INFO:executable: C:\Users\hamim\anaconda3\python.exe
2023-07-08 23:11:30,128:INFO:   machine: Windows-10-10.0.19045-SP0
2023-07-08 23:11:30,128:INFO:PyCaret required dependencies:
2023-07-08 23:11:30,128:INFO:                 pip: 22.2.2
2023-07-08 23:11:30,128:INFO:          setuptools: 63.4.1
2023-07-08 23:11:30,128:INFO:             pycaret: 3.0.4
2023-07-08 23:11:30,128:INFO:             IPython: 7.31.1
2023-07-08 23:11:30,128:INFO:          ipywidgets: 7.6.5
2023-07-08 23:11:30,128:INFO:                tqdm: 4.64.1
2023-07-08 23:11:30,128:INFO:               numpy: 1.21.5
2023-07-08 23:11:30,128:INFO:              pandas: 1.4.4
2023-07-08 23:11:30,128:INFO:              jinja2: 2.11.3
2023-07-08 23:11:30,128:INFO:               scipy: 1.9.1
2023-07-08 23:11:30,128:INFO:              joblib: 1.2.0
2023-07-08 23:11:30,128:INFO:             sklearn: 1.0.2
2023-07-08 23:11:30,128:INFO:                pyod: 1.1.0
2023-07-08 23:11:30,128:INFO:            imblearn: 0.10.1
2023-07-08 23:11:30,129:INFO:   category_encoders: 2.6.1
2023-07-08 23:11:30,129:INFO:            lightgbm: 3.3.5
2023-07-08 23:11:30,129:INFO:               numba: 0.55.1
2023-07-08 23:11:30,129:INFO:            requests: 2.28.1
2023-07-08 23:11:30,129:INFO:          matplotlib: 3.5.2
2023-07-08 23:11:30,129:INFO:          scikitplot: 0.3.7
2023-07-08 23:11:30,129:INFO:         yellowbrick: 1.5
2023-07-08 23:11:30,129:INFO:              plotly: 5.9.0
2023-07-08 23:11:30,129:INFO:    plotly-resampler: Not installed
2023-07-08 23:11:30,129:INFO:             kaleido: 0.2.1
2023-07-08 23:11:30,129:INFO:           schemdraw: 0.15
2023-07-08 23:11:30,129:INFO:         statsmodels: 0.13.2
2023-07-08 23:11:30,129:INFO:              sktime: 0.20.0
2023-07-08 23:11:30,129:INFO:               tbats: 1.1.3
2023-07-08 23:11:30,129:INFO:            pmdarima: 2.0.3
2023-07-08 23:11:30,129:INFO:              psutil: 5.9.0
2023-07-08 23:11:30,129:INFO:          markupsafe: 2.0.1
2023-07-08 23:11:30,129:INFO:             pickle5: Not installed
2023-07-08 23:11:30,129:INFO:         cloudpickle: 2.0.0
2023-07-08 23:11:30,129:INFO:         deprecation: 2.1.0
2023-07-08 23:11:30,129:INFO:              xxhash: 3.2.0
2023-07-08 23:11:30,129:INFO:           wurlitzer: Not installed
2023-07-08 23:11:30,129:INFO:PyCaret optional dependencies:
2023-07-08 23:11:30,130:INFO:                shap: Not installed
2023-07-08 23:11:30,130:INFO:           interpret: Not installed
2023-07-08 23:11:30,130:INFO:                umap: Not installed
2023-07-08 23:11:30,130:INFO:    pandas_profiling: Not installed
2023-07-08 23:11:30,130:INFO:  explainerdashboard: Not installed
2023-07-08 23:11:30,130:INFO:             autoviz: Not installed
2023-07-08 23:11:30,130:INFO:           fairlearn: Not installed
2023-07-08 23:11:30,130:INFO:          deepchecks: Not installed
2023-07-08 23:11:30,130:INFO:             xgboost: Not installed
2023-07-08 23:11:30,130:INFO:            catboost: Not installed
2023-07-08 23:11:30,130:INFO:              kmodes: Not installed
2023-07-08 23:11:30,130:INFO:             mlxtend: Not installed
2023-07-08 23:11:30,130:INFO:       statsforecast: Not installed
2023-07-08 23:11:30,130:INFO:        tune_sklearn: Not installed
2023-07-08 23:11:30,130:INFO:                 ray: Not installed
2023-07-08 23:11:30,130:INFO:            hyperopt: Not installed
2023-07-08 23:11:30,130:INFO:              optuna: Not installed
2023-07-08 23:11:30,130:INFO:               skopt: Not installed
2023-07-08 23:11:30,130:INFO:              mlflow: Not installed
2023-07-08 23:11:30,130:INFO:              gradio: Not installed
2023-07-08 23:11:30,130:INFO:             fastapi: Not installed
2023-07-08 23:11:30,130:INFO:             uvicorn: Not installed
2023-07-08 23:11:30,130:INFO:              m2cgen: Not installed
2023-07-08 23:11:30,131:INFO:           evidently: Not installed
2023-07-08 23:11:30,131:INFO:               fugue: Not installed
2023-07-08 23:11:30,131:INFO:           streamlit: Not installed
2023-07-08 23:11:30,131:INFO:             prophet: Not installed
2023-07-08 23:11:30,131:INFO:None
2023-07-08 23:11:30,131:INFO:Set up data.
2023-07-08 23:11:30,139:INFO:Set up train/test split.
2023-07-08 23:11:30,143:INFO:Set up index.
2023-07-08 23:11:30,143:INFO:Set up folding strategy.
2023-07-08 23:11:30,143:INFO:Assigning column types.
2023-07-08 23:11:30,146:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-08 23:11:30,189:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-08 23:11:30,189:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 23:11:30,217:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:30,217:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:30,261:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-08 23:11:30,262:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 23:11:30,288:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:30,288:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:30,289:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-08 23:11:30,333:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 23:11:30,359:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:30,359:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:30,404:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 23:11:30,431:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:30,432:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:30,432:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-08 23:11:30,504:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:30,505:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:30,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:30,576:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:30,577:INFO:Preparing preprocessing pipeline...
2023-07-08 23:11:30,578:INFO:Set up simple imputation.
2023-07-08 23:11:30,578:INFO:Set up imbalanced handling.
2023-07-08 23:11:30,579:INFO:Set up column name cleaning.
2023-07-08 23:11:30,625:INFO:Finished creating preprocessing pipeline.
2023-07-08 23:11:30,637:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Marital status_1',
                                             'Marital status_2',
                                             'Marital status_3',
                                             'Marital status_4',
                                             'Marital status_5',...
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-08 23:11:30,637:INFO:Creating final display dataframe.
2023-07-08 23:11:30,776:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Target
2                   Target type            Binary
3           Original data shape        (2802, 23)
4        Transformed data shape        (3825, 23)
5   Transformed train set shape        (2984, 23)
6    Transformed test set shape         (841, 23)
7              Numeric features                22
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              23d3
2023-07-08 23:11:30,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:30,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:30,981:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:30,982:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:11:30,982:INFO:setup() successfully completed in 1.27s...............
2023-07-08 23:11:33,722:INFO:Initializing compare_models()
2023-07-08 23:11:33,722:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-08 23:11:33,722:INFO:Checking exceptions
2023-07-08 23:11:33,727:INFO:Preparing display monitor
2023-07-08 23:11:33,778:INFO:Initializing Logistic Regression
2023-07-08 23:11:33,779:INFO:Total runtime is 1.661380132039388e-05 minutes
2023-07-08 23:11:33,786:INFO:SubProcess create_model() called ==================================
2023-07-08 23:11:33,786:INFO:Initializing create_model()
2023-07-08 23:11:33,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC327EB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:11:33,786:INFO:Checking exceptions
2023-07-08 23:11:33,786:INFO:Importing libraries
2023-07-08 23:11:33,787:INFO:Copying training dataset
2023-07-08 23:11:33,793:INFO:Defining folds
2023-07-08 23:11:33,793:INFO:Declaring metric variables
2023-07-08 23:11:33,799:INFO:Importing untrained model
2023-07-08 23:11:33,805:INFO:Logistic Regression Imported successfully
2023-07-08 23:11:33,813:INFO:Starting cross validation
2023-07-08 23:11:33,815:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:11:46,139:INFO:Calculating mean and std
2023-07-08 23:11:46,141:INFO:Creating metrics dataframe
2023-07-08 23:11:46,738:INFO:Uploading results into container
2023-07-08 23:11:46,740:INFO:Uploading model into container now
2023-07-08 23:11:46,740:INFO:_master_model_container: 1
2023-07-08 23:11:46,740:INFO:_display_container: 2
2023-07-08 23:11:46,741:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-08 23:11:46,741:INFO:create_model() successfully completed......................................
2023-07-08 23:11:46,815:INFO:SubProcess create_model() end ==================================
2023-07-08 23:11:46,815:INFO:Creating metrics dataframe
2023-07-08 23:11:46,823:INFO:Initializing K Neighbors Classifier
2023-07-08 23:11:46,824:INFO:Total runtime is 0.21742376486460369 minutes
2023-07-08 23:11:46,827:INFO:SubProcess create_model() called ==================================
2023-07-08 23:11:46,828:INFO:Initializing create_model()
2023-07-08 23:11:46,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC327EB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:11:46,828:INFO:Checking exceptions
2023-07-08 23:11:46,828:INFO:Importing libraries
2023-07-08 23:11:46,828:INFO:Copying training dataset
2023-07-08 23:11:46,833:INFO:Defining folds
2023-07-08 23:11:46,833:INFO:Declaring metric variables
2023-07-08 23:11:46,837:INFO:Importing untrained model
2023-07-08 23:11:46,842:INFO:K Neighbors Classifier Imported successfully
2023-07-08 23:11:46,855:INFO:Starting cross validation
2023-07-08 23:11:46,857:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:11:47,059:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:11:47,060:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:11:47,065:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:11:47,083:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:11:47,085:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:11:47,097:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:11:47,105:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:11:47,148:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:11:48,146:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:11:48,157:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:11:51,637:INFO:Calculating mean and std
2023-07-08 23:11:51,637:INFO:Creating metrics dataframe
2023-07-08 23:11:52,277:INFO:Uploading results into container
2023-07-08 23:11:52,278:INFO:Uploading model into container now
2023-07-08 23:11:52,279:INFO:_master_model_container: 2
2023-07-08 23:11:52,279:INFO:_display_container: 2
2023-07-08 23:11:52,279:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-08 23:11:52,279:INFO:create_model() successfully completed......................................
2023-07-08 23:11:52,356:INFO:SubProcess create_model() end ==================================
2023-07-08 23:11:52,356:INFO:Creating metrics dataframe
2023-07-08 23:11:52,371:INFO:Initializing Naive Bayes
2023-07-08 23:11:52,371:INFO:Total runtime is 0.30987293322881065 minutes
2023-07-08 23:11:52,376:INFO:SubProcess create_model() called ==================================
2023-07-08 23:11:52,377:INFO:Initializing create_model()
2023-07-08 23:11:52,377:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC327EB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:11:52,377:INFO:Checking exceptions
2023-07-08 23:11:52,377:INFO:Importing libraries
2023-07-08 23:11:52,378:INFO:Copying training dataset
2023-07-08 23:11:52,386:INFO:Defining folds
2023-07-08 23:11:52,387:INFO:Declaring metric variables
2023-07-08 23:11:52,392:INFO:Importing untrained model
2023-07-08 23:11:52,398:INFO:Naive Bayes Imported successfully
2023-07-08 23:11:52,411:INFO:Starting cross validation
2023-07-08 23:11:52,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:11:56,940:INFO:Calculating mean and std
2023-07-08 23:11:56,941:INFO:Creating metrics dataframe
2023-07-08 23:11:57,534:INFO:Uploading results into container
2023-07-08 23:11:57,535:INFO:Uploading model into container now
2023-07-08 23:11:57,536:INFO:_master_model_container: 3
2023-07-08 23:11:57,536:INFO:_display_container: 2
2023-07-08 23:11:57,536:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-08 23:11:57,536:INFO:create_model() successfully completed......................................
2023-07-08 23:11:57,603:INFO:SubProcess create_model() end ==================================
2023-07-08 23:11:57,603:INFO:Creating metrics dataframe
2023-07-08 23:11:57,612:INFO:Initializing Decision Tree Classifier
2023-07-08 23:11:57,612:INFO:Total runtime is 0.39723735253016157 minutes
2023-07-08 23:11:57,617:INFO:SubProcess create_model() called ==================================
2023-07-08 23:11:57,618:INFO:Initializing create_model()
2023-07-08 23:11:57,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC327EB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:11:57,618:INFO:Checking exceptions
2023-07-08 23:11:57,619:INFO:Importing libraries
2023-07-08 23:11:57,619:INFO:Copying training dataset
2023-07-08 23:11:57,624:INFO:Defining folds
2023-07-08 23:11:57,624:INFO:Declaring metric variables
2023-07-08 23:11:57,628:INFO:Importing untrained model
2023-07-08 23:11:57,633:INFO:Decision Tree Classifier Imported successfully
2023-07-08 23:11:57,644:INFO:Starting cross validation
2023-07-08 23:11:57,646:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:12:02,168:INFO:Calculating mean and std
2023-07-08 23:12:02,169:INFO:Creating metrics dataframe
2023-07-08 23:12:02,771:INFO:Uploading results into container
2023-07-08 23:12:02,772:INFO:Uploading model into container now
2023-07-08 23:12:02,772:INFO:_master_model_container: 4
2023-07-08 23:12:02,773:INFO:_display_container: 2
2023-07-08 23:12:02,773:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-08 23:12:02,773:INFO:create_model() successfully completed......................................
2023-07-08 23:12:02,848:INFO:SubProcess create_model() end ==================================
2023-07-08 23:12:02,848:INFO:Creating metrics dataframe
2023-07-08 23:12:02,862:INFO:Initializing SVM - Linear Kernel
2023-07-08 23:12:02,862:INFO:Total runtime is 0.4847321748733521 minutes
2023-07-08 23:12:02,866:INFO:SubProcess create_model() called ==================================
2023-07-08 23:12:02,867:INFO:Initializing create_model()
2023-07-08 23:12:02,867:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC327EB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:12:02,867:INFO:Checking exceptions
2023-07-08 23:12:02,867:INFO:Importing libraries
2023-07-08 23:12:02,868:INFO:Copying training dataset
2023-07-08 23:12:02,875:INFO:Defining folds
2023-07-08 23:12:02,875:INFO:Declaring metric variables
2023-07-08 23:12:02,879:INFO:Importing untrained model
2023-07-08 23:12:02,884:INFO:SVM - Linear Kernel Imported successfully
2023-07-08 23:12:02,894:INFO:Starting cross validation
2023-07-08 23:12:02,896:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:12:03,080:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:12:03,137:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:12:03,166:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:12:03,167:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:12:03,167:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:12:03,179:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:12:03,197:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:12:03,200:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:12:04,092:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:12:04,128:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:12:07,571:INFO:Calculating mean and std
2023-07-08 23:12:07,572:INFO:Creating metrics dataframe
2023-07-08 23:12:08,229:INFO:Uploading results into container
2023-07-08 23:12:08,230:INFO:Uploading model into container now
2023-07-08 23:12:08,231:INFO:_master_model_container: 5
2023-07-08 23:12:08,231:INFO:_display_container: 2
2023-07-08 23:12:08,231:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-08 23:12:08,232:INFO:create_model() successfully completed......................................
2023-07-08 23:12:08,311:INFO:SubProcess create_model() end ==================================
2023-07-08 23:12:08,311:INFO:Creating metrics dataframe
2023-07-08 23:12:08,325:INFO:Initializing Ridge Classifier
2023-07-08 23:12:08,325:INFO:Total runtime is 0.5757796764373779 minutes
2023-07-08 23:12:08,331:INFO:SubProcess create_model() called ==================================
2023-07-08 23:12:08,331:INFO:Initializing create_model()
2023-07-08 23:12:08,332:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC327EB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:12:08,332:INFO:Checking exceptions
2023-07-08 23:12:08,332:INFO:Importing libraries
2023-07-08 23:12:08,332:INFO:Copying training dataset
2023-07-08 23:12:08,341:INFO:Defining folds
2023-07-08 23:12:08,341:INFO:Declaring metric variables
2023-07-08 23:12:08,347:INFO:Importing untrained model
2023-07-08 23:12:08,352:INFO:Ridge Classifier Imported successfully
2023-07-08 23:12:08,365:INFO:Starting cross validation
2023-07-08 23:12:08,366:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:12:08,540:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:12:08,559:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:12:08,565:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:12:08,566:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:12:08,569:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:12:08,597:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:12:08,600:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:12:08,627:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:12:09,613:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:12:09,615:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:12:13,498:INFO:Calculating mean and std
2023-07-08 23:12:13,501:INFO:Creating metrics dataframe
2023-07-08 23:12:14,159:INFO:Uploading results into container
2023-07-08 23:12:14,160:INFO:Uploading model into container now
2023-07-08 23:12:14,161:INFO:_master_model_container: 6
2023-07-08 23:12:14,161:INFO:_display_container: 2
2023-07-08 23:12:14,161:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=42, solver='auto', tol=0.001)
2023-07-08 23:12:14,161:INFO:create_model() successfully completed......................................
2023-07-08 23:12:14,237:INFO:SubProcess create_model() end ==================================
2023-07-08 23:12:14,237:INFO:Creating metrics dataframe
2023-07-08 23:12:14,252:INFO:Initializing Random Forest Classifier
2023-07-08 23:12:14,252:INFO:Total runtime is 0.6745643019676208 minutes
2023-07-08 23:12:14,258:INFO:SubProcess create_model() called ==================================
2023-07-08 23:12:14,258:INFO:Initializing create_model()
2023-07-08 23:12:14,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC327EB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:12:14,259:INFO:Checking exceptions
2023-07-08 23:12:14,259:INFO:Importing libraries
2023-07-08 23:12:14,259:INFO:Copying training dataset
2023-07-08 23:12:14,268:INFO:Defining folds
2023-07-08 23:12:14,268:INFO:Declaring metric variables
2023-07-08 23:12:14,274:INFO:Importing untrained model
2023-07-08 23:12:14,280:INFO:Random Forest Classifier Imported successfully
2023-07-08 23:12:14,291:INFO:Starting cross validation
2023-07-08 23:12:14,292:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:12:20,986:INFO:Calculating mean and std
2023-07-08 23:12:20,987:INFO:Creating metrics dataframe
2023-07-08 23:12:21,618:INFO:Uploading results into container
2023-07-08 23:12:21,619:INFO:Uploading model into container now
2023-07-08 23:12:21,620:INFO:_master_model_container: 7
2023-07-08 23:12:21,620:INFO:_display_container: 2
2023-07-08 23:12:21,621:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-08 23:12:21,621:INFO:create_model() successfully completed......................................
2023-07-08 23:12:21,694:INFO:SubProcess create_model() end ==================================
2023-07-08 23:12:21,694:INFO:Creating metrics dataframe
2023-07-08 23:12:21,707:INFO:Initializing Quadratic Discriminant Analysis
2023-07-08 23:12:21,708:INFO:Total runtime is 0.7988288164138794 minutes
2023-07-08 23:12:21,712:INFO:SubProcess create_model() called ==================================
2023-07-08 23:12:21,713:INFO:Initializing create_model()
2023-07-08 23:12:21,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC327EB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:12:21,713:INFO:Checking exceptions
2023-07-08 23:12:21,713:INFO:Importing libraries
2023-07-08 23:12:21,713:INFO:Copying training dataset
2023-07-08 23:12:21,720:INFO:Defining folds
2023-07-08 23:12:21,721:INFO:Declaring metric variables
2023-07-08 23:12:21,729:INFO:Importing untrained model
2023-07-08 23:12:21,734:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-08 23:12:21,744:INFO:Starting cross validation
2023-07-08 23:12:21,746:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:12:21,915:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:12:21,916:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:12:21,938:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:12:21,947:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:12:21,962:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:12:21,967:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:12:21,970:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:21,970:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:21,970:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:21,971:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:21,971:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:21,972:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:21,974:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:12:21,976:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:12:21,984:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:21,985:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:21,985:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:22,006:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,007:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,007:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,007:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,007:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:22,008:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:22,011:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,011:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,012:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:22,016:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,016:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,016:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,016:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,016:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:22,016:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:22,019:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:12:22,022:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,022:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,022:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:22,025:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,025:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,026:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:22,032:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,032:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,033:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:22,036:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:12:22,039:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:12:22,046:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,046:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:12:22,046:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,047:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:22,055:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,057:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,057:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:22,061:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,061:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,061:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:22,062:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:12:22,064:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,065:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,065:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:22,070:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:12:22,071:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:12:22,072:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:12:22,078:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:12:22,080:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:12:22,082:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,082:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:22,083:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:22,085:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:12:22,092:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:12:22,094:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:12:22,094:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:12:22,107:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:12:22,124:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:12:23,161:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:12:23,186:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:23,187:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:23,187:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:23,199:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:12:23,207:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:23,207:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:23,207:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:23,209:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:12:23,211:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:12:23,219:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:23,219:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:23,220:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:23,237:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:23,237:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:12:23,237:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:12:23,238:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:12:23,241:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:12:26,915:INFO:Calculating mean and std
2023-07-08 23:12:26,917:INFO:Creating metrics dataframe
2023-07-08 23:12:27,496:INFO:Uploading results into container
2023-07-08 23:12:27,497:INFO:Uploading model into container now
2023-07-08 23:12:27,498:INFO:_master_model_container: 8
2023-07-08 23:12:27,498:INFO:_display_container: 2
2023-07-08 23:12:27,498:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-08 23:12:27,499:INFO:create_model() successfully completed......................................
2023-07-08 23:12:27,564:INFO:SubProcess create_model() end ==================================
2023-07-08 23:12:27,565:INFO:Creating metrics dataframe
2023-07-08 23:12:27,576:INFO:Initializing Ada Boost Classifier
2023-07-08 23:12:27,577:INFO:Total runtime is 0.8966349005699158 minutes
2023-07-08 23:12:27,582:INFO:SubProcess create_model() called ==================================
2023-07-08 23:12:27,582:INFO:Initializing create_model()
2023-07-08 23:12:27,582:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC327EB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:12:27,583:INFO:Checking exceptions
2023-07-08 23:12:27,583:INFO:Importing libraries
2023-07-08 23:12:27,583:INFO:Copying training dataset
2023-07-08 23:12:27,589:INFO:Defining folds
2023-07-08 23:12:27,590:INFO:Declaring metric variables
2023-07-08 23:12:27,596:INFO:Importing untrained model
2023-07-08 23:12:27,601:INFO:Ada Boost Classifier Imported successfully
2023-07-08 23:12:27,613:INFO:Starting cross validation
2023-07-08 23:12:27,614:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:12:32,700:INFO:Calculating mean and std
2023-07-08 23:12:32,702:INFO:Creating metrics dataframe
2023-07-08 23:12:33,445:INFO:Uploading results into container
2023-07-08 23:12:33,446:INFO:Uploading model into container now
2023-07-08 23:12:33,446:INFO:_master_model_container: 9
2023-07-08 23:12:33,446:INFO:_display_container: 2
2023-07-08 23:12:33,447:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2023-07-08 23:12:33,447:INFO:create_model() successfully completed......................................
2023-07-08 23:12:33,525:INFO:SubProcess create_model() end ==================================
2023-07-08 23:12:33,525:INFO:Creating metrics dataframe
2023-07-08 23:12:33,540:INFO:Initializing Gradient Boosting Classifier
2023-07-08 23:12:33,540:INFO:Total runtime is 0.9960360368092855 minutes
2023-07-08 23:12:33,545:INFO:SubProcess create_model() called ==================================
2023-07-08 23:12:33,545:INFO:Initializing create_model()
2023-07-08 23:12:33,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC327EB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:12:33,546:INFO:Checking exceptions
2023-07-08 23:12:33,546:INFO:Importing libraries
2023-07-08 23:12:33,546:INFO:Copying training dataset
2023-07-08 23:12:33,555:INFO:Defining folds
2023-07-08 23:12:33,555:INFO:Declaring metric variables
2023-07-08 23:12:33,559:INFO:Importing untrained model
2023-07-08 23:12:33,564:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 23:12:33,574:INFO:Starting cross validation
2023-07-08 23:12:33,576:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:12:40,299:INFO:Calculating mean and std
2023-07-08 23:12:40,301:INFO:Creating metrics dataframe
2023-07-08 23:12:41,007:INFO:Uploading results into container
2023-07-08 23:12:41,008:INFO:Uploading model into container now
2023-07-08 23:12:41,008:INFO:_master_model_container: 10
2023-07-08 23:12:41,008:INFO:_display_container: 2
2023-07-08 23:12:41,009:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 23:12:41,009:INFO:create_model() successfully completed......................................
2023-07-08 23:12:41,095:INFO:SubProcess create_model() end ==================================
2023-07-08 23:12:41,095:INFO:Creating metrics dataframe
2023-07-08 23:12:41,110:INFO:Initializing Linear Discriminant Analysis
2023-07-08 23:12:41,110:INFO:Total runtime is 1.1221907019615174 minutes
2023-07-08 23:12:41,115:INFO:SubProcess create_model() called ==================================
2023-07-08 23:12:41,116:INFO:Initializing create_model()
2023-07-08 23:12:41,116:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC327EB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:12:41,116:INFO:Checking exceptions
2023-07-08 23:12:41,116:INFO:Importing libraries
2023-07-08 23:12:41,116:INFO:Copying training dataset
2023-07-08 23:12:41,124:INFO:Defining folds
2023-07-08 23:12:41,124:INFO:Declaring metric variables
2023-07-08 23:12:41,130:INFO:Importing untrained model
2023-07-08 23:12:41,137:INFO:Linear Discriminant Analysis Imported successfully
2023-07-08 23:12:41,147:INFO:Starting cross validation
2023-07-08 23:12:41,148:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:12:45,712:INFO:Calculating mean and std
2023-07-08 23:12:45,714:INFO:Creating metrics dataframe
2023-07-08 23:12:46,311:INFO:Uploading results into container
2023-07-08 23:12:46,312:INFO:Uploading model into container now
2023-07-08 23:12:46,313:INFO:_master_model_container: 11
2023-07-08 23:12:46,314:INFO:_display_container: 2
2023-07-08 23:12:46,314:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-08 23:12:46,314:INFO:create_model() successfully completed......................................
2023-07-08 23:12:46,381:INFO:SubProcess create_model() end ==================================
2023-07-08 23:12:46,381:INFO:Creating metrics dataframe
2023-07-08 23:12:46,393:INFO:Initializing Extra Trees Classifier
2023-07-08 23:12:46,394:INFO:Total runtime is 1.2102660894393922 minutes
2023-07-08 23:12:46,398:INFO:SubProcess create_model() called ==================================
2023-07-08 23:12:46,399:INFO:Initializing create_model()
2023-07-08 23:12:46,399:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC327EB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:12:46,399:INFO:Checking exceptions
2023-07-08 23:12:46,400:INFO:Importing libraries
2023-07-08 23:12:46,400:INFO:Copying training dataset
2023-07-08 23:12:46,404:INFO:Defining folds
2023-07-08 23:12:46,405:INFO:Declaring metric variables
2023-07-08 23:12:46,408:INFO:Importing untrained model
2023-07-08 23:12:46,414:INFO:Extra Trees Classifier Imported successfully
2023-07-08 23:12:46,426:INFO:Starting cross validation
2023-07-08 23:12:46,427:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:12:52,472:INFO:Calculating mean and std
2023-07-08 23:12:52,474:INFO:Creating metrics dataframe
2023-07-08 23:12:53,146:INFO:Uploading results into container
2023-07-08 23:12:53,147:INFO:Uploading model into container now
2023-07-08 23:12:53,147:INFO:_master_model_container: 12
2023-07-08 23:12:53,148:INFO:_display_container: 2
2023-07-08 23:12:53,149:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-08 23:12:53,149:INFO:create_model() successfully completed......................................
2023-07-08 23:12:53,218:INFO:SubProcess create_model() end ==================================
2023-07-08 23:12:53,218:INFO:Creating metrics dataframe
2023-07-08 23:12:53,233:INFO:Initializing Light Gradient Boosting Machine
2023-07-08 23:12:53,233:INFO:Total runtime is 1.324237906932831 minutes
2023-07-08 23:12:53,237:INFO:SubProcess create_model() called ==================================
2023-07-08 23:12:53,237:INFO:Initializing create_model()
2023-07-08 23:12:53,238:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC327EB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:12:53,238:INFO:Checking exceptions
2023-07-08 23:12:53,238:INFO:Importing libraries
2023-07-08 23:12:53,238:INFO:Copying training dataset
2023-07-08 23:12:53,246:INFO:Defining folds
2023-07-08 23:12:53,246:INFO:Declaring metric variables
2023-07-08 23:12:53,252:INFO:Importing untrained model
2023-07-08 23:12:53,257:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-08 23:12:53,267:INFO:Starting cross validation
2023-07-08 23:12:53,269:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:13:00,759:INFO:Calculating mean and std
2023-07-08 23:13:00,760:INFO:Creating metrics dataframe
2023-07-08 23:13:01,398:INFO:Uploading results into container
2023-07-08 23:13:01,399:INFO:Uploading model into container now
2023-07-08 23:13:01,400:INFO:_master_model_container: 13
2023-07-08 23:13:01,400:INFO:_display_container: 2
2023-07-08 23:13:01,400:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-08 23:13:01,400:INFO:create_model() successfully completed......................................
2023-07-08 23:13:01,475:INFO:SubProcess create_model() end ==================================
2023-07-08 23:13:01,475:INFO:Creating metrics dataframe
2023-07-08 23:13:01,493:INFO:Initializing Dummy Classifier
2023-07-08 23:13:01,494:INFO:Total runtime is 1.4619224508603414 minutes
2023-07-08 23:13:01,500:INFO:SubProcess create_model() called ==================================
2023-07-08 23:13:01,500:INFO:Initializing create_model()
2023-07-08 23:13:01,500:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC327EB0>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:13:01,500:INFO:Checking exceptions
2023-07-08 23:13:01,500:INFO:Importing libraries
2023-07-08 23:13:01,501:INFO:Copying training dataset
2023-07-08 23:13:01,507:INFO:Defining folds
2023-07-08 23:13:01,508:INFO:Declaring metric variables
2023-07-08 23:13:01,512:INFO:Importing untrained model
2023-07-08 23:13:01,519:INFO:Dummy Classifier Imported successfully
2023-07-08 23:13:01,528:INFO:Starting cross validation
2023-07-08 23:13:01,530:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:13:01,718:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:13:01,752:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:13:01,766:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:13:01,779:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:13:01,796:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:13:01,804:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:13:01,809:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:13:01,952:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:13:02,854:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:13:02,862:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:13:06,308:INFO:Calculating mean and std
2023-07-08 23:13:06,310:INFO:Creating metrics dataframe
2023-07-08 23:13:06,935:INFO:Uploading results into container
2023-07-08 23:13:06,936:INFO:Uploading model into container now
2023-07-08 23:13:06,936:INFO:_master_model_container: 14
2023-07-08 23:13:06,937:INFO:_display_container: 2
2023-07-08 23:13:06,937:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-08 23:13:06,937:INFO:create_model() successfully completed......................................
2023-07-08 23:13:07,002:INFO:SubProcess create_model() end ==================================
2023-07-08 23:13:07,002:INFO:Creating metrics dataframe
2023-07-08 23:13:07,030:INFO:Initializing create_model()
2023-07-08 23:13:07,030:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:13:07,030:INFO:Checking exceptions
2023-07-08 23:13:07,032:INFO:Importing libraries
2023-07-08 23:13:07,032:INFO:Copying training dataset
2023-07-08 23:13:07,037:INFO:Defining folds
2023-07-08 23:13:07,037:INFO:Declaring metric variables
2023-07-08 23:13:07,037:INFO:Importing untrained model
2023-07-08 23:13:07,037:INFO:Declaring custom model
2023-07-08 23:13:07,038:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 23:13:07,039:INFO:Cross validation set to False
2023-07-08 23:13:07,040:INFO:Fitting Model
2023-07-08 23:13:07,902:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 23:13:07,902:INFO:create_model() successfully completed......................................
2023-07-08 23:13:08,012:INFO:_master_model_container: 14
2023-07-08 23:13:08,012:INFO:_display_container: 2
2023-07-08 23:13:08,013:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 23:13:08,013:INFO:compare_models() successfully completed......................................
2023-07-08 23:13:28,184:INFO:Initializing tune_model()
2023-07-08 23:13:28,185:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>)
2023-07-08 23:13:28,185:INFO:Checking exceptions
2023-07-08 23:13:28,230:INFO:Copying training dataset
2023-07-08 23:13:28,234:INFO:Checking base model
2023-07-08 23:13:28,235:INFO:Base model : Gradient Boosting Classifier
2023-07-08 23:13:28,241:INFO:Declaring metric variables
2023-07-08 23:13:28,247:INFO:Defining Hyperparameters
2023-07-08 23:13:28,327:INFO:Tuning with n_jobs=-1
2023-07-08 23:13:28,327:INFO:Initializing RandomizedSearchCV
2023-07-08 23:14:25,907:INFO:best_params: {'actual_estimator__subsample': 0.65, 'actual_estimator__n_estimators': 120, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.05}
2023-07-08 23:14:25,908:INFO:Hyperparameter search completed
2023-07-08 23:14:25,908:INFO:SubProcess create_model() called ==================================
2023-07-08 23:14:25,909:INFO:Initializing create_model()
2023-07-08 23:14:25,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BB0527F0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.65, 'n_estimators': 120, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0002, 'max_features': 'sqrt', 'max_depth': 6, 'learning_rate': 0.05})
2023-07-08 23:14:25,909:INFO:Checking exceptions
2023-07-08 23:14:25,909:INFO:Importing libraries
2023-07-08 23:14:25,909:INFO:Copying training dataset
2023-07-08 23:14:25,916:INFO:Defining folds
2023-07-08 23:14:25,916:INFO:Declaring metric variables
2023-07-08 23:14:25,921:INFO:Importing untrained model
2023-07-08 23:14:25,921:INFO:Declaring custom model
2023-07-08 23:14:25,926:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 23:14:25,949:INFO:Starting cross validation
2023-07-08 23:14:25,950:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:14:31,869:INFO:Calculating mean and std
2023-07-08 23:14:31,871:INFO:Creating metrics dataframe
2023-07-08 23:14:31,877:INFO:Finalizing model
2023-07-08 23:14:33,234:INFO:Uploading results into container
2023-07-08 23:14:33,235:INFO:Uploading model into container now
2023-07-08 23:14:33,236:INFO:_master_model_container: 15
2023-07-08 23:14:33,236:INFO:_display_container: 3
2023-07-08 23:14:33,237:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='deviance', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.0002, min_samples_leaf=3,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=120, n_iter_no_change=None,
                           random_state=42, subsample=0.65, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 23:14:33,238:INFO:create_model() successfully completed......................................
2023-07-08 23:14:33,314:INFO:SubProcess create_model() end ==================================
2023-07-08 23:14:33,314:INFO:choose_better activated
2023-07-08 23:14:33,318:INFO:SubProcess create_model() called ==================================
2023-07-08 23:14:33,319:INFO:Initializing create_model()
2023-07-08 23:14:33,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:14:33,319:INFO:Checking exceptions
2023-07-08 23:14:33,322:INFO:Importing libraries
2023-07-08 23:14:33,322:INFO:Copying training dataset
2023-07-08 23:14:33,329:INFO:Defining folds
2023-07-08 23:14:33,330:INFO:Declaring metric variables
2023-07-08 23:14:33,330:INFO:Importing untrained model
2023-07-08 23:14:33,330:INFO:Declaring custom model
2023-07-08 23:14:33,331:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 23:14:33,332:INFO:Starting cross validation
2023-07-08 23:14:33,333:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:14:39,536:INFO:Calculating mean and std
2023-07-08 23:14:39,536:INFO:Creating metrics dataframe
2023-07-08 23:14:39,539:INFO:Finalizing model
2023-07-08 23:14:40,290:INFO:Uploading results into container
2023-07-08 23:14:40,290:INFO:Uploading model into container now
2023-07-08 23:14:40,291:INFO:_master_model_container: 16
2023-07-08 23:14:40,291:INFO:_display_container: 4
2023-07-08 23:14:40,291:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 23:14:40,291:INFO:create_model() successfully completed......................................
2023-07-08 23:14:40,356:INFO:SubProcess create_model() end ==================================
2023-07-08 23:14:40,357:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8261
2023-07-08 23:14:40,357:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='deviance', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.0002, min_samples_leaf=3,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=120, n_iter_no_change=None,
                           random_state=42, subsample=0.65, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8241
2023-07-08 23:14:40,358:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-07-08 23:14:40,358:INFO:choose_better completed
2023-07-08 23:14:40,358:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-08 23:14:40,368:INFO:_master_model_container: 16
2023-07-08 23:14:40,368:INFO:_display_container: 3
2023-07-08 23:14:40,369:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 23:14:40,369:INFO:tune_model() successfully completed......................................
2023-07-08 23:14:57,010:INFO:Initializing evaluate_model()
2023-07-08 23:14:57,011:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-08 23:14:57,035:INFO:Initializing plot_model()
2023-07-08 23:14:57,036:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, system=True)
2023-07-08 23:14:57,036:INFO:Checking exceptions
2023-07-08 23:14:57,038:INFO:Preloading libraries
2023-07-08 23:14:57,048:INFO:Copying training dataset
2023-07-08 23:14:57,048:INFO:Plot type: pipeline
2023-07-08 23:14:57,146:INFO:Visual Rendered Successfully
2023-07-08 23:14:57,249:INFO:plot_model() successfully completed......................................
2023-07-08 23:15:00,866:INFO:Initializing plot_model()
2023-07-08 23:15:00,866:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, system=True)
2023-07-08 23:15:00,867:INFO:Checking exceptions
2023-07-08 23:15:00,869:INFO:Preloading libraries
2023-07-08 23:15:00,877:INFO:Copying training dataset
2023-07-08 23:15:00,878:INFO:Plot type: feature
2023-07-08 23:15:00,878:WARNING:No coef_ found. Trying feature_importances_
2023-07-08 23:15:01,093:INFO:Visual Rendered Successfully
2023-07-08 23:15:01,167:INFO:plot_model() successfully completed......................................
2023-07-08 23:15:44,354:INFO:Initializing predict_model()
2023-07-08 23:15:44,354:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000292BCC235E0>)
2023-07-08 23:15:44,355:INFO:Checking exceptions
2023-07-08 23:15:44,355:INFO:Preloading libraries
2023-07-08 23:15:54,359:INFO:Initializing predict_model()
2023-07-08 23:15:54,359:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000292BCC23430>)
2023-07-08 23:15:54,359:INFO:Checking exceptions
2023-07-08 23:15:54,359:INFO:Preloading libraries
2023-07-08 23:17:02,241:INFO:Initializing evaluate_model()
2023-07-08 23:17:02,242:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-08 23:17:02,267:INFO:Initializing plot_model()
2023-07-08 23:17:02,268:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, system=True)
2023-07-08 23:17:02,268:INFO:Checking exceptions
2023-07-08 23:17:02,273:INFO:Preloading libraries
2023-07-08 23:17:02,284:INFO:Copying training dataset
2023-07-08 23:17:02,284:INFO:Plot type: pipeline
2023-07-08 23:17:02,367:INFO:Visual Rendered Successfully
2023-07-08 23:17:02,437:INFO:plot_model() successfully completed......................................
2023-07-08 23:17:03,882:INFO:Initializing predict_model()
2023-07-08 23:17:03,882:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000292BC4CA670>)
2023-07-08 23:17:03,882:INFO:Checking exceptions
2023-07-08 23:17:03,882:INFO:Preloading libraries
2023-07-08 23:17:15,102:INFO:Initializing predict_model()
2023-07-08 23:17:15,102:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BE11A2E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000292BCBC2550>)
2023-07-08 23:17:15,102:INFO:Checking exceptions
2023-07-08 23:17:15,102:INFO:Preloading libraries
2023-07-08 23:23:21,182:INFO:PyCaret ClassificationExperiment
2023-07-08 23:23:21,182:INFO:Logging name: clf-default-name
2023-07-08 23:23:21,182:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-08 23:23:21,183:INFO:version 3.0.4
2023-07-08 23:23:21,183:INFO:Initializing setup()
2023-07-08 23:23:21,183:INFO:self.USI: 0091
2023-07-08 23:23:21,183:INFO:self._variable_keys: {'n_jobs_param', 'data', 'y_test', '_ml_usecase', 'memory', 'fold_groups_param', 'fix_imbalance', 'y', 'X_train', 'target_param', 'seed', 'y_train', 'exp_id', '_available_plots', 'html_param', 'X_test', 'fold_shuffle_param', 'logging_param', 'exp_name_log', 'gpu_param', 'USI', 'gpu_n_jobs_param', 'is_multiclass', 'fold_generator', 'idx', 'X', 'pipeline', 'log_plots_param'}
2023-07-08 23:23:21,183:INFO:Checking environment
2023-07-08 23:23:21,183:INFO:python_version: 3.9.13
2023-07-08 23:23:21,183:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-07-08 23:23:21,183:INFO:machine: AMD64
2023-07-08 23:23:21,183:INFO:platform: Windows-10-10.0.19045-SP0
2023-07-08 23:23:21,183:INFO:Memory: svmem(total=17125732352, available=10393485312, percent=39.3, used=6732247040, free=10393485312)
2023-07-08 23:23:21,183:INFO:Physical Core: 4
2023-07-08 23:23:21,183:INFO:Logical Core: 8
2023-07-08 23:23:21,183:INFO:Checking libraries
2023-07-08 23:23:21,183:INFO:System:
2023-07-08 23:23:21,183:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-07-08 23:23:21,183:INFO:executable: C:\Users\hamim\anaconda3\python.exe
2023-07-08 23:23:21,183:INFO:   machine: Windows-10-10.0.19045-SP0
2023-07-08 23:23:21,183:INFO:PyCaret required dependencies:
2023-07-08 23:23:21,183:INFO:                 pip: 22.2.2
2023-07-08 23:23:21,183:INFO:          setuptools: 63.4.1
2023-07-08 23:23:21,183:INFO:             pycaret: 3.0.4
2023-07-08 23:23:21,183:INFO:             IPython: 7.31.1
2023-07-08 23:23:21,183:INFO:          ipywidgets: 7.6.5
2023-07-08 23:23:21,183:INFO:                tqdm: 4.64.1
2023-07-08 23:23:21,184:INFO:               numpy: 1.21.5
2023-07-08 23:23:21,184:INFO:              pandas: 1.4.4
2023-07-08 23:23:21,184:INFO:              jinja2: 2.11.3
2023-07-08 23:23:21,184:INFO:               scipy: 1.9.1
2023-07-08 23:23:21,184:INFO:              joblib: 1.2.0
2023-07-08 23:23:21,184:INFO:             sklearn: 1.0.2
2023-07-08 23:23:21,184:INFO:                pyod: 1.1.0
2023-07-08 23:23:21,184:INFO:            imblearn: 0.10.1
2023-07-08 23:23:21,184:INFO:   category_encoders: 2.6.1
2023-07-08 23:23:21,184:INFO:            lightgbm: 3.3.5
2023-07-08 23:23:21,184:INFO:               numba: 0.55.1
2023-07-08 23:23:21,184:INFO:            requests: 2.28.1
2023-07-08 23:23:21,184:INFO:          matplotlib: 3.5.2
2023-07-08 23:23:21,184:INFO:          scikitplot: 0.3.7
2023-07-08 23:23:21,184:INFO:         yellowbrick: 1.5
2023-07-08 23:23:21,184:INFO:              plotly: 5.9.0
2023-07-08 23:23:21,184:INFO:    plotly-resampler: Not installed
2023-07-08 23:23:21,184:INFO:             kaleido: 0.2.1
2023-07-08 23:23:21,184:INFO:           schemdraw: 0.15
2023-07-08 23:23:21,185:INFO:         statsmodels: 0.13.2
2023-07-08 23:23:21,185:INFO:              sktime: 0.20.0
2023-07-08 23:23:21,185:INFO:               tbats: 1.1.3
2023-07-08 23:23:21,185:INFO:            pmdarima: 2.0.3
2023-07-08 23:23:21,185:INFO:              psutil: 5.9.0
2023-07-08 23:23:21,185:INFO:          markupsafe: 2.0.1
2023-07-08 23:23:21,185:INFO:             pickle5: Not installed
2023-07-08 23:23:21,185:INFO:         cloudpickle: 2.0.0
2023-07-08 23:23:21,185:INFO:         deprecation: 2.1.0
2023-07-08 23:23:21,185:INFO:              xxhash: 3.2.0
2023-07-08 23:23:21,185:INFO:           wurlitzer: Not installed
2023-07-08 23:23:21,185:INFO:PyCaret optional dependencies:
2023-07-08 23:23:21,185:INFO:                shap: Not installed
2023-07-08 23:23:21,185:INFO:           interpret: Not installed
2023-07-08 23:23:21,185:INFO:                umap: Not installed
2023-07-08 23:23:21,185:INFO:    pandas_profiling: Not installed
2023-07-08 23:23:21,185:INFO:  explainerdashboard: Not installed
2023-07-08 23:23:21,185:INFO:             autoviz: Not installed
2023-07-08 23:23:21,185:INFO:           fairlearn: Not installed
2023-07-08 23:23:21,186:INFO:          deepchecks: Not installed
2023-07-08 23:23:21,186:INFO:             xgboost: Not installed
2023-07-08 23:23:21,186:INFO:            catboost: Not installed
2023-07-08 23:23:21,186:INFO:              kmodes: Not installed
2023-07-08 23:23:21,186:INFO:             mlxtend: Not installed
2023-07-08 23:23:21,186:INFO:       statsforecast: Not installed
2023-07-08 23:23:21,186:INFO:        tune_sklearn: Not installed
2023-07-08 23:23:21,186:INFO:                 ray: Not installed
2023-07-08 23:23:21,186:INFO:            hyperopt: Not installed
2023-07-08 23:23:21,186:INFO:              optuna: Not installed
2023-07-08 23:23:21,186:INFO:               skopt: Not installed
2023-07-08 23:23:21,186:INFO:              mlflow: Not installed
2023-07-08 23:23:21,186:INFO:              gradio: Not installed
2023-07-08 23:23:21,186:INFO:             fastapi: Not installed
2023-07-08 23:23:21,186:INFO:             uvicorn: Not installed
2023-07-08 23:23:21,186:INFO:              m2cgen: Not installed
2023-07-08 23:23:21,186:INFO:           evidently: Not installed
2023-07-08 23:23:21,186:INFO:               fugue: Not installed
2023-07-08 23:23:21,186:INFO:           streamlit: Not installed
2023-07-08 23:23:21,186:INFO:             prophet: Not installed
2023-07-08 23:23:21,187:INFO:None
2023-07-08 23:23:21,187:INFO:Set up data.
2023-07-08 23:23:21,193:INFO:Set up train/test split.
2023-07-08 23:23:21,198:INFO:Set up index.
2023-07-08 23:23:21,198:INFO:Set up folding strategy.
2023-07-08 23:23:21,198:INFO:Assigning column types.
2023-07-08 23:23:21,204:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-08 23:23:21,259:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-08 23:23:21,260:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 23:23:21,293:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:23:21,293:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:23:21,345:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-08 23:23:21,347:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 23:23:21,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:23:21,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:23:21,385:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-08 23:23:21,434:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 23:23:21,461:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:23:21,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:23:21,506:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-08 23:23:21,532:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:23:21,533:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:23:21,533:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-08 23:23:21,613:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:23:21,613:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:23:21,695:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:23:21,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:23:21,696:INFO:Preparing preprocessing pipeline...
2023-07-08 23:23:21,697:INFO:Set up simple imputation.
2023-07-08 23:23:21,698:INFO:Set up imbalanced handling.
2023-07-08 23:23:21,698:INFO:Set up column name cleaning.
2023-07-08 23:23:21,759:INFO:Finished creating preprocessing pipeline.
2023-07-08 23:23:21,769:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\hamim\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tuition fees up to date',
                                             'Gender', 'Scholarship holder',
                                             'Curricular units 1st sem (grade)',
                                             'Curricular units 2nd sem (grade)',
                                             'Age Group_1', 'Age Group_2',
                                             'Age Group_3', 'Age Group_4',
                                             'Age Group_5', 'Age Group_6'],
                                    transformer...
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-08 23:23:21,769:INFO:Creating final display dataframe.
2023-07-08 23:23:21,886:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            Target
2                   Target type            Binary
3           Original data shape        (2802, 12)
4        Transformed data shape        (3825, 12)
5   Transformed train set shape        (2984, 12)
6    Transformed test set shape         (841, 12)
7              Numeric features                11
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              0091
2023-07-08 23:23:21,975:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:23:21,975:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:23:22,048:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:23:22,048:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-08 23:23:22,049:INFO:setup() successfully completed in 1.5s...............
2023-07-08 23:23:36,149:INFO:Initializing compare_models()
2023-07-08 23:23:36,149:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-08 23:23:36,150:INFO:Checking exceptions
2023-07-08 23:23:36,156:INFO:Preparing display monitor
2023-07-08 23:23:36,217:INFO:Initializing Logistic Regression
2023-07-08 23:23:36,217:INFO:Total runtime is 0.0 minutes
2023-07-08 23:23:36,222:INFO:SubProcess create_model() called ==================================
2023-07-08 23:23:36,223:INFO:Initializing create_model()
2023-07-08 23:23:36,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC469760>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:23:36,223:INFO:Checking exceptions
2023-07-08 23:23:36,224:INFO:Importing libraries
2023-07-08 23:23:36,224:INFO:Copying training dataset
2023-07-08 23:23:36,232:INFO:Defining folds
2023-07-08 23:23:36,232:INFO:Declaring metric variables
2023-07-08 23:23:36,236:INFO:Importing untrained model
2023-07-08 23:23:36,242:INFO:Logistic Regression Imported successfully
2023-07-08 23:23:36,255:INFO:Starting cross validation
2023-07-08 23:23:36,257:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:23:48,711:INFO:Calculating mean and std
2023-07-08 23:23:48,713:INFO:Creating metrics dataframe
2023-07-08 23:23:49,403:INFO:Uploading results into container
2023-07-08 23:23:49,404:INFO:Uploading model into container now
2023-07-08 23:23:49,404:INFO:_master_model_container: 1
2023-07-08 23:23:49,404:INFO:_display_container: 2
2023-07-08 23:23:49,405:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-08 23:23:49,405:INFO:create_model() successfully completed......................................
2023-07-08 23:23:49,481:INFO:SubProcess create_model() end ==================================
2023-07-08 23:23:49,482:INFO:Creating metrics dataframe
2023-07-08 23:23:49,493:INFO:Initializing K Neighbors Classifier
2023-07-08 23:23:49,493:INFO:Total runtime is 0.22127008040746052 minutes
2023-07-08 23:23:49,498:INFO:SubProcess create_model() called ==================================
2023-07-08 23:23:49,498:INFO:Initializing create_model()
2023-07-08 23:23:49,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC469760>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:23:49,499:INFO:Checking exceptions
2023-07-08 23:23:49,499:INFO:Importing libraries
2023-07-08 23:23:49,499:INFO:Copying training dataset
2023-07-08 23:23:49,505:INFO:Defining folds
2023-07-08 23:23:49,505:INFO:Declaring metric variables
2023-07-08 23:23:49,510:INFO:Importing untrained model
2023-07-08 23:23:49,518:INFO:K Neighbors Classifier Imported successfully
2023-07-08 23:23:49,530:INFO:Starting cross validation
2023-07-08 23:23:49,532:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:23:49,709:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:23:49,709:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:23:49,731:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:23:49,739:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:23:49,745:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:23:49,763:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:23:49,766:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:23:49,777:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:23:51,149:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:23:51,180:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-08 23:23:55,489:INFO:Calculating mean and std
2023-07-08 23:23:55,492:INFO:Creating metrics dataframe
2023-07-08 23:23:56,234:INFO:Uploading results into container
2023-07-08 23:23:56,235:INFO:Uploading model into container now
2023-07-08 23:23:56,236:INFO:_master_model_container: 2
2023-07-08 23:23:56,236:INFO:_display_container: 2
2023-07-08 23:23:56,236:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-08 23:23:56,237:INFO:create_model() successfully completed......................................
2023-07-08 23:23:56,305:INFO:SubProcess create_model() end ==================================
2023-07-08 23:23:56,306:INFO:Creating metrics dataframe
2023-07-08 23:23:56,315:INFO:Initializing Naive Bayes
2023-07-08 23:23:56,315:INFO:Total runtime is 0.3349703113238017 minutes
2023-07-08 23:23:56,318:INFO:SubProcess create_model() called ==================================
2023-07-08 23:23:56,319:INFO:Initializing create_model()
2023-07-08 23:23:56,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC469760>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:23:56,319:INFO:Checking exceptions
2023-07-08 23:23:56,319:INFO:Importing libraries
2023-07-08 23:23:56,319:INFO:Copying training dataset
2023-07-08 23:23:56,326:INFO:Defining folds
2023-07-08 23:23:56,326:INFO:Declaring metric variables
2023-07-08 23:23:56,331:INFO:Importing untrained model
2023-07-08 23:23:56,336:INFO:Naive Bayes Imported successfully
2023-07-08 23:23:56,347:INFO:Starting cross validation
2023-07-08 23:23:56,349:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:24:01,698:INFO:Calculating mean and std
2023-07-08 23:24:01,700:INFO:Creating metrics dataframe
2023-07-08 23:24:02,386:INFO:Uploading results into container
2023-07-08 23:24:02,387:INFO:Uploading model into container now
2023-07-08 23:24:02,387:INFO:_master_model_container: 3
2023-07-08 23:24:02,387:INFO:_display_container: 2
2023-07-08 23:24:02,388:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-08 23:24:02,388:INFO:create_model() successfully completed......................................
2023-07-08 23:24:02,458:INFO:SubProcess create_model() end ==================================
2023-07-08 23:24:02,458:INFO:Creating metrics dataframe
2023-07-08 23:24:02,467:INFO:Initializing Decision Tree Classifier
2023-07-08 23:24:02,468:INFO:Total runtime is 0.43752403259277345 minutes
2023-07-08 23:24:02,473:INFO:SubProcess create_model() called ==================================
2023-07-08 23:24:02,473:INFO:Initializing create_model()
2023-07-08 23:24:02,473:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC469760>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:24:02,473:INFO:Checking exceptions
2023-07-08 23:24:02,474:INFO:Importing libraries
2023-07-08 23:24:02,474:INFO:Copying training dataset
2023-07-08 23:24:02,479:INFO:Defining folds
2023-07-08 23:24:02,479:INFO:Declaring metric variables
2023-07-08 23:24:02,483:INFO:Importing untrained model
2023-07-08 23:24:02,488:INFO:Decision Tree Classifier Imported successfully
2023-07-08 23:24:02,502:INFO:Starting cross validation
2023-07-08 23:24:02,504:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:24:08,001:INFO:Calculating mean and std
2023-07-08 23:24:08,003:INFO:Creating metrics dataframe
2023-07-08 23:24:08,761:INFO:Uploading results into container
2023-07-08 23:24:08,762:INFO:Uploading model into container now
2023-07-08 23:24:08,763:INFO:_master_model_container: 4
2023-07-08 23:24:08,763:INFO:_display_container: 2
2023-07-08 23:24:08,764:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-08 23:24:08,764:INFO:create_model() successfully completed......................................
2023-07-08 23:24:08,841:INFO:SubProcess create_model() end ==================================
2023-07-08 23:24:08,842:INFO:Creating metrics dataframe
2023-07-08 23:24:08,854:INFO:Initializing SVM - Linear Kernel
2023-07-08 23:24:08,854:INFO:Total runtime is 0.5439535061518351 minutes
2023-07-08 23:24:08,858:INFO:SubProcess create_model() called ==================================
2023-07-08 23:24:08,859:INFO:Initializing create_model()
2023-07-08 23:24:08,859:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC469760>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:24:08,859:INFO:Checking exceptions
2023-07-08 23:24:08,859:INFO:Importing libraries
2023-07-08 23:24:08,859:INFO:Copying training dataset
2023-07-08 23:24:08,867:INFO:Defining folds
2023-07-08 23:24:08,868:INFO:Declaring metric variables
2023-07-08 23:24:08,873:INFO:Importing untrained model
2023-07-08 23:24:08,879:INFO:SVM - Linear Kernel Imported successfully
2023-07-08 23:24:08,892:INFO:Starting cross validation
2023-07-08 23:24:08,895:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:24:09,077:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:24:09,088:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:24:09,123:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:24:09,129:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:24:09,140:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:24:09,146:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:24:09,150:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:24:09,175:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:24:10,208:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:24:10,230:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-08 23:24:14,055:INFO:Calculating mean and std
2023-07-08 23:24:14,057:INFO:Creating metrics dataframe
2023-07-08 23:24:14,735:INFO:Uploading results into container
2023-07-08 23:24:14,736:INFO:Uploading model into container now
2023-07-08 23:24:14,736:INFO:_master_model_container: 5
2023-07-08 23:24:14,736:INFO:_display_container: 2
2023-07-08 23:24:14,737:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-08 23:24:14,737:INFO:create_model() successfully completed......................................
2023-07-08 23:24:14,804:INFO:SubProcess create_model() end ==================================
2023-07-08 23:24:14,804:INFO:Creating metrics dataframe
2023-07-08 23:24:14,815:INFO:Initializing Ridge Classifier
2023-07-08 23:24:14,815:INFO:Total runtime is 0.6433097004890442 minutes
2023-07-08 23:24:14,820:INFO:SubProcess create_model() called ==================================
2023-07-08 23:24:14,820:INFO:Initializing create_model()
2023-07-08 23:24:14,821:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC469760>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:24:14,821:INFO:Checking exceptions
2023-07-08 23:24:14,821:INFO:Importing libraries
2023-07-08 23:24:14,821:INFO:Copying training dataset
2023-07-08 23:24:14,826:INFO:Defining folds
2023-07-08 23:24:14,826:INFO:Declaring metric variables
2023-07-08 23:24:14,831:INFO:Importing untrained model
2023-07-08 23:24:14,837:INFO:Ridge Classifier Imported successfully
2023-07-08 23:24:14,850:INFO:Starting cross validation
2023-07-08 23:24:14,852:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:24:14,995:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:24:14,996:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:24:15,006:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:24:15,009:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:24:15,018:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:24:15,027:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:24:15,049:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:24:15,054:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:24:16,080:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-08 23:24:19,933:INFO:Calculating mean and std
2023-07-08 23:24:19,935:INFO:Creating metrics dataframe
2023-07-08 23:24:20,623:INFO:Uploading results into container
2023-07-08 23:24:20,624:INFO:Uploading model into container now
2023-07-08 23:24:20,624:INFO:_master_model_container: 6
2023-07-08 23:24:20,624:INFO:_display_container: 2
2023-07-08 23:24:20,625:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=42, solver='auto', tol=0.001)
2023-07-08 23:24:20,625:INFO:create_model() successfully completed......................................
2023-07-08 23:24:20,698:INFO:SubProcess create_model() end ==================================
2023-07-08 23:24:20,699:INFO:Creating metrics dataframe
2023-07-08 23:24:20,709:INFO:Initializing Random Forest Classifier
2023-07-08 23:24:20,709:INFO:Total runtime is 0.7415380636850993 minutes
2023-07-08 23:24:20,714:INFO:SubProcess create_model() called ==================================
2023-07-08 23:24:20,715:INFO:Initializing create_model()
2023-07-08 23:24:20,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC469760>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:24:20,715:INFO:Checking exceptions
2023-07-08 23:24:20,715:INFO:Importing libraries
2023-07-08 23:24:20,715:INFO:Copying training dataset
2023-07-08 23:24:20,720:INFO:Defining folds
2023-07-08 23:24:20,720:INFO:Declaring metric variables
2023-07-08 23:24:20,725:INFO:Importing untrained model
2023-07-08 23:24:20,730:INFO:Random Forest Classifier Imported successfully
2023-07-08 23:24:20,744:INFO:Starting cross validation
2023-07-08 23:24:20,747:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:24:27,529:INFO:Calculating mean and std
2023-07-08 23:24:27,531:INFO:Creating metrics dataframe
2023-07-08 23:24:28,242:INFO:Uploading results into container
2023-07-08 23:24:28,243:INFO:Uploading model into container now
2023-07-08 23:24:28,243:INFO:_master_model_container: 7
2023-07-08 23:24:28,244:INFO:_display_container: 2
2023-07-08 23:24:28,244:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-08 23:24:28,244:INFO:create_model() successfully completed......................................
2023-07-08 23:24:28,313:INFO:SubProcess create_model() end ==================================
2023-07-08 23:24:28,314:INFO:Creating metrics dataframe
2023-07-08 23:24:28,324:INFO:Initializing Quadratic Discriminant Analysis
2023-07-08 23:24:28,325:INFO:Total runtime is 0.8684747219085693 minutes
2023-07-08 23:24:28,328:INFO:SubProcess create_model() called ==================================
2023-07-08 23:24:28,328:INFO:Initializing create_model()
2023-07-08 23:24:28,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC469760>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:24:28,329:INFO:Checking exceptions
2023-07-08 23:24:28,329:INFO:Importing libraries
2023-07-08 23:24:28,329:INFO:Copying training dataset
2023-07-08 23:24:28,334:INFO:Defining folds
2023-07-08 23:24:28,334:INFO:Declaring metric variables
2023-07-08 23:24:28,337:INFO:Importing untrained model
2023-07-08 23:24:28,342:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-08 23:24:28,354:INFO:Starting cross validation
2023-07-08 23:24:28,357:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:24:28,460:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:24:28,462:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:24:28,471:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:24:28,490:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,490:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,493:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,493:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,493:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:24:28,499:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:24:28,502:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,502:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,503:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:28,503:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:28,503:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:28,507:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:24:28,520:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:24:28,529:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,529:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,529:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:28,532:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,532:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,532:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,533:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,533:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,533:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:28,533:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,533:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:28,533:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:28,536:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,536:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,536:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:28,537:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,537:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,537:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,537:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:28,537:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,538:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:28,538:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:24:28,540:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:24:28,542:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:24:28,546:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:24:28,547:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:24:28,550:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:24:28,553:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,554:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,554:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:28,559:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,560:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,560:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:28,566:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,566:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,567:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:28,568:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,568:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,569:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:28,570:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,571:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,571:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:24:28,571:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:28,572:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:24:28,576:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:24:28,577:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:24:28,578:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:24:28,578:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:24:28,582:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:24:28,582:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:24:28,586:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,587:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:28,587:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:28,590:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:24:28,597:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:24:29,643:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:24:29,653:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-08 23:24:29,663:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:29,663:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:29,663:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:29,670:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:29,670:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:29,671:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:29,680:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:29,680:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:29,680:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:29,682:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:24:29,685:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:24:29,687:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:29,687:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-08 23:24:29,687:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-08 23:24:29,688:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\hamim\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-07-08 23:24:29,691:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:24:33,554:INFO:Calculating mean and std
2023-07-08 23:24:33,556:INFO:Creating metrics dataframe
2023-07-08 23:24:34,239:INFO:Uploading results into container
2023-07-08 23:24:34,240:INFO:Uploading model into container now
2023-07-08 23:24:34,240:INFO:_master_model_container: 8
2023-07-08 23:24:34,241:INFO:_display_container: 2
2023-07-08 23:24:34,241:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-08 23:24:34,241:INFO:create_model() successfully completed......................................
2023-07-08 23:24:34,311:INFO:SubProcess create_model() end ==================================
2023-07-08 23:24:34,311:INFO:Creating metrics dataframe
2023-07-08 23:24:34,325:INFO:Initializing Ada Boost Classifier
2023-07-08 23:24:34,325:INFO:Total runtime is 0.9684652884801229 minutes
2023-07-08 23:24:34,329:INFO:SubProcess create_model() called ==================================
2023-07-08 23:24:34,330:INFO:Initializing create_model()
2023-07-08 23:24:34,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC469760>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:24:34,330:INFO:Checking exceptions
2023-07-08 23:24:34,330:INFO:Importing libraries
2023-07-08 23:24:34,330:INFO:Copying training dataset
2023-07-08 23:24:34,336:INFO:Defining folds
2023-07-08 23:24:34,336:INFO:Declaring metric variables
2023-07-08 23:24:34,340:INFO:Importing untrained model
2023-07-08 23:24:34,345:INFO:Ada Boost Classifier Imported successfully
2023-07-08 23:24:34,358:INFO:Starting cross validation
2023-07-08 23:24:34,361:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:24:40,613:INFO:Calculating mean and std
2023-07-08 23:24:40,615:INFO:Creating metrics dataframe
2023-07-08 23:24:41,360:INFO:Uploading results into container
2023-07-08 23:24:41,361:INFO:Uploading model into container now
2023-07-08 23:24:41,361:INFO:_master_model_container: 9
2023-07-08 23:24:41,361:INFO:_display_container: 2
2023-07-08 23:24:41,362:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2023-07-08 23:24:41,362:INFO:create_model() successfully completed......................................
2023-07-08 23:24:41,433:INFO:SubProcess create_model() end ==================================
2023-07-08 23:24:41,433:INFO:Creating metrics dataframe
2023-07-08 23:24:41,445:INFO:Initializing Gradient Boosting Classifier
2023-07-08 23:24:41,445:INFO:Total runtime is 1.087128710746765 minutes
2023-07-08 23:24:41,449:INFO:SubProcess create_model() called ==================================
2023-07-08 23:24:41,449:INFO:Initializing create_model()
2023-07-08 23:24:41,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC469760>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:24:41,450:INFO:Checking exceptions
2023-07-08 23:24:41,450:INFO:Importing libraries
2023-07-08 23:24:41,450:INFO:Copying training dataset
2023-07-08 23:24:41,455:INFO:Defining folds
2023-07-08 23:24:41,455:INFO:Declaring metric variables
2023-07-08 23:24:41,458:INFO:Importing untrained model
2023-07-08 23:24:41,463:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 23:24:41,475:INFO:Starting cross validation
2023-07-08 23:24:41,477:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:24:47,378:INFO:Calculating mean and std
2023-07-08 23:24:47,380:INFO:Creating metrics dataframe
2023-07-08 23:24:48,081:INFO:Uploading results into container
2023-07-08 23:24:48,082:INFO:Uploading model into container now
2023-07-08 23:24:48,082:INFO:_master_model_container: 10
2023-07-08 23:24:48,083:INFO:_display_container: 2
2023-07-08 23:24:48,083:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 23:24:48,083:INFO:create_model() successfully completed......................................
2023-07-08 23:24:48,155:INFO:SubProcess create_model() end ==================================
2023-07-08 23:24:48,155:INFO:Creating metrics dataframe
2023-07-08 23:24:48,166:INFO:Initializing Linear Discriminant Analysis
2023-07-08 23:24:48,166:INFO:Total runtime is 1.1991557916005453 minutes
2023-07-08 23:24:48,170:INFO:SubProcess create_model() called ==================================
2023-07-08 23:24:48,170:INFO:Initializing create_model()
2023-07-08 23:24:48,170:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC469760>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:24:48,170:INFO:Checking exceptions
2023-07-08 23:24:48,170:INFO:Importing libraries
2023-07-08 23:24:48,171:INFO:Copying training dataset
2023-07-08 23:24:48,177:INFO:Defining folds
2023-07-08 23:24:48,178:INFO:Declaring metric variables
2023-07-08 23:24:48,183:INFO:Importing untrained model
2023-07-08 23:24:48,188:INFO:Linear Discriminant Analysis Imported successfully
2023-07-08 23:24:48,203:INFO:Starting cross validation
2023-07-08 23:24:48,205:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:24:53,650:INFO:Calculating mean and std
2023-07-08 23:24:53,652:INFO:Creating metrics dataframe
2023-07-08 23:24:54,391:INFO:Uploading results into container
2023-07-08 23:24:54,391:INFO:Uploading model into container now
2023-07-08 23:24:54,392:INFO:_master_model_container: 11
2023-07-08 23:24:54,392:INFO:_display_container: 2
2023-07-08 23:24:54,393:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-08 23:24:54,393:INFO:create_model() successfully completed......................................
2023-07-08 23:24:54,469:INFO:SubProcess create_model() end ==================================
2023-07-08 23:24:54,470:INFO:Creating metrics dataframe
2023-07-08 23:24:54,482:INFO:Initializing Extra Trees Classifier
2023-07-08 23:24:54,483:INFO:Total runtime is 1.3044422705968222 minutes
2023-07-08 23:24:54,488:INFO:SubProcess create_model() called ==================================
2023-07-08 23:24:54,488:INFO:Initializing create_model()
2023-07-08 23:24:54,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC469760>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:24:54,489:INFO:Checking exceptions
2023-07-08 23:24:54,489:INFO:Importing libraries
2023-07-08 23:24:54,489:INFO:Copying training dataset
2023-07-08 23:24:54,496:INFO:Defining folds
2023-07-08 23:24:54,496:INFO:Declaring metric variables
2023-07-08 23:24:54,502:INFO:Importing untrained model
2023-07-08 23:24:54,508:INFO:Extra Trees Classifier Imported successfully
2023-07-08 23:24:54,520:INFO:Starting cross validation
2023-07-08 23:24:54,525:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:25:01,451:INFO:Calculating mean and std
2023-07-08 23:25:01,454:INFO:Creating metrics dataframe
2023-07-08 23:25:02,239:INFO:Uploading results into container
2023-07-08 23:25:02,240:INFO:Uploading model into container now
2023-07-08 23:25:02,241:INFO:_master_model_container: 12
2023-07-08 23:25:02,241:INFO:_display_container: 2
2023-07-08 23:25:02,242:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-08 23:25:02,242:INFO:create_model() successfully completed......................................
2023-07-08 23:25:02,316:INFO:SubProcess create_model() end ==================================
2023-07-08 23:25:02,317:INFO:Creating metrics dataframe
2023-07-08 23:25:02,330:INFO:Initializing Light Gradient Boosting Machine
2023-07-08 23:25:02,330:INFO:Total runtime is 1.4352189461390177 minutes
2023-07-08 23:25:02,334:INFO:SubProcess create_model() called ==================================
2023-07-08 23:25:02,335:INFO:Initializing create_model()
2023-07-08 23:25:02,335:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC469760>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:25:02,335:INFO:Checking exceptions
2023-07-08 23:25:02,335:INFO:Importing libraries
2023-07-08 23:25:02,335:INFO:Copying training dataset
2023-07-08 23:25:02,344:INFO:Defining folds
2023-07-08 23:25:02,344:INFO:Declaring metric variables
2023-07-08 23:25:02,348:INFO:Importing untrained model
2023-07-08 23:25:02,354:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-08 23:25:02,369:INFO:Starting cross validation
2023-07-08 23:25:02,370:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:25:09,528:INFO:Calculating mean and std
2023-07-08 23:25:09,529:INFO:Creating metrics dataframe
2023-07-08 23:25:10,338:INFO:Uploading results into container
2023-07-08 23:25:10,339:INFO:Uploading model into container now
2023-07-08 23:25:10,339:INFO:_master_model_container: 13
2023-07-08 23:25:10,340:INFO:_display_container: 2
2023-07-08 23:25:10,340:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-08 23:25:10,340:INFO:create_model() successfully completed......................................
2023-07-08 23:25:10,417:INFO:SubProcess create_model() end ==================================
2023-07-08 23:25:10,417:INFO:Creating metrics dataframe
2023-07-08 23:25:10,431:INFO:Initializing Dummy Classifier
2023-07-08 23:25:10,431:INFO:Total runtime is 1.5702303409576415 minutes
2023-07-08 23:25:10,436:INFO:SubProcess create_model() called ==================================
2023-07-08 23:25:10,437:INFO:Initializing create_model()
2023-07-08 23:25:10,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC469760>, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:25:10,437:INFO:Checking exceptions
2023-07-08 23:25:10,438:INFO:Importing libraries
2023-07-08 23:25:10,438:INFO:Copying training dataset
2023-07-08 23:25:10,447:INFO:Defining folds
2023-07-08 23:25:10,447:INFO:Declaring metric variables
2023-07-08 23:25:10,453:INFO:Importing untrained model
2023-07-08 23:25:10,460:INFO:Dummy Classifier Imported successfully
2023-07-08 23:25:10,472:INFO:Starting cross validation
2023-07-08 23:25:10,475:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:25:10,640:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:25:10,654:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:25:10,670:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:25:10,673:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:25:10,688:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:25:10,695:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:25:10,698:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:25:10,698:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:25:11,946:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:25:11,974:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-08 23:25:16,195:INFO:Calculating mean and std
2023-07-08 23:25:16,196:INFO:Creating metrics dataframe
2023-07-08 23:25:16,935:INFO:Uploading results into container
2023-07-08 23:25:16,936:INFO:Uploading model into container now
2023-07-08 23:25:16,936:INFO:_master_model_container: 14
2023-07-08 23:25:16,937:INFO:_display_container: 2
2023-07-08 23:25:16,937:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-08 23:25:16,937:INFO:create_model() successfully completed......................................
2023-07-08 23:25:17,005:INFO:SubProcess create_model() end ==================================
2023-07-08 23:25:17,005:INFO:Creating metrics dataframe
2023-07-08 23:25:17,029:INFO:Initializing create_model()
2023-07-08 23:25:17,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:25:17,029:INFO:Checking exceptions
2023-07-08 23:25:17,032:INFO:Importing libraries
2023-07-08 23:25:17,032:INFO:Copying training dataset
2023-07-08 23:25:17,037:INFO:Defining folds
2023-07-08 23:25:17,037:INFO:Declaring metric variables
2023-07-08 23:25:17,037:INFO:Importing untrained model
2023-07-08 23:25:17,037:INFO:Declaring custom model
2023-07-08 23:25:17,038:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 23:25:17,039:INFO:Cross validation set to False
2023-07-08 23:25:17,039:INFO:Fitting Model
2023-07-08 23:25:17,898:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 23:25:17,898:INFO:create_model() successfully completed......................................
2023-07-08 23:25:18,002:INFO:_master_model_container: 14
2023-07-08 23:25:18,003:INFO:_display_container: 2
2023-07-08 23:25:18,004:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 23:25:18,004:INFO:compare_models() successfully completed......................................
2023-07-08 23:25:36,541:INFO:Initializing tune_model()
2023-07-08 23:25:36,541:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>)
2023-07-08 23:25:36,542:INFO:Checking exceptions
2023-07-08 23:25:36,583:INFO:Copying training dataset
2023-07-08 23:25:36,587:INFO:Checking base model
2023-07-08 23:25:36,588:INFO:Base model : Gradient Boosting Classifier
2023-07-08 23:25:36,593:INFO:Declaring metric variables
2023-07-08 23:25:36,601:INFO:Defining Hyperparameters
2023-07-08 23:25:36,692:INFO:Tuning with n_jobs=-1
2023-07-08 23:25:36,692:INFO:Initializing RandomizedSearchCV
2023-07-08 23:26:42,372:INFO:best_params: {'actual_estimator__subsample': 0.65, 'actual_estimator__n_estimators': 120, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.05}
2023-07-08 23:26:42,373:INFO:Hyperparameter search completed
2023-07-08 23:26:42,374:INFO:SubProcess create_model() called ==================================
2023-07-08 23:26:42,374:INFO:Initializing create_model()
2023-07-08 23:26:42,374:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000292BC184D30>, model_only=True, return_train_score=False, kwargs={'subsample': 0.65, 'n_estimators': 120, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0002, 'max_features': 'sqrt', 'max_depth': 6, 'learning_rate': 0.05})
2023-07-08 23:26:42,375:INFO:Checking exceptions
2023-07-08 23:26:42,375:INFO:Importing libraries
2023-07-08 23:26:42,375:INFO:Copying training dataset
2023-07-08 23:26:42,381:INFO:Defining folds
2023-07-08 23:26:42,381:INFO:Declaring metric variables
2023-07-08 23:26:42,385:INFO:Importing untrained model
2023-07-08 23:26:42,386:INFO:Declaring custom model
2023-07-08 23:26:42,391:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 23:26:42,400:INFO:Starting cross validation
2023-07-08 23:26:42,401:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:26:49,437:INFO:Calculating mean and std
2023-07-08 23:26:49,439:INFO:Creating metrics dataframe
2023-07-08 23:26:49,445:INFO:Finalizing model
2023-07-08 23:26:50,734:INFO:Uploading results into container
2023-07-08 23:26:50,736:INFO:Uploading model into container now
2023-07-08 23:26:50,736:INFO:_master_model_container: 15
2023-07-08 23:26:50,737:INFO:_display_container: 3
2023-07-08 23:26:50,737:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='deviance', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.0002, min_samples_leaf=3,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=120, n_iter_no_change=None,
                           random_state=42, subsample=0.65, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 23:26:50,737:INFO:create_model() successfully completed......................................
2023-07-08 23:26:50,810:INFO:SubProcess create_model() end ==================================
2023-07-08 23:26:50,811:INFO:choose_better activated
2023-07-08 23:26:50,814:INFO:SubProcess create_model() called ==================================
2023-07-08 23:26:50,814:INFO:Initializing create_model()
2023-07-08 23:26:50,815:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-08 23:26:50,815:INFO:Checking exceptions
2023-07-08 23:26:50,817:INFO:Importing libraries
2023-07-08 23:26:50,817:INFO:Copying training dataset
2023-07-08 23:26:50,821:INFO:Defining folds
2023-07-08 23:26:50,821:INFO:Declaring metric variables
2023-07-08 23:26:50,822:INFO:Importing untrained model
2023-07-08 23:26:50,822:INFO:Declaring custom model
2023-07-08 23:26:50,822:INFO:Gradient Boosting Classifier Imported successfully
2023-07-08 23:26:50,823:INFO:Starting cross validation
2023-07-08 23:26:50,824:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-08 23:26:57,399:INFO:Calculating mean and std
2023-07-08 23:26:57,399:INFO:Creating metrics dataframe
2023-07-08 23:26:57,402:INFO:Finalizing model
2023-07-08 23:26:58,243:INFO:Uploading results into container
2023-07-08 23:26:58,244:INFO:Uploading model into container now
2023-07-08 23:26:58,244:INFO:_master_model_container: 16
2023-07-08 23:26:58,244:INFO:_display_container: 4
2023-07-08 23:26:58,245:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 23:26:58,245:INFO:create_model() successfully completed......................................
2023-07-08 23:26:58,311:INFO:SubProcess create_model() end ==================================
2023-07-08 23:26:58,312:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.822
2023-07-08 23:26:58,313:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='deviance', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.0002, min_samples_leaf=3,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=120, n_iter_no_change=None,
                           random_state=42, subsample=0.65, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8128
2023-07-08 23:26:58,313:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-07-08 23:26:58,313:INFO:choose_better completed
2023-07-08 23:26:58,313:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-07-08 23:26:58,323:INFO:_master_model_container: 16
2023-07-08 23:26:58,323:INFO:_display_container: 3
2023-07-08 23:26:58,324:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-08 23:26:58,324:INFO:tune_model() successfully completed......................................
2023-07-08 23:28:05,326:INFO:Initializing evaluate_model()
2023-07-08 23:28:05,326:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-08 23:28:05,355:INFO:Initializing plot_model()
2023-07-08 23:28:05,355:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, system=True)
2023-07-08 23:28:05,355:INFO:Checking exceptions
2023-07-08 23:28:05,358:INFO:Preloading libraries
2023-07-08 23:28:05,370:INFO:Copying training dataset
2023-07-08 23:28:05,370:INFO:Plot type: pipeline
2023-07-08 23:28:05,478:INFO:Visual Rendered Successfully
2023-07-08 23:28:05,567:INFO:plot_model() successfully completed......................................
2023-07-08 23:28:11,790:INFO:Initializing plot_model()
2023-07-08 23:28:11,790:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, system=True)
2023-07-08 23:28:11,790:INFO:Checking exceptions
2023-07-08 23:28:11,794:INFO:Preloading libraries
2023-07-08 23:28:11,808:INFO:Copying training dataset
2023-07-08 23:28:11,808:INFO:Plot type: confusion_matrix
2023-07-08 23:28:11,931:INFO:Fitting Model
2023-07-08 23:28:11,931:WARNING:C:\Users\hamim\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-07-08 23:28:11,932:INFO:Scoring test/hold-out set
2023-07-08 23:28:12,061:INFO:Visual Rendered Successfully
2023-07-08 23:28:12,142:INFO:plot_model() successfully completed......................................
2023-07-08 23:28:18,235:INFO:Initializing plot_model()
2023-07-08 23:28:18,236:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, system=True)
2023-07-08 23:28:18,236:INFO:Checking exceptions
2023-07-08 23:28:18,240:INFO:Preloading libraries
2023-07-08 23:28:18,250:INFO:Copying training dataset
2023-07-08 23:28:18,250:INFO:Plot type: feature
2023-07-08 23:28:18,250:WARNING:No coef_ found. Trying feature_importances_
2023-07-08 23:28:18,445:INFO:Visual Rendered Successfully
2023-07-08 23:28:18,526:INFO:plot_model() successfully completed......................................
2023-07-08 23:28:54,199:INFO:Initializing predict_model()
2023-07-08 23:28:54,200:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000292BCC40BE0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000292BC30D8B0>)
2023-07-08 23:28:54,200:INFO:Checking exceptions
2023-07-08 23:28:54,200:INFO:Preloading libraries
